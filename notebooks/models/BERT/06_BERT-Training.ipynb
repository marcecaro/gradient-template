{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bb3ff-f742-454d-8080-5e60d8175299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp project.models.bert.training\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb276b",
   "metadata": {},
   "source": [
    "# Bert Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a849c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# | export\n",
    "# Fix seed for experimenting\n",
    "import torch\n",
    "\n",
    "\n",
    "def manual_seed_all(\n",
    "    seed,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546b148-f35b-431f-a8a3-ef7810c1d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "\n",
    "# | export\n",
    "import os\n",
    "from random import (\n",
    "    shuffle,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from project.models.bert.model import (\n",
    "    BERT,\n",
    ")\n",
    "from project.utils.plot import (\n",
    "    LivePlot,\n",
    ")\n",
    "from torch import (\n",
    "    nn,\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    ")\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "def mask_theorem(\n",
    "    token_theorem,\n",
    "    tokenizer,\n",
    "    max_masked=40,\n",
    "):\n",
    "    theo_indices = []\n",
    "    for i in range(\n",
    "        1,\n",
    "        len(token_theorem),\n",
    "    ):  # don't mask [CLS] and [END] or spaces and new lines\n",
    "        if token_theorem[i] == tokenizer.sep_token_id:\n",
    "            break\n",
    "        theo_indices.append(i)\n",
    "\n",
    "    shuffle(theo_indices)\n",
    "    masked_poss = theo_indices[:max_masked]\n",
    "    masked_tokens = []\n",
    "    for i in masked_poss:\n",
    "        masked_tokens.append(token_theorem[i])\n",
    "        token_theorem[i] = tokenizer.mask_token_id\n",
    "    return (\n",
    "        token_theorem,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    )\n",
    "\n",
    "\n",
    "if \"tmp_data_dir\" in os.environ:\n",
    "    tmp_data_dir = os.environ[\"tmp_data_dir\"]\n",
    "else:\n",
    "    TMP_RELATIVE_DATA_PATH = \"../.tmp/data\"\n",
    "    notebook_path = os.getcwd()\n",
    "    tmp_data_dir = os.path.join(\n",
    "        notebook_path,\n",
    "        TMP_RELATIVE_DATA_PATH,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_from_json(\n",
    "    filename,\n",
    "):\n",
    "    print(f\"Loading: {filename}\")\n",
    "    with open(\n",
    "        filename,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_to_json(\n",
    "    data,\n",
    "    filename,\n",
    "):\n",
    "    print(f\"Saving: {filename}\")\n",
    "    with open(\n",
    "        filename,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            data,\n",
    "            f,\n",
    "        )\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    data_file,\n",
    "    max_masked=1,\n",
    "    batch_size=4,\n",
    "    max_length=1024,\n",
    "    cap_train_data=None,\n",
    "    tokenizer=None,\n",
    "):\n",
    "    batch = load_from_json(data_file)  # [(tokens, masked_tokens, masked_pos)]\n",
    "    if cap_train_data and cap_train_data > 0:\n",
    "        batch = batch[0:cap_train_data]\n",
    "\n",
    "    assert tokenizer is not None, \"Tokenizer is None, and must be provider\"\n",
    "\n",
    "    masked_batch = []\n",
    "    for theo in batch:\n",
    "        token_theorem = tokenizer.encode_plus(\n",
    "            theo,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        (\n",
    "            input_ids_list,\n",
    "            masked_tokens,\n",
    "            masked_poss,\n",
    "        ) = mask_theorem(\n",
    "            token_theorem[\"input_ids\"],\n",
    "            tokenizer,\n",
    "            max_masked=max_masked,\n",
    "        )\n",
    "        masked = torch.LongTensor(masked_tokens).cuda()\n",
    "        masked_poss = torch.LongTensor(masked_poss).cuda()\n",
    "        input_ids = torch.LongTensor(input_ids_list).cuda()\n",
    "        attention_mask = torch.LongTensor(token_theorem[\"attention_mask\"]).cuda()\n",
    "        masked_batch.append(\n",
    "            (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked,\n",
    "                masked_poss,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    (\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    ) = list(zip(*masked_batch))\n",
    "    input_ids = torch.stack(input_ids).squeeze(1)\n",
    "    attention_mask = torch.stack(attention_mask).squeeze(1)\n",
    "\n",
    "    masked_tokens = torch.stack(masked_tokens)\n",
    "    masked_poss = torch.stack(masked_poss)\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return (\n",
    "        dataloader,\n",
    "        tokenizer.vocab_size,\n",
    "    )\n",
    "\n",
    "\n",
    "class BERTEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_file,\n",
    "        tokenizer,\n",
    "        vocab_size,\n",
    "        num_heads=6,\n",
    "        n_layers=6,\n",
    "        d_model=1000,\n",
    "        max_length=1024,\n",
    "    ):\n",
    "        config = BertConfig(\n",
    "            vocab_size=vocab_size,\n",
    "            hidden_size=d_model,\n",
    "            num_hidden_layers=n_layers,\n",
    "            max_length=max_length,\n",
    "            num_attention_heads=num_heads,\n",
    "            intermediate_size=2048,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=max_length,\n",
    "            initializer_range=0.0001,\n",
    "        )\n",
    "\n",
    "        # Initialize the model\n",
    "        model = BertForMaskedLM(config).cuda()\n",
    "\n",
    "        # Load the state dictionary\n",
    "        state_dict = torch.load(model_file)\n",
    "\n",
    "        # Load this state dictionary into your BERT model\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        output_path,\n",
    "        dataloader_val,\n",
    "    ):\n",
    "        # Evaluate the model\n",
    "        minibatch_val_n = 0\n",
    "        running_accuracy = 0.0\n",
    "        n_batches_val = len(dataloader_val)\n",
    "        print(f\"==> Validating Epoch <==\")\n",
    "        progress: list[dict] = [{\"validation\": []}]\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked_tokens,\n",
    "                masked_poss,\n",
    "            ) in dataloader_val:\n",
    "                output = self.model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits = output.logits\n",
    "                mask_positions = torch.where(input_ids == self.tokenizer.mask_token_id)\n",
    "\n",
    "                # Extract logits for the [MASK] positions\n",
    "                mask_logits = logits[\n",
    "                    mask_positions[0],\n",
    "                    mask_positions[1],\n",
    "                    :,\n",
    "                ]\n",
    "                # Get the predicted token IDs for all [MASK] positions\n",
    "                predicted_token_ids = torch.argmax(\n",
    "                    mask_logits,\n",
    "                    dim=1,\n",
    "                )\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                predicted_tokens = [self.tokenizer.decode(token_id) for token_id in predicted_token_ids]\n",
    "\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                masked_logits = torch.gather(\n",
    "                    logits,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                accuracy = (predicted_token_ids == masked_tokens).float().mean().item()\n",
    "                running_accuracy += accuracy\n",
    "                predictions_list = []\n",
    "                for (\n",
    "                    p,\n",
    "                    l,\n",
    "                ) in zip(\n",
    "                    predicted_tokens,\n",
    "                    masked_tokens,\n",
    "                ):\n",
    "                    zipped_lp = zip(\n",
    "                        l,\n",
    "                        p,\n",
    "                    )\n",
    "                    predict = [\n",
    "                        (\n",
    "                            \"\".join(self.tokenizer.decode(ll)),\n",
    "                            \"\".join(pp),\n",
    "                        )\n",
    "                        for ll, pp in zipped_lp\n",
    "                    ]\n",
    "                    predictions_list.append(\" @ \".join([f\"{pr[0]}<>{pr[1]})\" for pr in predict]))\n",
    "                print(f\"Validation Minibatch: {minibatch_val_n}, Accuracy: {accuracy}, Accum Accuracy: {running_accuracy}\")\n",
    "                prediction_str = \" # \".join(predictions_list)\n",
    "                print(\n",
    "                    \"Predictions: \",\n",
    "                    prediction_str,\n",
    "                )\n",
    "                progress[-1][\"validation\"].append(\n",
    "                    {\n",
    "                        \"predictions\": prediction_str,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"acum_accuracy\": running_accuracy,\n",
    "                    }\n",
    "                )\n",
    "                minibatch_val_n += 1\n",
    "            total_accuracy = running_accuracy / n_batches_val\n",
    "            save_to_json(\n",
    "                {\"accuracy\": total_accuracy},\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    \"evaluation.json\",\n",
    "                ),\n",
    "            )\n",
    "            return total_accuracy\n",
    "\n",
    "\n",
    "class BERTTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataloader,\n",
    "        dataloader_val,\n",
    "        vocab_size,\n",
    "        num_heads=6,\n",
    "        n_layers=6,\n",
    "        d_model=1000,\n",
    "        max_length=1024,\n",
    "        tokenizer=None,\n",
    "        criterion=None,\n",
    "        optimizer=torch.optim.SGD,\n",
    "        gradient_accumulation_steps=1,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.num_heads = num_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        assert tokenizer is not None, \"Tokenizer is None, and must be provider\"\n",
    "        assert criterion is not None, \"Criterion is None, and must be provider\"\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        print(\"Create BERTodel\")\n",
    "        config = BertConfig(\n",
    "            vocab_size=vocab_size,\n",
    "            hidden_size=d_model,\n",
    "            num_hidden_layers=n_layers,\n",
    "            max_length=max_length,\n",
    "            num_attention_heads=num_heads,\n",
    "            intermediate_size=2048,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=max_length,\n",
    "            initializer_range=0.0001,\n",
    "        )\n",
    "\n",
    "        model = BertForMaskedLM(config).cuda()\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_val = dataloader_val\n",
    "\n",
    "        print(\n",
    "            \"Current GPU memory usage:\",\n",
    "            torch.cuda.memory_allocated(),\n",
    "        )\n",
    "        print(\n",
    "            \"Maximum GPU memory usage:\",\n",
    "            torch.cuda.max_memory_allocated(),\n",
    "        )\n",
    "\n",
    "        self.criterion = criterion.cuda()\n",
    "        self.optimizer = optimizer(\n",
    "            model.parameters(),\n",
    "            lr=0.001,\n",
    "        )  # torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Number of parameters: {num_params/(1000000)} Millions\")\n",
    "\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        output_path,\n",
    "        dataloader_val,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        criterion,\n",
    "        progress,\n",
    "        epoch=0,\n",
    "        train_loss=0,\n",
    "    ):\n",
    "        # Evaluate the model\n",
    "        minibatch_val_n = 0\n",
    "        accum_val_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        n_batches_val = len(dataloader_val)\n",
    "        print(f\"==> Validating Epoch {epoch} <==\")\n",
    "        model.eval()\n",
    "        progress.append({\"validation\": []})\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked_tokens,\n",
    "                masked_poss,\n",
    "            ) in dataloader_val:\n",
    "                output = model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits = output.logits\n",
    "                mask_positions = torch.where(input_ids == tokenizer.mask_token_id)\n",
    "\n",
    "                # Extract logits for the [MASK] positions\n",
    "                mask_logits = logits[\n",
    "                    mask_positions[0],\n",
    "                    mask_positions[1],\n",
    "                    :,\n",
    "                ]\n",
    "                # Get the predicted token IDs for all [MASK] positions\n",
    "                predicted_token_ids = torch.argmax(\n",
    "                    mask_logits,\n",
    "                    dim=1,\n",
    "                )\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                predicted_tokens = [tokenizer.decode(token_id) for token_id in predicted_token_ids]\n",
    "\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                masked_logits = torch.gather(\n",
    "                    logits,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                loss_lm = criterion(\n",
    "                    masked_logits.transpose(\n",
    "                        1,\n",
    "                        2,\n",
    "                    ),\n",
    "                    masked_tokens,\n",
    "                )\n",
    "                loss_lm = (loss_lm.float()).mean()\n",
    "                accum_val_loss += loss_lm.item()\n",
    "                accuracy = (predicted_token_ids == masked_tokens).float().mean().item()\n",
    "                running_accuracy += accuracy\n",
    "                predictions_list = []\n",
    "                for (\n",
    "                    p,\n",
    "                    l,\n",
    "                ) in zip(\n",
    "                    predicted_tokens,\n",
    "                    masked_tokens,\n",
    "                ):\n",
    "                    zipped_lp = zip(\n",
    "                        l,\n",
    "                        p,\n",
    "                    )\n",
    "                    predict = [\n",
    "                        (\n",
    "                            \"\".join(tokenizer.decode(ll)),\n",
    "                            \"\".join(pp),\n",
    "                        )\n",
    "                        for ll, pp in zipped_lp\n",
    "                    ]\n",
    "                    predictions_list.append(\" @ \".join([f\"{pr[0]}<>{pr[1]})\" for pr in predict]))\n",
    "                print(f\"Validation Epoch: {epoch}, Validation Minibatch: {minibatch_val_n}, Validation Loss: {loss_lm.item()}, Accuracy: {accuracy}, Accum Accuracy: {running_accuracy}\")\n",
    "                prediction_str = \" # \".join(predictions_list)\n",
    "                progress[-1][\"validation\"].append(\n",
    "                    {\n",
    "                        \"predictions\": prediction_str,\n",
    "                        \"eval_loss\": loss_lm.item(),\n",
    "                        \"mean_train_loss\": train_loss,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"acum_accuracy\": running_accuracy,\n",
    "                    }\n",
    "                )\n",
    "                minibatch_val_n += 1\n",
    "            return (\n",
    "                accum_val_loss,\n",
    "                running_accuracy,\n",
    "                n_batches_val,\n",
    "            )\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        lr=0.001,\n",
    "        epochs=20,\n",
    "        output_path=None,\n",
    "        graph=False,\n",
    "    ):\n",
    "        if not output_path:\n",
    "            output_path = \"./\"\n",
    "\n",
    "        print(f\"Output path: {output_path}\")\n",
    "        torch.cuda.set_device(0)\n",
    "        data_plot_loss = collections.defaultdict(list)\n",
    "        data_plot_accuracy = collections.defaultdict(list)\n",
    "        live_plot_loss = LivePlot()\n",
    "        train_summary: dict = {\n",
    "            \"epoch_summary\": [],\n",
    "            \"metadata\": {\n",
    "                \"lr\": lr,\n",
    "                \"ds_model\": self.d_model,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"n_layers\": self.n_layers,\n",
    "            },\n",
    "        }\n",
    "        progress: list = []\n",
    "        n_batches = len(self.dataloader)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"==> Training Epoch {epoch} <==\")\n",
    "            train_loss_acum = 0\n",
    "            self.model.train()\n",
    "            for (\n",
    "                step,\n",
    "                (\n",
    "                    input_ids,\n",
    "                    attention_mask,\n",
    "                    masked_tokens,\n",
    "                    masked_poss,\n",
    "                ),\n",
    "            ) in enumerate(self.dataloader):\n",
    "                output = self.model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits_lm = output.logits\n",
    "                masked_logits = torch.gather(\n",
    "                    logits_lm,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits_lm.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                loss_lm = self.criterion(\n",
    "                    masked_logits.transpose(\n",
    "                        1,\n",
    "                        2,\n",
    "                    ),\n",
    "                    masked_tokens,\n",
    "                )\n",
    "                loss_lm = (loss_lm.float()).mean()\n",
    "                loss_lm.backward()\n",
    "                loss_value = loss_lm.item()\n",
    "                train_loss_acum += loss_value\n",
    "\n",
    "                data_plot_loss[f\"Epoch-{epoch}\"].append(loss_value)\n",
    "                if graph:\n",
    "                    live_plot_loss.plot(data_plot_loss)\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.model.zero_grad()\n",
    "                if (step + 1) % 5 == 0:\n",
    "                    print(f\"Epoch: {epoch}, Step: {step+1}, Loss: {loss_value}\")\n",
    "\n",
    "            train_loss = train_loss_acum / n_batches\n",
    "\n",
    "            (\n",
    "                accum_val_loss,\n",
    "                running_accuracy,\n",
    "                n_batches_val,\n",
    "            ) = self.evaluate(\n",
    "                output_path,\n",
    "                self.dataloader_val,\n",
    "                self.model,\n",
    "                self.tokenizer,\n",
    "                self.criterion,\n",
    "                progress,\n",
    "                epoch,\n",
    "            )\n",
    "            save_to_json(\n",
    "                progress,\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"train-validation.json\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            mean_val_loss = accum_val_loss / n_batches_val\n",
    "            mean_val_accuracy = running_accuracy / n_batches_val\n",
    "            train_summary[\"epoch_summary\"].append(  # type: ignore\n",
    "                {\n",
    "                    \"mean_validation_loss\": mean_val_loss,\n",
    "                    \"mean_train_loss\": train_loss,\n",
    "                    \"mean_accuracy\": mean_val_accuracy,\n",
    "                }\n",
    "            )\n",
    "            save_to_json(\n",
    "                train_summary,\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"train-summary.json\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"Saving model for Epoch [{}], Validatoin Loss: {:.4f}, Mean Accuracy: {} \".format(\n",
    "                    epoch,\n",
    "                    mean_val_loss,\n",
    "                    mean_val_accuracy,\n",
    "                )\n",
    "            )\n",
    "            torch.save(\n",
    "                self.model.state_dict(),\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"bert.pth\",\n",
    "                ),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44a56",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b2584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 1000, Loss: 3.6355597972869873\n",
      "==> Validating Epoch 1 <==\n",
      "Validation Epoch: 1, Validation Minibatch: 0, Validation Loss: 3.2343013286590576, Accuracy: 0.19999998807907104, Accum Accuracy: 0.19999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 1, Validation Loss: 3.677597761154175, Accuracy: 0.0, Accum Accuracy: 0.19999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 2, Validation Loss: 3.299574613571167, Accuracy: 0.0, Accum Accuracy: 0.19999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 3, Validation Loss: 3.256929874420166, Accuracy: 0.0, Accum Accuracy: 0.19999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 4, Validation Loss: 3.207672119140625, Accuracy: 0.19999998807907104, Accum Accuracy: 0.3999999761581421\n",
      "Validation Epoch: 1, Validation Minibatch: 5, Validation Loss: 3.880948305130005, Accuracy: 0.09999999403953552, Accum Accuracy: 0.4999999701976776\n",
      "Validation Epoch: 1, Validation Minibatch: 6, Validation Loss: 3.7362587451934814, Accuracy: 0.09999999403953552, Accum Accuracy: 0.5999999642372131\n",
      "Validation Epoch: 1, Validation Minibatch: 7, Validation Loss: 4.268131256103516, Accuracy: 0.09999999403953552, Accum Accuracy: 0.6999999582767487\n",
      "Validation Epoch: 1, Validation Minibatch: 8, Validation Loss: 4.214645862579346, Accuracy: 0.09999999403953552, Accum Accuracy: 0.7999999523162842\n",
      "Validation Epoch: 1, Validation Minibatch: 9, Validation Loss: 3.20231294631958, Accuracy: 0.09999999403953552, Accum Accuracy: 0.8999999463558197\n",
      "Validation Epoch: 1, Validation Minibatch: 10, Validation Loss: 3.61279034614563, Accuracy: 0.19999998807907104, Accum Accuracy: 1.0999999344348907\n",
      "Validation Epoch: 1, Validation Minibatch: 11, Validation Loss: 3.5880725383758545, Accuracy: 0.09999999403953552, Accum Accuracy: 1.1999999284744263\n",
      "Validation Epoch: 1, Validation Minibatch: 12, Validation Loss: 4.318830966949463, Accuracy: 0.0, Accum Accuracy: 1.1999999284744263\n",
      "Validation Epoch: 1, Validation Minibatch: 13, Validation Loss: 4.037595748901367, Accuracy: 0.09999999403953552, Accum Accuracy: 1.2999999225139618\n",
      "Validation Epoch: 1, Validation Minibatch: 14, Validation Loss: 3.319235324859619, Accuracy: 0.09999999403953552, Accum Accuracy: 1.3999999165534973\n",
      "Validation Epoch: 1, Validation Minibatch: 15, Validation Loss: 4.302137851715088, Accuracy: 0.09999999403953552, Accum Accuracy: 1.4999999105930328\n",
      "Validation Epoch: 1, Validation Minibatch: 16, Validation Loss: 3.591214656829834, Accuracy: 0.0, Accum Accuracy: 1.4999999105930328\n",
      "Validation Epoch: 1, Validation Minibatch: 17, Validation Loss: 2.905627727508545, Accuracy: 0.29999998211860657, Accum Accuracy: 1.7999998927116394\n",
      "Validation Epoch: 1, Validation Minibatch: 18, Validation Loss: 4.28706169128418, Accuracy: 0.09999999403953552, Accum Accuracy: 1.899999886751175\n",
      "Validation Epoch: 1, Validation Minibatch: 19, Validation Loss: 3.4971375465393066, Accuracy: 0.09999999403953552, Accum Accuracy: 1.9999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 20, Validation Loss: 4.29953670501709, Accuracy: 0.0, Accum Accuracy: 1.9999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 21, Validation Loss: 3.960318088531494, Accuracy: 0.0, Accum Accuracy: 1.9999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 22, Validation Loss: 3.3239874839782715, Accuracy: 0.09999999403953552, Accum Accuracy: 2.099999874830246\n",
      "Validation Epoch: 1, Validation Minibatch: 23, Validation Loss: 4.373054504394531, Accuracy: 0.09999999403953552, Accum Accuracy: 2.1999998688697815\n",
      "Validation Epoch: 1, Validation Minibatch: 24, Validation Loss: 3.207338809967041, Accuracy: 0.19999998807907104, Accum Accuracy: 2.3999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 25, Validation Loss: 3.2764949798583984, Accuracy: 0.0, Accum Accuracy: 2.3999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 26, Validation Loss: 3.569326877593994, Accuracy: 0.0, Accum Accuracy: 2.3999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 27, Validation Loss: 4.6283464431762695, Accuracy: 0.0, Accum Accuracy: 2.3999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 28, Validation Loss: 3.9547157287597656, Accuracy: 0.0, Accum Accuracy: 2.3999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 29, Validation Loss: 4.263089179992676, Accuracy: 0.09999999403953552, Accum Accuracy: 2.499999850988388\n",
      "Validation Epoch: 1, Validation Minibatch: 30, Validation Loss: 3.2741246223449707, Accuracy: 0.19999998807907104, Accum Accuracy: 2.699999839067459\n",
      "Validation Epoch: 1, Validation Minibatch: 31, Validation Loss: 4.3735880851745605, Accuracy: 0.0, Accum Accuracy: 2.699999839067459\n",
      "Validation Epoch: 1, Validation Minibatch: 32, Validation Loss: 4.409625053405762, Accuracy: 0.0, Accum Accuracy: 2.699999839067459\n",
      "Validation Epoch: 1, Validation Minibatch: 33, Validation Loss: 3.5854079723358154, Accuracy: 0.09999999403953552, Accum Accuracy: 2.7999998331069946\n",
      "Validation Epoch: 1, Validation Minibatch: 34, Validation Loss: 4.18729305267334, Accuracy: 0.0, Accum Accuracy: 2.7999998331069946\n",
      "Validation Epoch: 1, Validation Minibatch: 35, Validation Loss: 4.230835914611816, Accuracy: 0.0, Accum Accuracy: 2.7999998331069946\n",
      "Validation Epoch: 1, Validation Minibatch: 36, Validation Loss: 3.882606029510498, Accuracy: 0.19999998807907104, Accum Accuracy: 2.9999998211860657\n",
      "Validation Epoch: 1, Validation Minibatch: 37, Validation Loss: 4.282764434814453, Accuracy: 0.0, Accum Accuracy: 2.9999998211860657\n",
      "Validation Epoch: 1, Validation Minibatch: 38, Validation Loss: 3.377324342727661, Accuracy: 0.09999999403953552, Accum Accuracy: 3.099999815225601\n",
      "Validation Epoch: 1, Validation Minibatch: 39, Validation Loss: 4.397417068481445, Accuracy: 0.19999998807907104, Accum Accuracy: 3.2999998033046722\n",
      "Validation Epoch: 1, Validation Minibatch: 40, Validation Loss: 3.6125845909118652, Accuracy: 0.09999999403953552, Accum Accuracy: 3.3999997973442078\n",
      "Validation Epoch: 1, Validation Minibatch: 41, Validation Loss: 4.029677391052246, Accuracy: 0.0, Accum Accuracy: 3.3999997973442078\n",
      "Validation Epoch: 1, Validation Minibatch: 42, Validation Loss: 4.6170783042907715, Accuracy: 0.09999999403953552, Accum Accuracy: 3.4999997913837433\n",
      "Validation Epoch: 1, Validation Minibatch: 43, Validation Loss: 3.72467303276062, Accuracy: 0.09999999403953552, Accum Accuracy: 3.599999785423279\n",
      "Validation Epoch: 1, Validation Minibatch: 44, Validation Loss: 3.90437388420105, Accuracy: 0.09999999403953552, Accum Accuracy: 3.6999997794628143\n",
      "Validation Epoch: 1, Validation Minibatch: 45, Validation Loss: 3.257533550262451, Accuracy: 0.0, Accum Accuracy: 3.6999997794628143\n",
      "Validation Epoch: 1, Validation Minibatch: 46, Validation Loss: 2.8260462284088135, Accuracy: 0.09999999403953552, Accum Accuracy: 3.79999977350235\n",
      "Validation Epoch: 1, Validation Minibatch: 47, Validation Loss: 3.7298011779785156, Accuracy: 0.19999998807907104, Accum Accuracy: 3.999999761581421\n",
      "Validation Epoch: 1, Validation Minibatch: 48, Validation Loss: 3.4267890453338623, Accuracy: 0.0, Accum Accuracy: 3.999999761581421\n",
      "Validation Epoch: 1, Validation Minibatch: 49, Validation Loss: 3.1832504272460938, Accuracy: 0.09999999403953552, Accum Accuracy: 4.099999755620956\n",
      "Validation Epoch: 1, Validation Minibatch: 50, Validation Loss: 3.5187020301818848, Accuracy: 0.09999999403953552, Accum Accuracy: 4.199999749660492\n",
      "Validation Epoch: 1, Validation Minibatch: 51, Validation Loss: 3.0342655181884766, Accuracy: 0.09999999403953552, Accum Accuracy: 4.2999997437000275\n",
      "Validation Epoch: 1, Validation Minibatch: 52, Validation Loss: 4.740547180175781, Accuracy: 0.0, Accum Accuracy: 4.2999997437000275\n",
      "Validation Epoch: 1, Validation Minibatch: 53, Validation Loss: 3.263876438140869, Accuracy: 0.19999998807907104, Accum Accuracy: 4.4999997317790985\n",
      "Validation Epoch: 1, Validation Minibatch: 54, Validation Loss: 4.004879474639893, Accuracy: 0.09999999403953552, Accum Accuracy: 4.599999725818634\n",
      "Validation Epoch: 1, Validation Minibatch: 55, Validation Loss: 3.710120677947998, Accuracy: 0.19999998807907104, Accum Accuracy: 4.799999713897705\n",
      "Validation Epoch: 1, Validation Minibatch: 56, Validation Loss: 3.8740646839141846, Accuracy: 0.09999999403953552, Accum Accuracy: 4.899999707937241\n",
      "Validation Epoch: 1, Validation Minibatch: 57, Validation Loss: 4.54350471496582, Accuracy: 0.09999999403953552, Accum Accuracy: 4.999999701976776\n",
      "Validation Epoch: 1, Validation Minibatch: 58, Validation Loss: 4.007885456085205, Accuracy: 0.19999998807907104, Accum Accuracy: 5.199999690055847\n",
      "Validation Epoch: 1, Validation Minibatch: 59, Validation Loss: 3.6856627464294434, Accuracy: 0.0, Accum Accuracy: 5.199999690055847\n",
      "Validation Epoch: 1, Validation Minibatch: 60, Validation Loss: 3.4471917152404785, Accuracy: 0.19999998807907104, Accum Accuracy: 5.399999678134918\n",
      "Validation Epoch: 1, Validation Minibatch: 61, Validation Loss: 4.164515018463135, Accuracy: 0.09999999403953552, Accum Accuracy: 5.499999672174454\n",
      "Validation Epoch: 1, Validation Minibatch: 62, Validation Loss: 3.622756242752075, Accuracy: 0.0, Accum Accuracy: 5.499999672174454\n",
      "Validation Epoch: 1, Validation Minibatch: 63, Validation Loss: 4.04971170425415, Accuracy: 0.09999999403953552, Accum Accuracy: 5.599999666213989\n",
      "Validation Epoch: 1, Validation Minibatch: 64, Validation Loss: 3.823608875274658, Accuracy: 0.09999999403953552, Accum Accuracy: 5.699999660253525\n",
      "Validation Epoch: 1, Validation Minibatch: 65, Validation Loss: 3.9706790447235107, Accuracy: 0.0, Accum Accuracy: 5.699999660253525\n",
      "Validation Epoch: 1, Validation Minibatch: 66, Validation Loss: 3.224412202835083, Accuracy: 0.3999999761581421, Accum Accuracy: 6.099999636411667\n",
      "Validation Epoch: 1, Validation Minibatch: 67, Validation Loss: 3.2405924797058105, Accuracy: 0.09999999403953552, Accum Accuracy: 6.199999630451202\n",
      "Validation Epoch: 1, Validation Minibatch: 68, Validation Loss: 3.389523983001709, Accuracy: 0.0, Accum Accuracy: 6.199999630451202\n",
      "Validation Epoch: 1, Validation Minibatch: 69, Validation Loss: 3.6489360332489014, Accuracy: 0.09999999403953552, Accum Accuracy: 6.299999624490738\n",
      "Validation Epoch: 1, Validation Minibatch: 70, Validation Loss: 4.920291900634766, Accuracy: 0.0, Accum Accuracy: 6.299999624490738\n",
      "Validation Epoch: 1, Validation Minibatch: 71, Validation Loss: 3.8516197204589844, Accuracy: 0.0, Accum Accuracy: 6.299999624490738\n",
      "Validation Epoch: 1, Validation Minibatch: 72, Validation Loss: 3.6303164958953857, Accuracy: 0.09999999403953552, Accum Accuracy: 6.399999618530273\n",
      "Validation Epoch: 1, Validation Minibatch: 73, Validation Loss: 3.7212092876434326, Accuracy: 0.0, Accum Accuracy: 6.399999618530273\n",
      "Validation Epoch: 1, Validation Minibatch: 74, Validation Loss: 3.3527557849884033, Accuracy: 0.0, Accum Accuracy: 6.399999618530273\n",
      "Validation Epoch: 1, Validation Minibatch: 75, Validation Loss: 3.735079288482666, Accuracy: 0.0, Accum Accuracy: 6.399999618530273\n",
      "Validation Epoch: 1, Validation Minibatch: 76, Validation Loss: 3.0311272144317627, Accuracy: 0.09999999403953552, Accum Accuracy: 6.499999612569809\n",
      "Validation Epoch: 1, Validation Minibatch: 77, Validation Loss: 3.166912078857422, Accuracy: 0.19999998807907104, Accum Accuracy: 6.69999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 78, Validation Loss: 3.8831684589385986, Accuracy: 0.0, Accum Accuracy: 6.69999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 79, Validation Loss: 3.7946419715881348, Accuracy: 0.19999998807907104, Accum Accuracy: 6.899999588727951\n",
      "Validation Epoch: 1, Validation Minibatch: 80, Validation Loss: 3.3226571083068848, Accuracy: 0.19999998807907104, Accum Accuracy: 7.099999576807022\n",
      "Validation Epoch: 1, Validation Minibatch: 81, Validation Loss: 3.283809185028076, Accuracy: 0.09999999403953552, Accum Accuracy: 7.199999570846558\n",
      "Validation Epoch: 1, Validation Minibatch: 82, Validation Loss: 3.8738505840301514, Accuracy: 0.09999999403953552, Accum Accuracy: 7.299999564886093\n",
      "Validation Epoch: 1, Validation Minibatch: 83, Validation Loss: 3.885749101638794, Accuracy: 0.19999998807907104, Accum Accuracy: 7.499999552965164\n",
      "Validation Epoch: 1, Validation Minibatch: 84, Validation Loss: 3.4489734172821045, Accuracy: 0.09999999403953552, Accum Accuracy: 7.5999995470047\n",
      "Validation Epoch: 1, Validation Minibatch: 85, Validation Loss: 4.111634731292725, Accuracy: 0.0, Accum Accuracy: 7.5999995470047\n",
      "Validation Epoch: 1, Validation Minibatch: 86, Validation Loss: 4.077834129333496, Accuracy: 0.0, Accum Accuracy: 7.5999995470047\n",
      "Validation Epoch: 1, Validation Minibatch: 87, Validation Loss: 3.596670150756836, Accuracy: 0.09999999403953552, Accum Accuracy: 7.699999541044235\n",
      "Validation Epoch: 1, Validation Minibatch: 88, Validation Loss: 3.4067320823669434, Accuracy: 0.09999999403953552, Accum Accuracy: 7.799999535083771\n",
      "Validation Epoch: 1, Validation Minibatch: 89, Validation Loss: 3.9770500659942627, Accuracy: 0.19999998807907104, Accum Accuracy: 7.999999523162842\n",
      "Validation Epoch: 1, Validation Minibatch: 90, Validation Loss: 3.5170950889587402, Accuracy: 0.19999998807907104, Accum Accuracy: 8.199999511241913\n",
      "Validation Epoch: 1, Validation Minibatch: 91, Validation Loss: 3.6503424644470215, Accuracy: 0.19999998807907104, Accum Accuracy: 8.399999499320984\n",
      "Validation Epoch: 1, Validation Minibatch: 92, Validation Loss: 3.3429229259490967, Accuracy: 0.29999998211860657, Accum Accuracy: 8.69999948143959\n",
      "Validation Epoch: 1, Validation Minibatch: 93, Validation Loss: 3.6349740028381348, Accuracy: 0.09999999403953552, Accum Accuracy: 8.799999475479126\n",
      "Validation Epoch: 1, Validation Minibatch: 94, Validation Loss: 3.9740231037139893, Accuracy: 0.0, Accum Accuracy: 8.799999475479126\n",
      "Validation Epoch: 1, Validation Minibatch: 95, Validation Loss: 3.262737989425659, Accuracy: 0.09999999403953552, Accum Accuracy: 8.899999469518661\n",
      "Validation Epoch: 1, Validation Minibatch: 96, Validation Loss: 3.393322706222534, Accuracy: 0.19999998807907104, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 97, Validation Loss: 4.120882511138916, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 98, Validation Loss: 4.1302666664123535, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 99, Validation Loss: 3.212970733642578, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 100, Validation Loss: 3.7859249114990234, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 101, Validation Loss: 3.3240318298339844, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 102, Validation Loss: 3.118561267852783, Accuracy: 0.0, Accum Accuracy: 9.099999457597733\n",
      "Validation Epoch: 1, Validation Minibatch: 103, Validation Loss: 3.4789223670959473, Accuracy: 0.29999998211860657, Accum Accuracy: 9.399999439716339\n",
      "Validation Epoch: 1, Validation Minibatch: 104, Validation Loss: 4.159252643585205, Accuracy: 0.0, Accum Accuracy: 9.399999439716339\n",
      "Validation Epoch: 1, Validation Minibatch: 105, Validation Loss: 3.04128360748291, Accuracy: 0.09999999403953552, Accum Accuracy: 9.499999433755875\n",
      "Validation Epoch: 1, Validation Minibatch: 106, Validation Loss: 2.947566509246826, Accuracy: 0.19999998807907104, Accum Accuracy: 9.699999421834946\n",
      "Validation Epoch: 1, Validation Minibatch: 107, Validation Loss: 4.201987266540527, Accuracy: 0.09999999403953552, Accum Accuracy: 9.799999415874481\n",
      "Validation Epoch: 1, Validation Minibatch: 108, Validation Loss: 3.948148012161255, Accuracy: 0.0, Accum Accuracy: 9.799999415874481\n",
      "Validation Epoch: 1, Validation Minibatch: 109, Validation Loss: 3.2662627696990967, Accuracy: 0.19999998807907104, Accum Accuracy: 9.999999403953552\n",
      "Validation Epoch: 1, Validation Minibatch: 110, Validation Loss: 3.787813663482666, Accuracy: 0.0, Accum Accuracy: 9.999999403953552\n",
      "Validation Epoch: 1, Validation Minibatch: 111, Validation Loss: 3.7959563732147217, Accuracy: 0.09999999403953552, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 112, Validation Loss: 3.3796138763427734, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 113, Validation Loss: 4.393157482147217, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 114, Validation Loss: 4.303543567657471, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 115, Validation Loss: 4.19912576675415, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 116, Validation Loss: 3.633820056915283, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 117, Validation Loss: 3.6488544940948486, Accuracy: 0.0, Accum Accuracy: 10.099999397993088\n",
      "Validation Epoch: 1, Validation Minibatch: 118, Validation Loss: 4.263086795806885, Accuracy: 0.09999999403953552, Accum Accuracy: 10.199999392032623\n",
      "Validation Epoch: 1, Validation Minibatch: 119, Validation Loss: 3.649151563644409, Accuracy: 0.19999998807907104, Accum Accuracy: 10.399999380111694\n",
      "Validation Epoch: 1, Validation Minibatch: 120, Validation Loss: 3.856288194656372, Accuracy: 0.09999999403953552, Accum Accuracy: 10.49999937415123\n",
      "Validation Epoch: 1, Validation Minibatch: 121, Validation Loss: 3.1205875873565674, Accuracy: 0.19999998807907104, Accum Accuracy: 10.699999362230301\n",
      "Validation Epoch: 1, Validation Minibatch: 122, Validation Loss: 3.492694854736328, Accuracy: 0.09999999403953552, Accum Accuracy: 10.799999356269836\n",
      "Validation Epoch: 1, Validation Minibatch: 123, Validation Loss: 3.7422213554382324, Accuracy: 0.0, Accum Accuracy: 10.799999356269836\n",
      "Validation Epoch: 1, Validation Minibatch: 124, Validation Loss: 3.30009126663208, Accuracy: 0.09999999403953552, Accum Accuracy: 10.899999350309372\n",
      "Validation Epoch: 1, Validation Minibatch: 125, Validation Loss: 3.858402967453003, Accuracy: 0.09999999403953552, Accum Accuracy: 10.999999344348907\n",
      "Validation Epoch: 1, Validation Minibatch: 126, Validation Loss: 3.580155849456787, Accuracy: 0.0, Accum Accuracy: 10.999999344348907\n",
      "Validation Epoch: 1, Validation Minibatch: 127, Validation Loss: 3.8179287910461426, Accuracy: 0.09999999403953552, Accum Accuracy: 11.099999338388443\n",
      "Validation Epoch: 1, Validation Minibatch: 128, Validation Loss: 3.557168483734131, Accuracy: 0.0, Accum Accuracy: 11.099999338388443\n",
      "Validation Epoch: 1, Validation Minibatch: 129, Validation Loss: 4.229768753051758, Accuracy: 0.09999999403953552, Accum Accuracy: 11.199999332427979\n",
      "Validation Epoch: 1, Validation Minibatch: 130, Validation Loss: 3.2806153297424316, Accuracy: 0.0, Accum Accuracy: 11.199999332427979\n",
      "Validation Epoch: 1, Validation Minibatch: 131, Validation Loss: 3.6104443073272705, Accuracy: 0.09999999403953552, Accum Accuracy: 11.299999326467514\n",
      "Validation Epoch: 1, Validation Minibatch: 132, Validation Loss: 3.368765354156494, Accuracy: 0.0, Accum Accuracy: 11.299999326467514\n",
      "Validation Epoch: 1, Validation Minibatch: 133, Validation Loss: 3.823646068572998, Accuracy: 0.0, Accum Accuracy: 11.299999326467514\n",
      "Validation Epoch: 1, Validation Minibatch: 134, Validation Loss: 3.079418420791626, Accuracy: 0.09999999403953552, Accum Accuracy: 11.39999932050705\n",
      "Validation Epoch: 1, Validation Minibatch: 135, Validation Loss: 3.6857733726501465, Accuracy: 0.19999998807907104, Accum Accuracy: 11.59999930858612\n",
      "Validation Epoch: 1, Validation Minibatch: 136, Validation Loss: 3.6410012245178223, Accuracy: 0.09999999403953552, Accum Accuracy: 11.699999302625656\n",
      "Validation Epoch: 1, Validation Minibatch: 137, Validation Loss: 2.7315688133239746, Accuracy: 0.19999998807907104, Accum Accuracy: 11.899999290704727\n",
      "Validation Epoch: 1, Validation Minibatch: 138, Validation Loss: 4.317124366760254, Accuracy: 0.0, Accum Accuracy: 11.899999290704727\n",
      "Validation Epoch: 1, Validation Minibatch: 139, Validation Loss: 4.2037153244018555, Accuracy: 0.0, Accum Accuracy: 11.899999290704727\n",
      "Validation Epoch: 1, Validation Minibatch: 140, Validation Loss: 3.6734912395477295, Accuracy: 0.0, Accum Accuracy: 11.899999290704727\n",
      "Validation Epoch: 1, Validation Minibatch: 141, Validation Loss: 3.696091890335083, Accuracy: 0.19999998807907104, Accum Accuracy: 12.099999278783798\n",
      "Validation Epoch: 1, Validation Minibatch: 142, Validation Loss: 3.2892284393310547, Accuracy: 0.0, Accum Accuracy: 12.099999278783798\n",
      "Validation Epoch: 1, Validation Minibatch: 143, Validation Loss: 3.1444497108459473, Accuracy: 0.09999999403953552, Accum Accuracy: 12.199999272823334\n",
      "Validation Epoch: 1, Validation Minibatch: 144, Validation Loss: 4.640834331512451, Accuracy: 0.29999998211860657, Accum Accuracy: 12.49999925494194\n",
      "Validation Epoch: 1, Validation Minibatch: 145, Validation Loss: 3.8082244396209717, Accuracy: 0.0, Accum Accuracy: 12.49999925494194\n",
      "Validation Epoch: 1, Validation Minibatch: 146, Validation Loss: 3.2170703411102295, Accuracy: 0.19999998807907104, Accum Accuracy: 12.699999243021011\n",
      "Validation Epoch: 1, Validation Minibatch: 147, Validation Loss: 3.980250835418701, Accuracy: 0.0, Accum Accuracy: 12.699999243021011\n",
      "Validation Epoch: 1, Validation Minibatch: 148, Validation Loss: 3.8398399353027344, Accuracy: 0.0, Accum Accuracy: 12.699999243021011\n",
      "Validation Epoch: 1, Validation Minibatch: 149, Validation Loss: 3.044146776199341, Accuracy: 0.09999999403953552, Accum Accuracy: 12.799999237060547\n",
      "Validation Epoch: 1, Validation Minibatch: 150, Validation Loss: 3.411754608154297, Accuracy: 0.19999998807907104, Accum Accuracy: 12.999999225139618\n",
      "Validation Epoch: 1, Validation Minibatch: 151, Validation Loss: 3.3943355083465576, Accuracy: 0.0, Accum Accuracy: 12.999999225139618\n",
      "Validation Epoch: 1, Validation Minibatch: 152, Validation Loss: 3.807378053665161, Accuracy: 0.0, Accum Accuracy: 12.999999225139618\n",
      "Validation Epoch: 1, Validation Minibatch: 153, Validation Loss: 4.043997764587402, Accuracy: 0.0, Accum Accuracy: 12.999999225139618\n",
      "Validation Epoch: 1, Validation Minibatch: 154, Validation Loss: 3.219552993774414, Accuracy: 0.09999999403953552, Accum Accuracy: 13.099999219179153\n",
      "Validation Epoch: 1, Validation Minibatch: 155, Validation Loss: 3.301884174346924, Accuracy: 0.19999998807907104, Accum Accuracy: 13.299999207258224\n",
      "Validation Epoch: 1, Validation Minibatch: 156, Validation Loss: 4.093231201171875, Accuracy: 0.09999999403953552, Accum Accuracy: 13.39999920129776\n",
      "Validation Epoch: 1, Validation Minibatch: 157, Validation Loss: 3.7435810565948486, Accuracy: 0.09999999403953552, Accum Accuracy: 13.499999195337296\n",
      "Validation Epoch: 1, Validation Minibatch: 158, Validation Loss: 3.4092133045196533, Accuracy: 0.09999999403953552, Accum Accuracy: 13.599999189376831\n",
      "Validation Epoch: 1, Validation Minibatch: 159, Validation Loss: 3.621051073074341, Accuracy: 0.0, Accum Accuracy: 13.599999189376831\n",
      "Validation Epoch: 1, Validation Minibatch: 160, Validation Loss: 3.8686130046844482, Accuracy: 0.09999999403953552, Accum Accuracy: 13.699999183416367\n",
      "Validation Epoch: 1, Validation Minibatch: 161, Validation Loss: 3.220615863800049, Accuracy: 0.09999999403953552, Accum Accuracy: 13.799999177455902\n",
      "Validation Epoch: 1, Validation Minibatch: 162, Validation Loss: 4.488274097442627, Accuracy: 0.0, Accum Accuracy: 13.799999177455902\n",
      "Validation Epoch: 1, Validation Minibatch: 163, Validation Loss: 4.000664710998535, Accuracy: 0.0, Accum Accuracy: 13.799999177455902\n",
      "Validation Epoch: 1, Validation Minibatch: 164, Validation Loss: 3.478290557861328, Accuracy: 0.19999998807907104, Accum Accuracy: 13.999999165534973\n",
      "Validation Epoch: 1, Validation Minibatch: 165, Validation Loss: 3.1483001708984375, Accuracy: 0.09999999403953552, Accum Accuracy: 14.099999159574509\n",
      "Validation Epoch: 1, Validation Minibatch: 166, Validation Loss: 4.300982475280762, Accuracy: 0.09999999403953552, Accum Accuracy: 14.199999153614044\n",
      "Validation Epoch: 1, Validation Minibatch: 167, Validation Loss: 4.112635135650635, Accuracy: 0.0, Accum Accuracy: 14.199999153614044\n",
      "Validation Epoch: 1, Validation Minibatch: 168, Validation Loss: 4.235860347747803, Accuracy: 0.0, Accum Accuracy: 14.199999153614044\n",
      "Validation Epoch: 1, Validation Minibatch: 169, Validation Loss: 3.788036823272705, Accuracy: 0.0, Accum Accuracy: 14.199999153614044\n",
      "Validation Epoch: 1, Validation Minibatch: 170, Validation Loss: 3.4304661750793457, Accuracy: 0.0, Accum Accuracy: 14.199999153614044\n",
      "Validation Epoch: 1, Validation Minibatch: 171, Validation Loss: 4.3468194007873535, Accuracy: 0.09999999403953552, Accum Accuracy: 14.29999914765358\n",
      "Validation Epoch: 1, Validation Minibatch: 172, Validation Loss: 3.579263210296631, Accuracy: 0.09999999403953552, Accum Accuracy: 14.399999141693115\n",
      "Validation Epoch: 1, Validation Minibatch: 173, Validation Loss: 3.684135913848877, Accuracy: 0.09999999403953552, Accum Accuracy: 14.49999913573265\n",
      "Validation Epoch: 1, Validation Minibatch: 174, Validation Loss: 4.085433006286621, Accuracy: 0.09999999403953552, Accum Accuracy: 14.599999129772186\n",
      "Validation Epoch: 1, Validation Minibatch: 175, Validation Loss: 3.7352919578552246, Accuracy: 0.0, Accum Accuracy: 14.599999129772186\n",
      "Validation Epoch: 1, Validation Minibatch: 176, Validation Loss: 3.6074938774108887, Accuracy: 0.09999999403953552, Accum Accuracy: 14.699999123811722\n",
      "Validation Epoch: 1, Validation Minibatch: 177, Validation Loss: 3.7189853191375732, Accuracy: 0.0, Accum Accuracy: 14.699999123811722\n",
      "Validation Epoch: 1, Validation Minibatch: 178, Validation Loss: 4.15871524810791, Accuracy: 0.0, Accum Accuracy: 14.699999123811722\n",
      "Validation Epoch: 1, Validation Minibatch: 179, Validation Loss: 3.9761695861816406, Accuracy: 0.0, Accum Accuracy: 14.699999123811722\n",
      "Validation Epoch: 1, Validation Minibatch: 180, Validation Loss: 3.542409896850586, Accuracy: 0.19999998807907104, Accum Accuracy: 14.899999111890793\n",
      "Validation Epoch: 1, Validation Minibatch: 181, Validation Loss: 3.9529025554656982, Accuracy: 0.0, Accum Accuracy: 14.899999111890793\n",
      "Validation Epoch: 1, Validation Minibatch: 182, Validation Loss: 3.498974323272705, Accuracy: 0.19999998807907104, Accum Accuracy: 15.099999099969864\n",
      "Validation Epoch: 1, Validation Minibatch: 183, Validation Loss: 3.8331103324890137, Accuracy: 0.19999998807907104, Accum Accuracy: 15.299999088048935\n",
      "Validation Epoch: 1, Validation Minibatch: 184, Validation Loss: 4.690099716186523, Accuracy: 0.0, Accum Accuracy: 15.299999088048935\n",
      "Validation Epoch: 1, Validation Minibatch: 185, Validation Loss: 3.7164313793182373, Accuracy: 0.09999999403953552, Accum Accuracy: 15.39999908208847\n",
      "Validation Epoch: 1, Validation Minibatch: 186, Validation Loss: 2.985501527786255, Accuracy: 0.09999999403953552, Accum Accuracy: 15.499999076128006\n",
      "Validation Epoch: 1, Validation Minibatch: 187, Validation Loss: 3.973127841949463, Accuracy: 0.0, Accum Accuracy: 15.499999076128006\n",
      "Validation Epoch: 1, Validation Minibatch: 188, Validation Loss: 3.2189249992370605, Accuracy: 0.09999999403953552, Accum Accuracy: 15.599999070167542\n",
      "Validation Epoch: 1, Validation Minibatch: 189, Validation Loss: 4.476613998413086, Accuracy: 0.0, Accum Accuracy: 15.599999070167542\n",
      "Validation Epoch: 1, Validation Minibatch: 190, Validation Loss: 4.151934623718262, Accuracy: 0.0, Accum Accuracy: 15.599999070167542\n",
      "Validation Epoch: 1, Validation Minibatch: 191, Validation Loss: 3.6238784790039062, Accuracy: 0.09999999403953552, Accum Accuracy: 15.699999064207077\n",
      "Validation Epoch: 1, Validation Minibatch: 192, Validation Loss: 3.4529709815979004, Accuracy: 0.29999998211860657, Accum Accuracy: 15.999999046325684\n",
      "Validation Epoch: 1, Validation Minibatch: 193, Validation Loss: 3.664885997772217, Accuracy: 0.29999998211860657, Accum Accuracy: 16.29999902844429\n",
      "Validation Epoch: 1, Validation Minibatch: 194, Validation Loss: 3.4801037311553955, Accuracy: 0.19999998807907104, Accum Accuracy: 16.49999901652336\n",
      "Validation Epoch: 1, Validation Minibatch: 195, Validation Loss: 3.405205488204956, Accuracy: 0.0, Accum Accuracy: 16.49999901652336\n",
      "Validation Epoch: 1, Validation Minibatch: 196, Validation Loss: 4.375611782073975, Accuracy: 0.09999999403953552, Accum Accuracy: 16.599999010562897\n",
      "Validation Epoch: 1, Validation Minibatch: 197, Validation Loss: 3.8407890796661377, Accuracy: 0.19999998807907104, Accum Accuracy: 16.799998998641968\n",
      "Validation Epoch: 1, Validation Minibatch: 198, Validation Loss: 4.315934181213379, Accuracy: 0.09999999403953552, Accum Accuracy: 16.899998992681503\n",
      "Validation Epoch: 1, Validation Minibatch: 199, Validation Loss: 4.007019519805908, Accuracy: 0.0, Accum Accuracy: 16.899998992681503\n",
      "Validation Epoch: 1, Validation Minibatch: 200, Validation Loss: 3.3686351776123047, Accuracy: 0.0, Accum Accuracy: 16.899998992681503\n",
      "Validation Epoch: 1, Validation Minibatch: 201, Validation Loss: 4.238780975341797, Accuracy: 0.0, Accum Accuracy: 16.899998992681503\n",
      "Validation Epoch: 1, Validation Minibatch: 202, Validation Loss: 3.7203478813171387, Accuracy: 0.19999998807907104, Accum Accuracy: 17.099998980760574\n",
      "Validation Epoch: 1, Validation Minibatch: 203, Validation Loss: 4.36333703994751, Accuracy: 0.19999998807907104, Accum Accuracy: 17.299998968839645\n",
      "Validation Epoch: 1, Validation Minibatch: 204, Validation Loss: 3.4908394813537598, Accuracy: 0.09999999403953552, Accum Accuracy: 17.39999896287918\n",
      "Validation Epoch: 1, Validation Minibatch: 205, Validation Loss: 3.803642988204956, Accuracy: 0.0, Accum Accuracy: 17.39999896287918\n",
      "Validation Epoch: 1, Validation Minibatch: 206, Validation Loss: 4.480072021484375, Accuracy: 0.09999999403953552, Accum Accuracy: 17.499998956918716\n",
      "Validation Epoch: 1, Validation Minibatch: 207, Validation Loss: 4.145370960235596, Accuracy: 0.0, Accum Accuracy: 17.499998956918716\n",
      "Validation Epoch: 1, Validation Minibatch: 208, Validation Loss: 3.191979169845581, Accuracy: 0.0, Accum Accuracy: 17.499998956918716\n",
      "Validation Epoch: 1, Validation Minibatch: 209, Validation Loss: 3.703151226043701, Accuracy: 0.09999999403953552, Accum Accuracy: 17.599998950958252\n",
      "Validation Epoch: 1, Validation Minibatch: 210, Validation Loss: 3.875156879425049, Accuracy: 0.09999999403953552, Accum Accuracy: 17.699998944997787\n",
      "Validation Epoch: 1, Validation Minibatch: 211, Validation Loss: 3.6368651390075684, Accuracy: 0.0, Accum Accuracy: 17.699998944997787\n",
      "Validation Epoch: 1, Validation Minibatch: 212, Validation Loss: 3.8282294273376465, Accuracy: 0.19999998807907104, Accum Accuracy: 17.89999893307686\n",
      "Validation Epoch: 1, Validation Minibatch: 213, Validation Loss: 4.208235263824463, Accuracy: 0.09999999403953552, Accum Accuracy: 17.999998927116394\n",
      "Validation Epoch: 1, Validation Minibatch: 214, Validation Loss: 3.7783615589141846, Accuracy: 0.0, Accum Accuracy: 17.999998927116394\n",
      "Validation Epoch: 1, Validation Minibatch: 215, Validation Loss: 3.7951645851135254, Accuracy: 0.09999999403953552, Accum Accuracy: 18.09999892115593\n",
      "Validation Epoch: 1, Validation Minibatch: 216, Validation Loss: 3.737499952316284, Accuracy: 0.0, Accum Accuracy: 18.09999892115593\n",
      "Validation Epoch: 1, Validation Minibatch: 217, Validation Loss: 3.998302936553955, Accuracy: 0.09999999403953552, Accum Accuracy: 18.199998915195465\n",
      "Validation Epoch: 1, Validation Minibatch: 218, Validation Loss: 3.5763142108917236, Accuracy: 0.09999999403953552, Accum Accuracy: 18.299998909235\n",
      "Validation Epoch: 1, Validation Minibatch: 219, Validation Loss: 4.164883613586426, Accuracy: 0.09999999403953552, Accum Accuracy: 18.399998903274536\n",
      "Validation Epoch: 1, Validation Minibatch: 220, Validation Loss: 3.2422878742218018, Accuracy: 0.09999999403953552, Accum Accuracy: 18.49999889731407\n",
      "Validation Epoch: 1, Validation Minibatch: 221, Validation Loss: 3.7647640705108643, Accuracy: 0.09999999403953552, Accum Accuracy: 18.599998891353607\n",
      "Validation Epoch: 1, Validation Minibatch: 222, Validation Loss: 3.4320626258850098, Accuracy: 0.19999998807907104, Accum Accuracy: 18.799998879432678\n",
      "Validation Epoch: 1, Validation Minibatch: 223, Validation Loss: 4.003739833831787, Accuracy: 0.09999999403953552, Accum Accuracy: 18.899998873472214\n",
      "Validation Epoch: 1, Validation Minibatch: 224, Validation Loss: 3.991507053375244, Accuracy: 0.09999999403953552, Accum Accuracy: 18.99999886751175\n",
      "Validation Epoch: 1, Validation Minibatch: 225, Validation Loss: 3.5221004486083984, Accuracy: 0.09999999403953552, Accum Accuracy: 19.099998861551285\n",
      "Validation Epoch: 1, Validation Minibatch: 226, Validation Loss: 5.21049690246582, Accuracy: 0.0, Accum Accuracy: 19.099998861551285\n",
      "Validation Epoch: 1, Validation Minibatch: 227, Validation Loss: 3.103363513946533, Accuracy: 0.09999999403953552, Accum Accuracy: 19.19999885559082\n",
      "Validation Epoch: 1, Validation Minibatch: 228, Validation Loss: 3.3491692543029785, Accuracy: 0.0, Accum Accuracy: 19.19999885559082\n",
      "Validation Epoch: 1, Validation Minibatch: 229, Validation Loss: 3.552471160888672, Accuracy: 0.09999999403953552, Accum Accuracy: 19.299998849630356\n",
      "Validation Epoch: 1, Validation Minibatch: 230, Validation Loss: 3.980945587158203, Accuracy: 0.09999999403953552, Accum Accuracy: 19.39999884366989\n",
      "Validation Epoch: 1, Validation Minibatch: 231, Validation Loss: 3.816389799118042, Accuracy: 0.29999998211860657, Accum Accuracy: 19.699998825788498\n",
      "Validation Epoch: 1, Validation Minibatch: 232, Validation Loss: 3.4466259479522705, Accuracy: 0.09999999403953552, Accum Accuracy: 19.799998819828033\n",
      "Validation Epoch: 1, Validation Minibatch: 233, Validation Loss: 3.5110409259796143, Accuracy: 0.0, Accum Accuracy: 19.799998819828033\n",
      "Validation Epoch: 1, Validation Minibatch: 234, Validation Loss: 3.894681215286255, Accuracy: 0.0, Accum Accuracy: 19.799998819828033\n",
      "Validation Epoch: 1, Validation Minibatch: 235, Validation Loss: 3.7981066703796387, Accuracy: 0.09999999403953552, Accum Accuracy: 19.89999881386757\n",
      "Validation Epoch: 1, Validation Minibatch: 236, Validation Loss: 4.796426773071289, Accuracy: 0.0, Accum Accuracy: 19.89999881386757\n",
      "Validation Epoch: 1, Validation Minibatch: 237, Validation Loss: 3.5791428089141846, Accuracy: 0.09999999403953552, Accum Accuracy: 19.999998807907104\n",
      "Validation Epoch: 1, Validation Minibatch: 238, Validation Loss: 3.316518783569336, Accuracy: 0.09999999403953552, Accum Accuracy: 20.09999880194664\n",
      "Validation Epoch: 1, Validation Minibatch: 239, Validation Loss: 3.5469284057617188, Accuracy: 0.09999999403953552, Accum Accuracy: 20.199998795986176\n",
      "Validation Epoch: 1, Validation Minibatch: 240, Validation Loss: 3.781614303588867, Accuracy: 0.0, Accum Accuracy: 20.199998795986176\n",
      "Validation Epoch: 1, Validation Minibatch: 241, Validation Loss: 3.2003817558288574, Accuracy: 0.09999999403953552, Accum Accuracy: 20.29999879002571\n",
      "Validation Epoch: 1, Validation Minibatch: 242, Validation Loss: 3.829357147216797, Accuracy: 0.09999999403953552, Accum Accuracy: 20.399998784065247\n",
      "Validation Epoch: 1, Validation Minibatch: 243, Validation Loss: 4.00731897354126, Accuracy: 0.0, Accum Accuracy: 20.399998784065247\n",
      "Validation Epoch: 1, Validation Minibatch: 244, Validation Loss: 3.346189022064209, Accuracy: 0.19999998807907104, Accum Accuracy: 20.599998772144318\n",
      "Validation Epoch: 1, Validation Minibatch: 245, Validation Loss: 4.092108726501465, Accuracy: 0.09999999403953552, Accum Accuracy: 20.699998766183853\n",
      "Validation Epoch: 1, Validation Minibatch: 246, Validation Loss: 3.7135815620422363, Accuracy: 0.29999998211860657, Accum Accuracy: 20.99999874830246\n",
      "Validation Epoch: 1, Validation Minibatch: 247, Validation Loss: 3.0151188373565674, Accuracy: 0.0, Accum Accuracy: 20.99999874830246\n",
      "Validation Epoch: 1, Validation Minibatch: 248, Validation Loss: 3.715336322784424, Accuracy: 0.09999999403953552, Accum Accuracy: 21.099998742341995\n",
      "Validation Epoch: 1, Validation Minibatch: 249, Validation Loss: 3.566193103790283, Accuracy: 0.09999999403953552, Accum Accuracy: 21.19999873638153\n",
      "Validation Epoch: 1, Validation Minibatch: 250, Validation Loss: 4.647107124328613, Accuracy: 0.0, Accum Accuracy: 21.19999873638153\n",
      "Validation Epoch: 1, Validation Minibatch: 251, Validation Loss: 3.3216445446014404, Accuracy: 0.19999998807907104, Accum Accuracy: 21.399998724460602\n",
      "Validation Epoch: 1, Validation Minibatch: 252, Validation Loss: 3.8829612731933594, Accuracy: 0.09999999403953552, Accum Accuracy: 21.499998718500137\n",
      "Validation Epoch: 1, Validation Minibatch: 253, Validation Loss: 4.016548156738281, Accuracy: 0.0, Accum Accuracy: 21.499998718500137\n",
      "Validation Epoch: 1, Validation Minibatch: 254, Validation Loss: 4.139832496643066, Accuracy: 0.0, Accum Accuracy: 21.499998718500137\n",
      "Validation Epoch: 1, Validation Minibatch: 255, Validation Loss: 3.893388271331787, Accuracy: 0.0, Accum Accuracy: 21.499998718500137\n",
      "Validation Epoch: 1, Validation Minibatch: 256, Validation Loss: 3.788815975189209, Accuracy: 0.0, Accum Accuracy: 21.499998718500137\n",
      "Validation Epoch: 1, Validation Minibatch: 257, Validation Loss: 3.4516749382019043, Accuracy: 0.09999999403953552, Accum Accuracy: 21.599998712539673\n",
      "Validation Epoch: 1, Validation Minibatch: 258, Validation Loss: 4.232348442077637, Accuracy: 0.19999998807907104, Accum Accuracy: 21.799998700618744\n",
      "Validation Epoch: 1, Validation Minibatch: 259, Validation Loss: 3.560314178466797, Accuracy: 0.19999998807907104, Accum Accuracy: 21.999998688697815\n",
      "Validation Epoch: 1, Validation Minibatch: 260, Validation Loss: 3.2303566932678223, Accuracy: 0.09999999403953552, Accum Accuracy: 22.09999868273735\n",
      "Validation Epoch: 1, Validation Minibatch: 261, Validation Loss: 3.9858288764953613, Accuracy: 0.0, Accum Accuracy: 22.09999868273735\n",
      "Validation Epoch: 1, Validation Minibatch: 262, Validation Loss: 3.515528917312622, Accuracy: 0.19999998807907104, Accum Accuracy: 22.29999867081642\n",
      "Validation Epoch: 1, Validation Minibatch: 263, Validation Loss: 3.621825695037842, Accuracy: 0.09999999403953552, Accum Accuracy: 22.399998664855957\n",
      "Validation Epoch: 1, Validation Minibatch: 264, Validation Loss: 4.7138590812683105, Accuracy: 0.19999998807907104, Accum Accuracy: 22.599998652935028\n",
      "Validation Epoch: 1, Validation Minibatch: 265, Validation Loss: 4.009947299957275, Accuracy: 0.19999998807907104, Accum Accuracy: 22.7999986410141\n",
      "Validation Epoch: 1, Validation Minibatch: 266, Validation Loss: 4.16359806060791, Accuracy: 0.0, Accum Accuracy: 22.7999986410141\n",
      "Validation Epoch: 1, Validation Minibatch: 267, Validation Loss: 3.2109055519104004, Accuracy: 0.09999999403953552, Accum Accuracy: 22.899998635053635\n",
      "Validation Epoch: 1, Validation Minibatch: 268, Validation Loss: 3.2657630443573, Accuracy: 0.0, Accum Accuracy: 22.899998635053635\n",
      "Validation Epoch: 1, Validation Minibatch: 269, Validation Loss: 3.7328667640686035, Accuracy: 0.09999999403953552, Accum Accuracy: 22.99999862909317\n",
      "Validation Epoch: 1, Validation Minibatch: 270, Validation Loss: 3.492388963699341, Accuracy: 0.19999998807907104, Accum Accuracy: 23.19999861717224\n",
      "Validation Epoch: 1, Validation Minibatch: 271, Validation Loss: 4.0896759033203125, Accuracy: 0.0, Accum Accuracy: 23.19999861717224\n",
      "Validation Epoch: 1, Validation Minibatch: 272, Validation Loss: 3.6185696125030518, Accuracy: 0.0, Accum Accuracy: 23.19999861717224\n",
      "Validation Epoch: 1, Validation Minibatch: 273, Validation Loss: 4.315913200378418, Accuracy: 0.0, Accum Accuracy: 23.19999861717224\n",
      "Validation Epoch: 1, Validation Minibatch: 274, Validation Loss: 4.083636283874512, Accuracy: 0.0, Accum Accuracy: 23.19999861717224\n",
      "Validation Epoch: 1, Validation Minibatch: 275, Validation Loss: 4.278194904327393, Accuracy: 0.09999999403953552, Accum Accuracy: 23.299998611211777\n",
      "Validation Epoch: 1, Validation Minibatch: 276, Validation Loss: 4.038268089294434, Accuracy: 0.0, Accum Accuracy: 23.299998611211777\n",
      "Validation Epoch: 1, Validation Minibatch: 277, Validation Loss: 4.351439952850342, Accuracy: 0.0, Accum Accuracy: 23.299998611211777\n",
      "Validation Epoch: 1, Validation Minibatch: 278, Validation Loss: 4.7137556076049805, Accuracy: 0.0, Accum Accuracy: 23.299998611211777\n",
      "Validation Epoch: 1, Validation Minibatch: 279, Validation Loss: 4.11565637588501, Accuracy: 0.09999999403953552, Accum Accuracy: 23.399998605251312\n",
      "Validation Epoch: 1, Validation Minibatch: 280, Validation Loss: 2.992241621017456, Accuracy: 0.09999999403953552, Accum Accuracy: 23.499998599290848\n",
      "Validation Epoch: 1, Validation Minibatch: 281, Validation Loss: 3.574707508087158, Accuracy: 0.09999999403953552, Accum Accuracy: 23.599998593330383\n",
      "Validation Epoch: 1, Validation Minibatch: 282, Validation Loss: 3.5958189964294434, Accuracy: 0.0, Accum Accuracy: 23.599998593330383\n",
      "Validation Epoch: 1, Validation Minibatch: 283, Validation Loss: 4.053104877471924, Accuracy: 0.19999998807907104, Accum Accuracy: 23.799998581409454\n",
      "Validation Epoch: 1, Validation Minibatch: 284, Validation Loss: 3.64665150642395, Accuracy: 0.0, Accum Accuracy: 23.799998581409454\n",
      "Validation Epoch: 1, Validation Minibatch: 285, Validation Loss: 3.9355320930480957, Accuracy: 0.0, Accum Accuracy: 23.799998581409454\n",
      "Validation Epoch: 1, Validation Minibatch: 286, Validation Loss: 3.358022689819336, Accuracy: 0.0, Accum Accuracy: 23.799998581409454\n",
      "Validation Epoch: 1, Validation Minibatch: 287, Validation Loss: 4.020097255706787, Accuracy: 0.09999999403953552, Accum Accuracy: 23.89999857544899\n",
      "Validation Epoch: 1, Validation Minibatch: 288, Validation Loss: 3.114905834197998, Accuracy: 0.0, Accum Accuracy: 23.89999857544899\n",
      "Validation Epoch: 1, Validation Minibatch: 289, Validation Loss: 4.031059265136719, Accuracy: 0.09999999403953552, Accum Accuracy: 23.999998569488525\n",
      "Validation Epoch: 1, Validation Minibatch: 290, Validation Loss: 4.021973609924316, Accuracy: 0.09999999403953552, Accum Accuracy: 24.09999856352806\n",
      "Validation Epoch: 1, Validation Minibatch: 291, Validation Loss: 4.277539253234863, Accuracy: 0.09999999403953552, Accum Accuracy: 24.199998557567596\n",
      "Validation Epoch: 1, Validation Minibatch: 292, Validation Loss: 4.067760944366455, Accuracy: 0.09999999403953552, Accum Accuracy: 24.299998551607132\n",
      "Validation Epoch: 1, Validation Minibatch: 293, Validation Loss: 4.038788318634033, Accuracy: 0.0, Accum Accuracy: 24.299998551607132\n",
      "Validation Epoch: 1, Validation Minibatch: 294, Validation Loss: 3.2511496543884277, Accuracy: 0.19999998807907104, Accum Accuracy: 24.499998539686203\n",
      "Validation Epoch: 1, Validation Minibatch: 295, Validation Loss: 4.669538974761963, Accuracy: 0.19999998807907104, Accum Accuracy: 24.699998527765274\n",
      "Validation Epoch: 1, Validation Minibatch: 296, Validation Loss: 3.208163022994995, Accuracy: 0.0, Accum Accuracy: 24.699998527765274\n",
      "Validation Epoch: 1, Validation Minibatch: 297, Validation Loss: 4.1249895095825195, Accuracy: 0.0, Accum Accuracy: 24.699998527765274\n",
      "Validation Epoch: 1, Validation Minibatch: 298, Validation Loss: 3.7820019721984863, Accuracy: 0.09999999403953552, Accum Accuracy: 24.79999852180481\n",
      "Validation Epoch: 1, Validation Minibatch: 299, Validation Loss: 3.2799899578094482, Accuracy: 0.09999999403953552, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 300, Validation Loss: 3.69476580619812, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 301, Validation Loss: 4.219008445739746, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 302, Validation Loss: 3.8968982696533203, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 303, Validation Loss: 4.026891231536865, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 304, Validation Loss: 4.164656639099121, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 305, Validation Loss: 3.8468635082244873, Accuracy: 0.0, Accum Accuracy: 24.899998515844345\n",
      "Validation Epoch: 1, Validation Minibatch: 306, Validation Loss: 3.6638596057891846, Accuracy: 0.19999998807907104, Accum Accuracy: 25.099998503923416\n",
      "Validation Epoch: 1, Validation Minibatch: 307, Validation Loss: 3.4984569549560547, Accuracy: 0.0, Accum Accuracy: 25.099998503923416\n",
      "Validation Epoch: 1, Validation Minibatch: 308, Validation Loss: 4.143113136291504, Accuracy: 0.0, Accum Accuracy: 25.099998503923416\n",
      "Validation Epoch: 1, Validation Minibatch: 309, Validation Loss: 3.7644405364990234, Accuracy: 0.0, Accum Accuracy: 25.099998503923416\n",
      "Validation Epoch: 1, Validation Minibatch: 310, Validation Loss: 4.8038530349731445, Accuracy: 0.09999999403953552, Accum Accuracy: 25.19999849796295\n",
      "Validation Epoch: 1, Validation Minibatch: 311, Validation Loss: 4.657010078430176, Accuracy: 0.0, Accum Accuracy: 25.19999849796295\n",
      "Validation Epoch: 1, Validation Minibatch: 312, Validation Loss: 3.3705551624298096, Accuracy: 0.09999999403953552, Accum Accuracy: 25.299998492002487\n",
      "Validation Epoch: 1, Validation Minibatch: 313, Validation Loss: 3.906609296798706, Accuracy: 0.19999998807907104, Accum Accuracy: 25.49999848008156\n",
      "Validation Epoch: 1, Validation Minibatch: 314, Validation Loss: 3.4838244915008545, Accuracy: 0.09999999403953552, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 315, Validation Loss: 3.1906580924987793, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 316, Validation Loss: 3.5370917320251465, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 317, Validation Loss: 3.885732650756836, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 318, Validation Loss: 3.9081573486328125, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 319, Validation Loss: 2.9642560482025146, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 320, Validation Loss: 4.128354072570801, Accuracy: 0.0, Accum Accuracy: 25.599998474121094\n",
      "Validation Epoch: 1, Validation Minibatch: 321, Validation Loss: 3.006603717803955, Accuracy: 0.09999999403953552, Accum Accuracy: 25.69999846816063\n",
      "Validation Epoch: 1, Validation Minibatch: 322, Validation Loss: 3.0501956939697266, Accuracy: 0.09999999403953552, Accum Accuracy: 25.799998462200165\n",
      "Validation Epoch: 1, Validation Minibatch: 323, Validation Loss: 3.726536989212036, Accuracy: 0.09999999403953552, Accum Accuracy: 25.8999984562397\n",
      "Validation Epoch: 1, Validation Minibatch: 324, Validation Loss: 3.688704013824463, Accuracy: 0.0, Accum Accuracy: 25.8999984562397\n",
      "Validation Epoch: 1, Validation Minibatch: 325, Validation Loss: 4.075601577758789, Accuracy: 0.0, Accum Accuracy: 25.8999984562397\n",
      "Validation Epoch: 1, Validation Minibatch: 326, Validation Loss: 3.9476776123046875, Accuracy: 0.19999998807907104, Accum Accuracy: 26.09999844431877\n",
      "Validation Epoch: 1, Validation Minibatch: 327, Validation Loss: 3.455031633377075, Accuracy: 0.0, Accum Accuracy: 26.09999844431877\n",
      "Validation Epoch: 1, Validation Minibatch: 328, Validation Loss: 3.8409130573272705, Accuracy: 0.0, Accum Accuracy: 26.09999844431877\n",
      "Validation Epoch: 1, Validation Minibatch: 329, Validation Loss: 3.2945594787597656, Accuracy: 0.09999999403953552, Accum Accuracy: 26.199998438358307\n",
      "Validation Epoch: 1, Validation Minibatch: 330, Validation Loss: 3.1132378578186035, Accuracy: 0.19999998807907104, Accum Accuracy: 26.399998426437378\n",
      "Validation Epoch: 1, Validation Minibatch: 331, Validation Loss: 3.6355628967285156, Accuracy: 0.0, Accum Accuracy: 26.399998426437378\n",
      "Validation Epoch: 1, Validation Minibatch: 332, Validation Loss: 4.344090938568115, Accuracy: 0.09999999403953552, Accum Accuracy: 26.499998420476913\n",
      "Validation Epoch: 1, Validation Minibatch: 333, Validation Loss: 3.931981325149536, Accuracy: 0.19999998807907104, Accum Accuracy: 26.699998408555984\n",
      "Validation Epoch: 1, Validation Minibatch: 334, Validation Loss: 3.4325003623962402, Accuracy: 0.3999999761581421, Accum Accuracy: 27.099998384714127\n",
      "Validation Epoch: 1, Validation Minibatch: 335, Validation Loss: 3.952427387237549, Accuracy: 0.09999999403953552, Accum Accuracy: 27.199998378753662\n",
      "Validation Epoch: 1, Validation Minibatch: 336, Validation Loss: 4.499067783355713, Accuracy: 0.09999999403953552, Accum Accuracy: 27.299998372793198\n",
      "Validation Epoch: 1, Validation Minibatch: 337, Validation Loss: 3.2872471809387207, Accuracy: 0.09999999403953552, Accum Accuracy: 27.399998366832733\n",
      "Validation Epoch: 1, Validation Minibatch: 338, Validation Loss: 3.931819200515747, Accuracy: 0.0, Accum Accuracy: 27.399998366832733\n",
      "Validation Epoch: 1, Validation Minibatch: 339, Validation Loss: 3.817495346069336, Accuracy: 0.09999999403953552, Accum Accuracy: 27.49999836087227\n",
      "Validation Epoch: 1, Validation Minibatch: 340, Validation Loss: 3.188192129135132, Accuracy: 0.29999998211860657, Accum Accuracy: 27.799998342990875\n",
      "Validation Epoch: 1, Validation Minibatch: 341, Validation Loss: 2.94773006439209, Accuracy: 0.0, Accum Accuracy: 27.799998342990875\n",
      "Validation Epoch: 1, Validation Minibatch: 342, Validation Loss: 3.408486843109131, Accuracy: 0.09999999403953552, Accum Accuracy: 27.89999833703041\n",
      "Validation Epoch: 1, Validation Minibatch: 343, Validation Loss: 3.8813071250915527, Accuracy: 0.09999999403953552, Accum Accuracy: 27.999998331069946\n",
      "Validation Epoch: 1, Validation Minibatch: 344, Validation Loss: 3.915907621383667, Accuracy: 0.0, Accum Accuracy: 27.999998331069946\n",
      "Validation Epoch: 1, Validation Minibatch: 345, Validation Loss: 3.3414714336395264, Accuracy: 0.09999999403953552, Accum Accuracy: 28.099998325109482\n",
      "Validation Epoch: 1, Validation Minibatch: 346, Validation Loss: 3.4195358753204346, Accuracy: 0.09999999403953552, Accum Accuracy: 28.199998319149017\n",
      "Validation Epoch: 1, Validation Minibatch: 347, Validation Loss: 4.011778354644775, Accuracy: 0.09999999403953552, Accum Accuracy: 28.299998313188553\n",
      "Validation Epoch: 1, Validation Minibatch: 348, Validation Loss: 3.3604702949523926, Accuracy: 0.09999999403953552, Accum Accuracy: 28.39999830722809\n",
      "Validation Epoch: 1, Validation Minibatch: 349, Validation Loss: 3.0748367309570312, Accuracy: 0.09999999403953552, Accum Accuracy: 28.499998301267624\n",
      "Validation Epoch: 1, Validation Minibatch: 350, Validation Loss: 4.324027061462402, Accuracy: 0.0, Accum Accuracy: 28.499998301267624\n",
      "Validation Epoch: 1, Validation Minibatch: 351, Validation Loss: 4.452685832977295, Accuracy: 0.0, Accum Accuracy: 28.499998301267624\n",
      "Validation Epoch: 1, Validation Minibatch: 352, Validation Loss: 3.725445508956909, Accuracy: 0.0, Accum Accuracy: 28.499998301267624\n",
      "Validation Epoch: 1, Validation Minibatch: 353, Validation Loss: 4.115200519561768, Accuracy: 0.0, Accum Accuracy: 28.499998301267624\n",
      "Validation Epoch: 1, Validation Minibatch: 354, Validation Loss: 3.480679750442505, Accuracy: 0.09999999403953552, Accum Accuracy: 28.59999829530716\n",
      "Validation Epoch: 1, Validation Minibatch: 355, Validation Loss: 3.8671112060546875, Accuracy: 0.0, Accum Accuracy: 28.59999829530716\n",
      "Validation Epoch: 1, Validation Minibatch: 356, Validation Loss: 3.4020094871520996, Accuracy: 0.09999999403953552, Accum Accuracy: 28.699998289346695\n",
      "Validation Epoch: 1, Validation Minibatch: 357, Validation Loss: 3.425354480743408, Accuracy: 0.09999999403953552, Accum Accuracy: 28.79999828338623\n",
      "Validation Epoch: 1, Validation Minibatch: 358, Validation Loss: 4.111958980560303, Accuracy: 0.0, Accum Accuracy: 28.79999828338623\n",
      "Validation Epoch: 1, Validation Minibatch: 359, Validation Loss: 3.6150176525115967, Accuracy: 0.0, Accum Accuracy: 28.79999828338623\n",
      "Validation Epoch: 1, Validation Minibatch: 360, Validation Loss: 3.3772521018981934, Accuracy: 0.09999999403953552, Accum Accuracy: 28.899998277425766\n",
      "Validation Epoch: 1, Validation Minibatch: 361, Validation Loss: 4.050748348236084, Accuracy: 0.0, Accum Accuracy: 28.899998277425766\n",
      "Validation Epoch: 1, Validation Minibatch: 362, Validation Loss: 4.03017520904541, Accuracy: 0.09999999403953552, Accum Accuracy: 28.9999982714653\n",
      "Validation Epoch: 1, Validation Minibatch: 363, Validation Loss: 4.127743721008301, Accuracy: 0.0, Accum Accuracy: 28.9999982714653\n",
      "Validation Epoch: 1, Validation Minibatch: 364, Validation Loss: 4.344422340393066, Accuracy: 0.0, Accum Accuracy: 28.9999982714653\n",
      "Validation Epoch: 1, Validation Minibatch: 365, Validation Loss: 4.137822151184082, Accuracy: 0.09999999403953552, Accum Accuracy: 29.099998265504837\n",
      "Validation Epoch: 1, Validation Minibatch: 366, Validation Loss: 4.181814193725586, Accuracy: 0.0, Accum Accuracy: 29.099998265504837\n",
      "Validation Epoch: 1, Validation Minibatch: 367, Validation Loss: 3.637153148651123, Accuracy: 0.19999998807907104, Accum Accuracy: 29.299998253583908\n",
      "Validation Epoch: 1, Validation Minibatch: 368, Validation Loss: 3.7032623291015625, Accuracy: 0.0, Accum Accuracy: 29.299998253583908\n",
      "Validation Epoch: 1, Validation Minibatch: 369, Validation Loss: 3.7278716564178467, Accuracy: 0.19999998807907104, Accum Accuracy: 29.49999824166298\n",
      "Validation Epoch: 1, Validation Minibatch: 370, Validation Loss: 3.96216082572937, Accuracy: 0.0, Accum Accuracy: 29.49999824166298\n",
      "Validation Epoch: 1, Validation Minibatch: 371, Validation Loss: 4.34778356552124, Accuracy: 0.0, Accum Accuracy: 29.49999824166298\n",
      "Validation Epoch: 1, Validation Minibatch: 372, Validation Loss: 4.279363632202148, Accuracy: 0.19999998807907104, Accum Accuracy: 29.69999822974205\n",
      "Validation Epoch: 1, Validation Minibatch: 373, Validation Loss: 3.2906508445739746, Accuracy: 0.0, Accum Accuracy: 29.69999822974205\n",
      "Validation Epoch: 1, Validation Minibatch: 374, Validation Loss: 3.1724600791931152, Accuracy: 0.0, Accum Accuracy: 29.69999822974205\n",
      "Validation Epoch: 1, Validation Minibatch: 375, Validation Loss: 3.53045916557312, Accuracy: 0.0, Accum Accuracy: 29.69999822974205\n",
      "Validation Epoch: 1, Validation Minibatch: 376, Validation Loss: 3.5411205291748047, Accuracy: 0.29999998211860657, Accum Accuracy: 29.999998211860657\n",
      "Validation Epoch: 1, Validation Minibatch: 377, Validation Loss: 4.005276679992676, Accuracy: 0.0, Accum Accuracy: 29.999998211860657\n",
      "Validation Epoch: 1, Validation Minibatch: 378, Validation Loss: 3.9856204986572266, Accuracy: 0.09999999403953552, Accum Accuracy: 30.099998205900192\n",
      "Validation Epoch: 1, Validation Minibatch: 379, Validation Loss: 3.54548716545105, Accuracy: 0.09999999403953552, Accum Accuracy: 30.199998199939728\n",
      "Validation Epoch: 1, Validation Minibatch: 380, Validation Loss: 4.177908897399902, Accuracy: 0.0, Accum Accuracy: 30.199998199939728\n",
      "Validation Epoch: 1, Validation Minibatch: 381, Validation Loss: 3.454671859741211, Accuracy: 0.0, Accum Accuracy: 30.199998199939728\n",
      "Validation Epoch: 1, Validation Minibatch: 382, Validation Loss: 3.748561382293701, Accuracy: 0.0, Accum Accuracy: 30.199998199939728\n",
      "Validation Epoch: 1, Validation Minibatch: 383, Validation Loss: 4.190455436706543, Accuracy: 0.19999998807907104, Accum Accuracy: 30.3999981880188\n",
      "Validation Epoch: 1, Validation Minibatch: 384, Validation Loss: 3.2665677070617676, Accuracy: 0.0, Accum Accuracy: 30.3999981880188\n",
      "Validation Epoch: 1, Validation Minibatch: 385, Validation Loss: 4.682576656341553, Accuracy: 0.19999998807907104, Accum Accuracy: 30.59999817609787\n",
      "Validation Epoch: 1, Validation Minibatch: 386, Validation Loss: 3.8800082206726074, Accuracy: 0.0, Accum Accuracy: 30.59999817609787\n",
      "Validation Epoch: 1, Validation Minibatch: 387, Validation Loss: 3.9540419578552246, Accuracy: 0.09999999403953552, Accum Accuracy: 30.699998170137405\n",
      "Validation Epoch: 1, Validation Minibatch: 388, Validation Loss: 4.827933311462402, Accuracy: 0.0, Accum Accuracy: 30.699998170137405\n",
      "Validation Epoch: 1, Validation Minibatch: 389, Validation Loss: 3.2266058921813965, Accuracy: 0.09999999403953552, Accum Accuracy: 30.79999816417694\n",
      "Validation Epoch: 1, Validation Minibatch: 390, Validation Loss: 3.2815966606140137, Accuracy: 0.0, Accum Accuracy: 30.79999816417694\n",
      "Validation Epoch: 1, Validation Minibatch: 391, Validation Loss: 3.455956220626831, Accuracy: 0.09999999403953552, Accum Accuracy: 30.899998158216476\n",
      "Validation Epoch: 1, Validation Minibatch: 392, Validation Loss: 4.298281669616699, Accuracy: 0.09999999403953552, Accum Accuracy: 30.999998152256012\n",
      "Validation Epoch: 1, Validation Minibatch: 393, Validation Loss: 4.653539180755615, Accuracy: 0.09999999403953552, Accum Accuracy: 31.099998146295547\n",
      "Validation Epoch: 1, Validation Minibatch: 394, Validation Loss: 4.722373008728027, Accuracy: 0.0, Accum Accuracy: 31.099998146295547\n",
      "Validation Epoch: 1, Validation Minibatch: 395, Validation Loss: 3.60874605178833, Accuracy: 0.0, Accum Accuracy: 31.099998146295547\n",
      "Validation Epoch: 1, Validation Minibatch: 396, Validation Loss: 3.7439322471618652, Accuracy: 0.19999998807907104, Accum Accuracy: 31.29999813437462\n",
      "Validation Epoch: 1, Validation Minibatch: 397, Validation Loss: 3.348553419113159, Accuracy: 0.09999999403953552, Accum Accuracy: 31.399998128414154\n",
      "Validation Epoch: 1, Validation Minibatch: 398, Validation Loss: 3.534148693084717, Accuracy: 0.09999999403953552, Accum Accuracy: 31.49999812245369\n",
      "Validation Epoch: 1, Validation Minibatch: 399, Validation Loss: 3.9926438331604004, Accuracy: 0.0, Accum Accuracy: 31.49999812245369\n",
      "Validation Epoch: 1, Validation Minibatch: 400, Validation Loss: 3.112724542617798, Accuracy: 0.0, Accum Accuracy: 31.49999812245369\n",
      "Validation Epoch: 1, Validation Minibatch: 401, Validation Loss: 3.8137176036834717, Accuracy: 0.19999998807907104, Accum Accuracy: 31.69999811053276\n",
      "Validation Epoch: 1, Validation Minibatch: 402, Validation Loss: 3.7112197875976562, Accuracy: 0.09999999403953552, Accum Accuracy: 31.799998104572296\n",
      "Validation Epoch: 1, Validation Minibatch: 403, Validation Loss: 4.52880859375, Accuracy: 0.0, Accum Accuracy: 31.799998104572296\n",
      "Validation Epoch: 1, Validation Minibatch: 404, Validation Loss: 3.3356125354766846, Accuracy: 0.19999998807907104, Accum Accuracy: 31.999998092651367\n",
      "Validation Epoch: 1, Validation Minibatch: 405, Validation Loss: 4.212432384490967, Accuracy: 0.09999999403953552, Accum Accuracy: 32.0999980866909\n",
      "Validation Epoch: 1, Validation Minibatch: 406, Validation Loss: 4.474552631378174, Accuracy: 0.0, Accum Accuracy: 32.0999980866909\n",
      "Validation Epoch: 1, Validation Minibatch: 407, Validation Loss: 4.816121578216553, Accuracy: 0.0, Accum Accuracy: 32.0999980866909\n",
      "Validation Epoch: 1, Validation Minibatch: 408, Validation Loss: 4.022407531738281, Accuracy: 0.09999999403953552, Accum Accuracy: 32.19999808073044\n",
      "Validation Epoch: 1, Validation Minibatch: 409, Validation Loss: 3.2996227741241455, Accuracy: 0.19999998807907104, Accum Accuracy: 32.39999806880951\n",
      "Validation Epoch: 1, Validation Minibatch: 410, Validation Loss: 3.7415542602539062, Accuracy: 0.09999999403953552, Accum Accuracy: 32.499998062849045\n",
      "Validation Epoch: 1, Validation Minibatch: 411, Validation Loss: 3.4752819538116455, Accuracy: 0.09999999403953552, Accum Accuracy: 32.59999805688858\n",
      "Validation Epoch: 1, Validation Minibatch: 412, Validation Loss: 3.644266128540039, Accuracy: 0.09999999403953552, Accum Accuracy: 32.699998050928116\n",
      "Validation Epoch: 1, Validation Minibatch: 413, Validation Loss: 3.866908550262451, Accuracy: 0.19999998807907104, Accum Accuracy: 32.89999803900719\n",
      "Validation Epoch: 1, Validation Minibatch: 414, Validation Loss: 3.6968512535095215, Accuracy: 0.09999999403953552, Accum Accuracy: 32.99999803304672\n",
      "Validation Epoch: 1, Validation Minibatch: 415, Validation Loss: 3.8358376026153564, Accuracy: 0.09999999403953552, Accum Accuracy: 33.09999802708626\n",
      "Validation Epoch: 1, Validation Minibatch: 416, Validation Loss: 4.543280124664307, Accuracy: 0.09999999403953552, Accum Accuracy: 33.19999802112579\n",
      "Validation Epoch: 1, Validation Minibatch: 417, Validation Loss: 3.28936505317688, Accuracy: 0.0, Accum Accuracy: 33.19999802112579\n",
      "Validation Epoch: 1, Validation Minibatch: 418, Validation Loss: 4.24501371383667, Accuracy: 0.0, Accum Accuracy: 33.19999802112579\n",
      "Validation Epoch: 1, Validation Minibatch: 419, Validation Loss: 4.528298854827881, Accuracy: 0.0, Accum Accuracy: 33.19999802112579\n",
      "Validation Epoch: 1, Validation Minibatch: 420, Validation Loss: 3.967263698577881, Accuracy: 0.19999998807907104, Accum Accuracy: 33.399998009204865\n",
      "Validation Epoch: 1, Validation Minibatch: 421, Validation Loss: 4.265033721923828, Accuracy: 0.0, Accum Accuracy: 33.399998009204865\n",
      "Validation Epoch: 1, Validation Minibatch: 422, Validation Loss: 4.523233890533447, Accuracy: 0.09999999403953552, Accum Accuracy: 33.4999980032444\n",
      "Validation Epoch: 1, Validation Minibatch: 423, Validation Loss: 3.5726115703582764, Accuracy: 0.0, Accum Accuracy: 33.4999980032444\n",
      "Validation Epoch: 1, Validation Minibatch: 424, Validation Loss: 4.74299430847168, Accuracy: 0.09999999403953552, Accum Accuracy: 33.599997997283936\n",
      "Validation Epoch: 1, Validation Minibatch: 425, Validation Loss: 4.054152011871338, Accuracy: 0.19999998807907104, Accum Accuracy: 33.79999798536301\n",
      "Validation Epoch: 1, Validation Minibatch: 426, Validation Loss: 3.558581590652466, Accuracy: 0.0, Accum Accuracy: 33.79999798536301\n",
      "Validation Epoch: 1, Validation Minibatch: 427, Validation Loss: 3.904944658279419, Accuracy: 0.29999998211860657, Accum Accuracy: 34.09999796748161\n",
      "Validation Epoch: 1, Validation Minibatch: 428, Validation Loss: 3.7838993072509766, Accuracy: 0.09999999403953552, Accum Accuracy: 34.19999796152115\n",
      "Validation Epoch: 1, Validation Minibatch: 429, Validation Loss: 3.7966933250427246, Accuracy: 0.09999999403953552, Accum Accuracy: 34.299997955560684\n",
      "Validation Epoch: 1, Validation Minibatch: 430, Validation Loss: 3.7714035511016846, Accuracy: 0.0, Accum Accuracy: 34.299997955560684\n",
      "Validation Epoch: 1, Validation Minibatch: 431, Validation Loss: 3.239259719848633, Accuracy: 0.0, Accum Accuracy: 34.299997955560684\n",
      "Validation Epoch: 1, Validation Minibatch: 432, Validation Loss: 3.8602099418640137, Accuracy: 0.0, Accum Accuracy: 34.299997955560684\n",
      "Validation Epoch: 1, Validation Minibatch: 433, Validation Loss: 4.209280490875244, Accuracy: 0.09999999403953552, Accum Accuracy: 34.39999794960022\n",
      "Validation Epoch: 1, Validation Minibatch: 434, Validation Loss: 3.267961025238037, Accuracy: 0.0, Accum Accuracy: 34.39999794960022\n",
      "Validation Epoch: 1, Validation Minibatch: 435, Validation Loss: 4.76800537109375, Accuracy: 0.0, Accum Accuracy: 34.39999794960022\n",
      "Validation Epoch: 1, Validation Minibatch: 436, Validation Loss: 4.006235122680664, Accuracy: 0.0, Accum Accuracy: 34.39999794960022\n",
      "Validation Epoch: 1, Validation Minibatch: 437, Validation Loss: 4.347812175750732, Accuracy: 0.0, Accum Accuracy: 34.39999794960022\n",
      "Validation Epoch: 1, Validation Minibatch: 438, Validation Loss: 4.120369911193848, Accuracy: 0.19999998807907104, Accum Accuracy: 34.59999793767929\n",
      "Validation Epoch: 1, Validation Minibatch: 439, Validation Loss: 4.579902648925781, Accuracy: 0.0, Accum Accuracy: 34.59999793767929\n",
      "Validation Epoch: 1, Validation Minibatch: 440, Validation Loss: 3.7235195636749268, Accuracy: 0.19999998807907104, Accum Accuracy: 34.79999792575836\n",
      "Validation Epoch: 1, Validation Minibatch: 441, Validation Loss: 3.950033664703369, Accuracy: 0.09999999403953552, Accum Accuracy: 34.8999979197979\n",
      "Validation Epoch: 1, Validation Minibatch: 442, Validation Loss: 3.7029659748077393, Accuracy: 0.0, Accum Accuracy: 34.8999979197979\n",
      "Validation Epoch: 1, Validation Minibatch: 443, Validation Loss: 4.008553504943848, Accuracy: 0.0, Accum Accuracy: 34.8999979197979\n",
      "Validation Epoch: 1, Validation Minibatch: 444, Validation Loss: 3.93879771232605, Accuracy: 0.0, Accum Accuracy: 34.8999979197979\n",
      "Validation Epoch: 1, Validation Minibatch: 445, Validation Loss: 4.362639427185059, Accuracy: 0.0, Accum Accuracy: 34.8999979197979\n",
      "Validation Epoch: 1, Validation Minibatch: 446, Validation Loss: 3.6054153442382812, Accuracy: 0.29999998211860657, Accum Accuracy: 35.199997901916504\n",
      "Validation Epoch: 1, Validation Minibatch: 447, Validation Loss: 3.1631267070770264, Accuracy: 0.19999998807907104, Accum Accuracy: 35.399997889995575\n",
      "Validation Epoch: 1, Validation Minibatch: 448, Validation Loss: 3.4512526988983154, Accuracy: 0.09999999403953552, Accum Accuracy: 35.49999788403511\n",
      "Validation Epoch: 1, Validation Minibatch: 449, Validation Loss: 3.9143619537353516, Accuracy: 0.09999999403953552, Accum Accuracy: 35.599997878074646\n",
      "Validation Epoch: 1, Validation Minibatch: 450, Validation Loss: 3.5060882568359375, Accuracy: 0.0, Accum Accuracy: 35.599997878074646\n",
      "Validation Epoch: 1, Validation Minibatch: 451, Validation Loss: 3.8334202766418457, Accuracy: 0.0, Accum Accuracy: 35.599997878074646\n",
      "Validation Epoch: 1, Validation Minibatch: 452, Validation Loss: 3.3829445838928223, Accuracy: 0.19999998807907104, Accum Accuracy: 35.79999786615372\n",
      "Validation Epoch: 1, Validation Minibatch: 453, Validation Loss: 4.411361217498779, Accuracy: 0.0, Accum Accuracy: 35.79999786615372\n",
      "Validation Epoch: 1, Validation Minibatch: 454, Validation Loss: 3.8559632301330566, Accuracy: 0.0, Accum Accuracy: 35.79999786615372\n",
      "Validation Epoch: 1, Validation Minibatch: 455, Validation Loss: 3.703795909881592, Accuracy: 0.0, Accum Accuracy: 35.79999786615372\n",
      "Validation Epoch: 1, Validation Minibatch: 456, Validation Loss: 2.715132474899292, Accuracy: 0.29999998211860657, Accum Accuracy: 36.099997848272324\n",
      "Validation Epoch: 1, Validation Minibatch: 457, Validation Loss: 3.731271743774414, Accuracy: 0.0, Accum Accuracy: 36.099997848272324\n",
      "Validation Epoch: 1, Validation Minibatch: 458, Validation Loss: 3.817239284515381, Accuracy: 0.0, Accum Accuracy: 36.099997848272324\n",
      "Validation Epoch: 1, Validation Minibatch: 459, Validation Loss: 4.190037727355957, Accuracy: 0.09999999403953552, Accum Accuracy: 36.19999784231186\n",
      "Validation Epoch: 1, Validation Minibatch: 460, Validation Loss: 3.911972761154175, Accuracy: 0.0, Accum Accuracy: 36.19999784231186\n",
      "Validation Epoch: 1, Validation Minibatch: 461, Validation Loss: 4.505701541900635, Accuracy: 0.0, Accum Accuracy: 36.19999784231186\n",
      "Validation Epoch: 1, Validation Minibatch: 462, Validation Loss: 3.585203170776367, Accuracy: 0.19999998807907104, Accum Accuracy: 36.39999783039093\n",
      "Validation Epoch: 1, Validation Minibatch: 463, Validation Loss: 3.3399078845977783, Accuracy: 0.09999999403953552, Accum Accuracy: 36.499997824430466\n",
      "Validation Epoch: 1, Validation Minibatch: 464, Validation Loss: 4.6354498863220215, Accuracy: 0.09999999403953552, Accum Accuracy: 36.59999781847\n",
      "Validation Epoch: 1, Validation Minibatch: 465, Validation Loss: 3.596876621246338, Accuracy: 0.29999998211860657, Accum Accuracy: 36.89999780058861\n",
      "Validation Epoch: 1, Validation Minibatch: 466, Validation Loss: 3.5876288414001465, Accuracy: 0.09999999403953552, Accum Accuracy: 36.99999779462814\n",
      "Validation Epoch: 1, Validation Minibatch: 467, Validation Loss: 2.883174419403076, Accuracy: 0.19999998807907104, Accum Accuracy: 37.199997782707214\n",
      "Validation Epoch: 1, Validation Minibatch: 468, Validation Loss: 4.306907653808594, Accuracy: 0.0, Accum Accuracy: 37.199997782707214\n",
      "Validation Epoch: 1, Validation Minibatch: 469, Validation Loss: 3.821664810180664, Accuracy: 0.09999999403953552, Accum Accuracy: 37.29999777674675\n",
      "Validation Epoch: 1, Validation Minibatch: 470, Validation Loss: 3.869541883468628, Accuracy: 0.19999998807907104, Accum Accuracy: 37.49999776482582\n",
      "Validation Epoch: 1, Validation Minibatch: 471, Validation Loss: 4.2355637550354, Accuracy: 0.0, Accum Accuracy: 37.49999776482582\n",
      "Validation Epoch: 1, Validation Minibatch: 472, Validation Loss: 3.877929210662842, Accuracy: 0.09999999403953552, Accum Accuracy: 37.599997758865356\n",
      "Validation Epoch: 1, Validation Minibatch: 473, Validation Loss: 3.3309879302978516, Accuracy: 0.19999998807907104, Accum Accuracy: 37.79999774694443\n",
      "Validation Epoch: 1, Validation Minibatch: 474, Validation Loss: 3.7048754692077637, Accuracy: 0.0, Accum Accuracy: 37.79999774694443\n",
      "Validation Epoch: 1, Validation Minibatch: 475, Validation Loss: 3.806262493133545, Accuracy: 0.0, Accum Accuracy: 37.79999774694443\n",
      "Validation Epoch: 1, Validation Minibatch: 476, Validation Loss: 3.7910168170928955, Accuracy: 0.0, Accum Accuracy: 37.79999774694443\n",
      "Validation Epoch: 1, Validation Minibatch: 477, Validation Loss: 3.370770215988159, Accuracy: 0.09999999403953552, Accum Accuracy: 37.89999774098396\n",
      "Validation Epoch: 1, Validation Minibatch: 478, Validation Loss: 4.404323577880859, Accuracy: 0.0, Accum Accuracy: 37.89999774098396\n",
      "Validation Epoch: 1, Validation Minibatch: 479, Validation Loss: 3.691375732421875, Accuracy: 0.09999999403953552, Accum Accuracy: 37.9999977350235\n",
      "Validation Epoch: 1, Validation Minibatch: 480, Validation Loss: 3.648531675338745, Accuracy: 0.09999999403953552, Accum Accuracy: 38.099997729063034\n",
      "Validation Epoch: 1, Validation Minibatch: 481, Validation Loss: 3.354712724685669, Accuracy: 0.0, Accum Accuracy: 38.099997729063034\n",
      "Validation Epoch: 1, Validation Minibatch: 482, Validation Loss: 3.596132755279541, Accuracy: 0.0, Accum Accuracy: 38.099997729063034\n",
      "Validation Epoch: 1, Validation Minibatch: 483, Validation Loss: 4.12044620513916, Accuracy: 0.09999999403953552, Accum Accuracy: 38.19999772310257\n",
      "Validation Epoch: 1, Validation Minibatch: 484, Validation Loss: 5.127603530883789, Accuracy: 0.09999999403953552, Accum Accuracy: 38.299997717142105\n",
      "Validation Epoch: 1, Validation Minibatch: 485, Validation Loss: 3.8808770179748535, Accuracy: 0.09999999403953552, Accum Accuracy: 38.39999771118164\n",
      "Validation Epoch: 1, Validation Minibatch: 486, Validation Loss: 3.173875331878662, Accuracy: 0.09999999403953552, Accum Accuracy: 38.499997705221176\n",
      "Validation Epoch: 1, Validation Minibatch: 487, Validation Loss: 3.6049389839172363, Accuracy: 0.09999999403953552, Accum Accuracy: 38.59999769926071\n",
      "Validation Epoch: 1, Validation Minibatch: 488, Validation Loss: 3.6222634315490723, Accuracy: 0.09999999403953552, Accum Accuracy: 38.69999769330025\n",
      "Validation Epoch: 1, Validation Minibatch: 489, Validation Loss: 3.5558974742889404, Accuracy: 0.09999999403953552, Accum Accuracy: 38.79999768733978\n",
      "Validation Epoch: 1, Validation Minibatch: 490, Validation Loss: 3.6394972801208496, Accuracy: 0.0, Accum Accuracy: 38.79999768733978\n",
      "Validation Epoch: 1, Validation Minibatch: 491, Validation Loss: 3.696276903152466, Accuracy: 0.0, Accum Accuracy: 38.79999768733978\n",
      "Validation Epoch: 1, Validation Minibatch: 492, Validation Loss: 3.4278037548065186, Accuracy: 0.09999999403953552, Accum Accuracy: 38.89999768137932\n",
      "Validation Epoch: 1, Validation Minibatch: 493, Validation Loss: 3.255250930786133, Accuracy: 0.19999998807907104, Accum Accuracy: 39.09999766945839\n",
      "Validation Epoch: 1, Validation Minibatch: 494, Validation Loss: 4.660560607910156, Accuracy: 0.0, Accum Accuracy: 39.09999766945839\n",
      "Validation Epoch: 1, Validation Minibatch: 495, Validation Loss: 3.8115882873535156, Accuracy: 0.0, Accum Accuracy: 39.09999766945839\n",
      "Validation Epoch: 1, Validation Minibatch: 496, Validation Loss: 4.355430603027344, Accuracy: 0.0, Accum Accuracy: 39.09999766945839\n",
      "Validation Epoch: 1, Validation Minibatch: 497, Validation Loss: 3.857468843460083, Accuracy: 0.0, Accum Accuracy: 39.09999766945839\n",
      "Validation Epoch: 1, Validation Minibatch: 498, Validation Loss: 3.965855121612549, Accuracy: 0.09999999403953552, Accum Accuracy: 39.199997663497925\n",
      "Validation Epoch: 1, Validation Minibatch: 499, Validation Loss: 4.086568355560303, Accuracy: 0.09999999403953552, Accum Accuracy: 39.29999765753746\n",
      "Validation Epoch: 1, Validation Minibatch: 500, Validation Loss: 3.9208836555480957, Accuracy: 0.0, Accum Accuracy: 39.29999765753746\n",
      "Validation Epoch: 1, Validation Minibatch: 501, Validation Loss: 3.2706360816955566, Accuracy: 0.29999998211860657, Accum Accuracy: 39.59999763965607\n",
      "Validation Epoch: 1, Validation Minibatch: 502, Validation Loss: 3.0238490104675293, Accuracy: 0.19999998807907104, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 503, Validation Loss: 3.9989311695098877, Accuracy: 0.0, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 504, Validation Loss: 4.1163554191589355, Accuracy: 0.0, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 505, Validation Loss: 3.641355037689209, Accuracy: 0.0, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 506, Validation Loss: 3.7875945568084717, Accuracy: 0.0, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 507, Validation Loss: 3.750890016555786, Accuracy: 0.0, Accum Accuracy: 39.79999762773514\n",
      "Validation Epoch: 1, Validation Minibatch: 508, Validation Loss: 4.5562849044799805, Accuracy: 0.09999999403953552, Accum Accuracy: 39.89999762177467\n",
      "Validation Epoch: 1, Validation Minibatch: 509, Validation Loss: 3.500572919845581, Accuracy: 0.0, Accum Accuracy: 39.89999762177467\n",
      "Validation Epoch: 1, Validation Minibatch: 510, Validation Loss: 3.7328410148620605, Accuracy: 0.09999999403953552, Accum Accuracy: 39.99999761581421\n",
      "Validation Epoch: 1, Validation Minibatch: 511, Validation Loss: 3.1393086910247803, Accuracy: 0.09999999403953552, Accum Accuracy: 40.099997609853745\n",
      "Validation Epoch: 1, Validation Minibatch: 512, Validation Loss: 4.161076068878174, Accuracy: 0.09999999403953552, Accum Accuracy: 40.19999760389328\n",
      "Validation Epoch: 1, Validation Minibatch: 513, Validation Loss: 3.5721144676208496, Accuracy: 0.0, Accum Accuracy: 40.19999760389328\n",
      "Validation Epoch: 1, Validation Minibatch: 514, Validation Loss: 4.295961380004883, Accuracy: 0.0, Accum Accuracy: 40.19999760389328\n",
      "Validation Epoch: 1, Validation Minibatch: 515, Validation Loss: 3.9834072589874268, Accuracy: 0.0, Accum Accuracy: 40.19999760389328\n",
      "Validation Epoch: 1, Validation Minibatch: 516, Validation Loss: 4.07034158706665, Accuracy: 0.0, Accum Accuracy: 40.19999760389328\n",
      "Validation Epoch: 1, Validation Minibatch: 517, Validation Loss: 3.2883248329162598, Accuracy: 0.09999999403953552, Accum Accuracy: 40.299997597932816\n",
      "Validation Epoch: 1, Validation Minibatch: 518, Validation Loss: 4.817980766296387, Accuracy: 0.0, Accum Accuracy: 40.299997597932816\n",
      "Validation Epoch: 1, Validation Minibatch: 519, Validation Loss: 3.248610734939575, Accuracy: 0.09999999403953552, Accum Accuracy: 40.39999759197235\n",
      "Validation Epoch: 1, Validation Minibatch: 520, Validation Loss: 4.156194686889648, Accuracy: 0.09999999403953552, Accum Accuracy: 40.49999758601189\n",
      "Validation Epoch: 1, Validation Minibatch: 521, Validation Loss: 3.4376091957092285, Accuracy: 0.19999998807907104, Accum Accuracy: 40.69999757409096\n",
      "Validation Epoch: 1, Validation Minibatch: 522, Validation Loss: 3.6129727363586426, Accuracy: 0.09999999403953552, Accum Accuracy: 40.79999756813049\n",
      "Validation Epoch: 1, Validation Minibatch: 523, Validation Loss: 4.2131524085998535, Accuracy: 0.29999998211860657, Accum Accuracy: 41.0999975502491\n",
      "Validation Epoch: 1, Validation Minibatch: 524, Validation Loss: 3.805945873260498, Accuracy: 0.0, Accum Accuracy: 41.0999975502491\n",
      "Validation Epoch: 1, Validation Minibatch: 525, Validation Loss: 3.6069655418395996, Accuracy: 0.0, Accum Accuracy: 41.0999975502491\n",
      "Validation Epoch: 1, Validation Minibatch: 526, Validation Loss: 4.113672256469727, Accuracy: 0.0, Accum Accuracy: 41.0999975502491\n",
      "Validation Epoch: 1, Validation Minibatch: 527, Validation Loss: 4.282998085021973, Accuracy: 0.09999999403953552, Accum Accuracy: 41.199997544288635\n",
      "Validation Epoch: 1, Validation Minibatch: 528, Validation Loss: 3.640467882156372, Accuracy: 0.0, Accum Accuracy: 41.199997544288635\n",
      "Validation Epoch: 1, Validation Minibatch: 529, Validation Loss: 3.880481719970703, Accuracy: 0.09999999403953552, Accum Accuracy: 41.29999753832817\n",
      "Validation Epoch: 1, Validation Minibatch: 530, Validation Loss: 3.579127073287964, Accuracy: 0.09999999403953552, Accum Accuracy: 41.399997532367706\n",
      "Validation Epoch: 1, Validation Minibatch: 531, Validation Loss: 3.2629597187042236, Accuracy: 0.09999999403953552, Accum Accuracy: 41.49999752640724\n",
      "Validation Epoch: 1, Validation Minibatch: 532, Validation Loss: 3.0232186317443848, Accuracy: 0.09999999403953552, Accum Accuracy: 41.59999752044678\n",
      "Validation Epoch: 1, Validation Minibatch: 533, Validation Loss: 4.342610836029053, Accuracy: 0.09999999403953552, Accum Accuracy: 41.69999751448631\n",
      "Validation Epoch: 1, Validation Minibatch: 534, Validation Loss: 4.106960773468018, Accuracy: 0.0, Accum Accuracy: 41.69999751448631\n",
      "Validation Epoch: 1, Validation Minibatch: 535, Validation Loss: 3.9156646728515625, Accuracy: 0.29999998211860657, Accum Accuracy: 41.99999749660492\n",
      "Validation Epoch: 1, Validation Minibatch: 536, Validation Loss: 3.1523706912994385, Accuracy: 0.09999999403953552, Accum Accuracy: 42.099997490644455\n",
      "Validation Epoch: 1, Validation Minibatch: 537, Validation Loss: 3.478193759918213, Accuracy: 0.09999999403953552, Accum Accuracy: 42.19999748468399\n",
      "Validation Epoch: 1, Validation Minibatch: 538, Validation Loss: 4.335824012756348, Accuracy: 0.0, Accum Accuracy: 42.19999748468399\n",
      "Validation Epoch: 1, Validation Minibatch: 539, Validation Loss: 3.0338895320892334, Accuracy: 0.09999999403953552, Accum Accuracy: 42.299997478723526\n",
      "Validation Epoch: 1, Validation Minibatch: 540, Validation Loss: 3.905609130859375, Accuracy: 0.0, Accum Accuracy: 42.299997478723526\n",
      "Validation Epoch: 1, Validation Minibatch: 541, Validation Loss: 4.737493515014648, Accuracy: 0.09999999403953552, Accum Accuracy: 42.39999747276306\n",
      "Validation Epoch: 1, Validation Minibatch: 542, Validation Loss: 3.440324068069458, Accuracy: 0.29999998211860657, Accum Accuracy: 42.69999745488167\n",
      "Validation Epoch: 1, Validation Minibatch: 543, Validation Loss: 3.313894271850586, Accuracy: 0.0, Accum Accuracy: 42.69999745488167\n",
      "Validation Epoch: 1, Validation Minibatch: 544, Validation Loss: 3.480084180831909, Accuracy: 0.09999999403953552, Accum Accuracy: 42.799997448921204\n",
      "Validation Epoch: 1, Validation Minibatch: 545, Validation Loss: 3.097287893295288, Accuracy: 0.09999999403953552, Accum Accuracy: 42.89999744296074\n",
      "Validation Epoch: 1, Validation Minibatch: 546, Validation Loss: 3.745082139968872, Accuracy: 0.09999999403953552, Accum Accuracy: 42.999997437000275\n",
      "Validation Epoch: 1, Validation Minibatch: 547, Validation Loss: 3.6701595783233643, Accuracy: 0.0, Accum Accuracy: 42.999997437000275\n",
      "Validation Epoch: 1, Validation Minibatch: 548, Validation Loss: 3.205225706100464, Accuracy: 0.09999999403953552, Accum Accuracy: 43.09999743103981\n",
      "Validation Epoch: 1, Validation Minibatch: 549, Validation Loss: 4.727822303771973, Accuracy: 0.0, Accum Accuracy: 43.09999743103981\n",
      "Validation Epoch: 1, Validation Minibatch: 550, Validation Loss: 4.1860246658325195, Accuracy: 0.0, Accum Accuracy: 43.09999743103981\n",
      "Validation Epoch: 1, Validation Minibatch: 551, Validation Loss: 3.262547254562378, Accuracy: 0.19999998807907104, Accum Accuracy: 43.29999741911888\n",
      "Validation Epoch: 1, Validation Minibatch: 552, Validation Loss: 3.723864793777466, Accuracy: 0.0, Accum Accuracy: 43.29999741911888\n",
      "Validation Epoch: 1, Validation Minibatch: 553, Validation Loss: 2.8675484657287598, Accuracy: 0.0, Accum Accuracy: 43.29999741911888\n",
      "Validation Epoch: 1, Validation Minibatch: 554, Validation Loss: 3.5543606281280518, Accuracy: 0.09999999403953552, Accum Accuracy: 43.39999741315842\n",
      "Validation Epoch: 1, Validation Minibatch: 555, Validation Loss: 4.378047466278076, Accuracy: 0.0, Accum Accuracy: 43.39999741315842\n",
      "Validation Epoch: 1, Validation Minibatch: 556, Validation Loss: 3.2193546295166016, Accuracy: 0.19999998807907104, Accum Accuracy: 43.59999740123749\n",
      "Validation Epoch: 1, Validation Minibatch: 557, Validation Loss: 3.6638426780700684, Accuracy: 0.0, Accum Accuracy: 43.59999740123749\n",
      "Validation Epoch: 1, Validation Minibatch: 558, Validation Loss: 3.249445676803589, Accuracy: 0.19999998807907104, Accum Accuracy: 43.79999738931656\n",
      "Validation Epoch: 1, Validation Minibatch: 559, Validation Loss: 4.082091331481934, Accuracy: 0.09999999403953552, Accum Accuracy: 43.899997383356094\n",
      "Validation Epoch: 1, Validation Minibatch: 560, Validation Loss: 4.362838268280029, Accuracy: 0.09999999403953552, Accum Accuracy: 43.99999737739563\n",
      "Validation Epoch: 1, Validation Minibatch: 561, Validation Loss: 4.114151954650879, Accuracy: 0.0, Accum Accuracy: 43.99999737739563\n",
      "Validation Epoch: 1, Validation Minibatch: 562, Validation Loss: 3.7690932750701904, Accuracy: 0.09999999403953552, Accum Accuracy: 44.099997371435165\n",
      "Validation Epoch: 1, Validation Minibatch: 563, Validation Loss: 4.224400520324707, Accuracy: 0.0, Accum Accuracy: 44.099997371435165\n",
      "Validation Epoch: 1, Validation Minibatch: 564, Validation Loss: 4.4688568115234375, Accuracy: 0.0, Accum Accuracy: 44.099997371435165\n",
      "Validation Epoch: 1, Validation Minibatch: 565, Validation Loss: 3.3626513481140137, Accuracy: 0.0, Accum Accuracy: 44.099997371435165\n",
      "Validation Epoch: 1, Validation Minibatch: 566, Validation Loss: 3.6781814098358154, Accuracy: 0.09999999403953552, Accum Accuracy: 44.1999973654747\n",
      "Validation Epoch: 1, Validation Minibatch: 567, Validation Loss: 4.134376049041748, Accuracy: 0.09999999403953552, Accum Accuracy: 44.29999735951424\n",
      "Validation Epoch: 1, Validation Minibatch: 568, Validation Loss: 3.8377487659454346, Accuracy: 0.09999999403953552, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 569, Validation Loss: 3.418625593185425, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 570, Validation Loss: 3.7934136390686035, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 571, Validation Loss: 4.1965203285217285, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 572, Validation Loss: 4.30653715133667, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 573, Validation Loss: 4.212538719177246, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 574, Validation Loss: 3.8588085174560547, Accuracy: 0.0, Accum Accuracy: 44.39999735355377\n",
      "Validation Epoch: 1, Validation Minibatch: 575, Validation Loss: 3.9253833293914795, Accuracy: 0.09999999403953552, Accum Accuracy: 44.49999734759331\n",
      "Validation Epoch: 1, Validation Minibatch: 576, Validation Loss: 4.509762763977051, Accuracy: 0.0, Accum Accuracy: 44.49999734759331\n",
      "Validation Epoch: 1, Validation Minibatch: 577, Validation Loss: 3.7030131816864014, Accuracy: 0.0, Accum Accuracy: 44.49999734759331\n",
      "Validation Epoch: 1, Validation Minibatch: 578, Validation Loss: 3.767861843109131, Accuracy: 0.19999998807907104, Accum Accuracy: 44.69999733567238\n",
      "Validation Epoch: 1, Validation Minibatch: 579, Validation Loss: 3.3542544841766357, Accuracy: 0.09999999403953552, Accum Accuracy: 44.799997329711914\n",
      "Validation Epoch: 1, Validation Minibatch: 580, Validation Loss: 3.5516979694366455, Accuracy: 0.0, Accum Accuracy: 44.799997329711914\n",
      "Validation Epoch: 1, Validation Minibatch: 581, Validation Loss: 3.723602771759033, Accuracy: 0.09999999403953552, Accum Accuracy: 44.89999732375145\n",
      "Validation Epoch: 1, Validation Minibatch: 582, Validation Loss: 4.091527462005615, Accuracy: 0.19999998807907104, Accum Accuracy: 45.09999731183052\n",
      "Validation Epoch: 1, Validation Minibatch: 583, Validation Loss: 3.4333701133728027, Accuracy: 0.0, Accum Accuracy: 45.09999731183052\n",
      "Validation Epoch: 1, Validation Minibatch: 584, Validation Loss: 3.3784472942352295, Accuracy: 0.09999999403953552, Accum Accuracy: 45.199997305870056\n",
      "Validation Epoch: 1, Validation Minibatch: 585, Validation Loss: 3.427860975265503, Accuracy: 0.09999999403953552, Accum Accuracy: 45.29999729990959\n",
      "Validation Epoch: 1, Validation Minibatch: 586, Validation Loss: 4.126584529876709, Accuracy: 0.09999999403953552, Accum Accuracy: 45.39999729394913\n",
      "Validation Epoch: 1, Validation Minibatch: 587, Validation Loss: 3.634429931640625, Accuracy: 0.09999999403953552, Accum Accuracy: 45.49999728798866\n",
      "Validation Epoch: 1, Validation Minibatch: 588, Validation Loss: 2.9130752086639404, Accuracy: 0.19999998807907104, Accum Accuracy: 45.699997276067734\n",
      "Validation Epoch: 1, Validation Minibatch: 589, Validation Loss: 3.4714889526367188, Accuracy: 0.19999998807907104, Accum Accuracy: 45.899997264146805\n",
      "Validation Epoch: 1, Validation Minibatch: 590, Validation Loss: 3.2696595191955566, Accuracy: 0.29999998211860657, Accum Accuracy: 46.19999724626541\n",
      "Validation Epoch: 1, Validation Minibatch: 591, Validation Loss: 3.46562123298645, Accuracy: 0.09999999403953552, Accum Accuracy: 46.29999724030495\n",
      "Validation Epoch: 1, Validation Minibatch: 592, Validation Loss: 3.253047227859497, Accuracy: 0.19999998807907104, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 593, Validation Loss: 3.2387683391571045, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 594, Validation Loss: 4.077271461486816, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 595, Validation Loss: 3.443714141845703, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 596, Validation Loss: 3.290623426437378, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 597, Validation Loss: 4.1881585121154785, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 598, Validation Loss: 3.070272207260132, Accuracy: 0.0, Accum Accuracy: 46.49999722838402\n",
      "Validation Epoch: 1, Validation Minibatch: 599, Validation Loss: 3.018350601196289, Accuracy: 0.09999999403953552, Accum Accuracy: 46.59999722242355\n",
      "Validation Epoch: 1, Validation Minibatch: 600, Validation Loss: 3.8188323974609375, Accuracy: 0.09999999403953552, Accum Accuracy: 46.69999721646309\n",
      "Validation Epoch: 1, Validation Minibatch: 601, Validation Loss: 3.6694107055664062, Accuracy: 0.0, Accum Accuracy: 46.69999721646309\n",
      "Validation Epoch: 1, Validation Minibatch: 602, Validation Loss: 3.6688899993896484, Accuracy: 0.0, Accum Accuracy: 46.69999721646309\n",
      "Validation Epoch: 1, Validation Minibatch: 603, Validation Loss: 3.649709701538086, Accuracy: 0.09999999403953552, Accum Accuracy: 46.799997210502625\n",
      "Validation Epoch: 1, Validation Minibatch: 604, Validation Loss: 3.5607120990753174, Accuracy: 0.09999999403953552, Accum Accuracy: 46.89999720454216\n",
      "Validation Epoch: 1, Validation Minibatch: 605, Validation Loss: 3.4129586219787598, Accuracy: 0.09999999403953552, Accum Accuracy: 46.999997198581696\n",
      "Validation Epoch: 1, Validation Minibatch: 606, Validation Loss: 4.2327880859375, Accuracy: 0.09999999403953552, Accum Accuracy: 47.09999719262123\n",
      "Validation Epoch: 1, Validation Minibatch: 607, Validation Loss: 4.371468544006348, Accuracy: 0.09999999403953552, Accum Accuracy: 47.19999718666077\n",
      "Validation Epoch: 1, Validation Minibatch: 608, Validation Loss: 4.264296531677246, Accuracy: 0.0, Accum Accuracy: 47.19999718666077\n",
      "Validation Epoch: 1, Validation Minibatch: 609, Validation Loss: 4.181831359863281, Accuracy: 0.0, Accum Accuracy: 47.19999718666077\n",
      "Validation Epoch: 1, Validation Minibatch: 610, Validation Loss: 4.322064399719238, Accuracy: 0.0, Accum Accuracy: 47.19999718666077\n",
      "Validation Epoch: 1, Validation Minibatch: 611, Validation Loss: 3.8424079418182373, Accuracy: 0.0, Accum Accuracy: 47.19999718666077\n",
      "Validation Epoch: 1, Validation Minibatch: 612, Validation Loss: 3.835371732711792, Accuracy: 0.09999999403953552, Accum Accuracy: 47.2999971807003\n",
      "Validation Epoch: 1, Validation Minibatch: 613, Validation Loss: 4.049763202667236, Accuracy: 0.0, Accum Accuracy: 47.2999971807003\n",
      "Validation Epoch: 1, Validation Minibatch: 614, Validation Loss: 3.3275203704833984, Accuracy: 0.0, Accum Accuracy: 47.2999971807003\n",
      "Validation Epoch: 1, Validation Minibatch: 615, Validation Loss: 3.5420074462890625, Accuracy: 0.09999999403953552, Accum Accuracy: 47.39999717473984\n",
      "Validation Epoch: 1, Validation Minibatch: 616, Validation Loss: 3.864570140838623, Accuracy: 0.0, Accum Accuracy: 47.39999717473984\n",
      "Validation Epoch: 1, Validation Minibatch: 617, Validation Loss: 3.822470188140869, Accuracy: 0.09999999403953552, Accum Accuracy: 47.49999716877937\n",
      "Validation Epoch: 1, Validation Minibatch: 618, Validation Loss: 3.960920810699463, Accuracy: 0.3999999761581421, Accum Accuracy: 47.899997144937515\n",
      "Validation Epoch: 1, Validation Minibatch: 619, Validation Loss: 3.202355146408081, Accuracy: 0.0, Accum Accuracy: 47.899997144937515\n",
      "Validation Epoch: 1, Validation Minibatch: 620, Validation Loss: 3.362884044647217, Accuracy: 0.5, Accum Accuracy: 48.399997144937515\n",
      "Validation Epoch: 1, Validation Minibatch: 621, Validation Loss: 4.709410667419434, Accuracy: 0.09999999403953552, Accum Accuracy: 48.49999713897705\n",
      "Validation Epoch: 1, Validation Minibatch: 622, Validation Loss: 3.6208317279815674, Accuracy: 0.09999999403953552, Accum Accuracy: 48.599997133016586\n",
      "Validation Epoch: 1, Validation Minibatch: 623, Validation Loss: 3.2851920127868652, Accuracy: 0.19999998807907104, Accum Accuracy: 48.79999712109566\n",
      "Validation Epoch: 1, Validation Minibatch: 624, Validation Loss: 3.441199541091919, Accuracy: 0.0, Accum Accuracy: 48.79999712109566\n",
      "Validation Epoch: 1, Validation Minibatch: 625, Validation Loss: 3.209545612335205, Accuracy: 0.09999999403953552, Accum Accuracy: 48.89999711513519\n",
      "Validation Epoch: 1, Validation Minibatch: 626, Validation Loss: 3.9397575855255127, Accuracy: 0.0, Accum Accuracy: 48.89999711513519\n",
      "Validation Epoch: 1, Validation Minibatch: 627, Validation Loss: 4.572470664978027, Accuracy: 0.09999999403953552, Accum Accuracy: 48.99999710917473\n",
      "Validation Epoch: 1, Validation Minibatch: 628, Validation Loss: 3.677001476287842, Accuracy: 0.0, Accum Accuracy: 48.99999710917473\n",
      "Validation Epoch: 1, Validation Minibatch: 629, Validation Loss: 4.62355899810791, Accuracy: 0.19999998807907104, Accum Accuracy: 49.1999970972538\n",
      "Validation Epoch: 1, Validation Minibatch: 630, Validation Loss: 4.037292957305908, Accuracy: 0.0, Accum Accuracy: 49.1999970972538\n",
      "Validation Epoch: 1, Validation Minibatch: 631, Validation Loss: 3.5855534076690674, Accuracy: 0.0, Accum Accuracy: 49.1999970972538\n",
      "Validation Epoch: 1, Validation Minibatch: 632, Validation Loss: 3.8487319946289062, Accuracy: 0.09999999403953552, Accum Accuracy: 49.299997091293335\n",
      "Validation Epoch: 1, Validation Minibatch: 633, Validation Loss: 4.064374923706055, Accuracy: 0.09999999403953552, Accum Accuracy: 49.39999708533287\n",
      "Validation Epoch: 1, Validation Minibatch: 634, Validation Loss: 3.8361778259277344, Accuracy: 0.09999999403953552, Accum Accuracy: 49.499997079372406\n",
      "Validation Epoch: 1, Validation Minibatch: 635, Validation Loss: 3.394448757171631, Accuracy: 0.0, Accum Accuracy: 49.499997079372406\n",
      "Validation Epoch: 1, Validation Minibatch: 636, Validation Loss: 3.496769428253174, Accuracy: 0.09999999403953552, Accum Accuracy: 49.59999707341194\n",
      "Validation Epoch: 1, Validation Minibatch: 637, Validation Loss: 3.4125170707702637, Accuracy: 0.0, Accum Accuracy: 49.59999707341194\n",
      "Validation Epoch: 1, Validation Minibatch: 638, Validation Loss: 3.3500583171844482, Accuracy: 0.0, Accum Accuracy: 49.59999707341194\n",
      "Validation Epoch: 1, Validation Minibatch: 639, Validation Loss: 3.360809803009033, Accuracy: 0.09999999403953552, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 640, Validation Loss: 3.6150569915771484, Accuracy: 0.0, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 641, Validation Loss: 3.5903706550598145, Accuracy: 0.0, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 642, Validation Loss: 3.4952635765075684, Accuracy: 0.0, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 643, Validation Loss: 3.6902308464050293, Accuracy: 0.0, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 644, Validation Loss: 4.277262210845947, Accuracy: 0.0, Accum Accuracy: 49.69999706745148\n",
      "Validation Epoch: 1, Validation Minibatch: 645, Validation Loss: 3.852672576904297, Accuracy: 0.29999998211860657, Accum Accuracy: 49.999997049570084\n",
      "Validation Epoch: 1, Validation Minibatch: 646, Validation Loss: 3.0424513816833496, Accuracy: 0.19999998807907104, Accum Accuracy: 50.199997037649155\n",
      "Validation Epoch: 1, Validation Minibatch: 647, Validation Loss: 3.6181201934814453, Accuracy: 0.09999999403953552, Accum Accuracy: 50.29999703168869\n",
      "Validation Epoch: 1, Validation Minibatch: 648, Validation Loss: 3.262671709060669, Accuracy: 0.09999999403953552, Accum Accuracy: 50.399997025728226\n",
      "Validation Epoch: 1, Validation Minibatch: 649, Validation Loss: 3.1691346168518066, Accuracy: 0.09999999403953552, Accum Accuracy: 50.49999701976776\n",
      "Validation Epoch: 1, Validation Minibatch: 650, Validation Loss: 3.7553374767303467, Accuracy: 0.09999999403953552, Accum Accuracy: 50.5999970138073\n",
      "Validation Epoch: 1, Validation Minibatch: 651, Validation Loss: 3.1712441444396973, Accuracy: 0.09999999403953552, Accum Accuracy: 50.69999700784683\n",
      "Validation Epoch: 1, Validation Minibatch: 652, Validation Loss: 3.5569961071014404, Accuracy: 0.0, Accum Accuracy: 50.69999700784683\n",
      "Validation Epoch: 1, Validation Minibatch: 653, Validation Loss: 3.801665782928467, Accuracy: 0.09999999403953552, Accum Accuracy: 50.79999700188637\n",
      "Validation Epoch: 1, Validation Minibatch: 654, Validation Loss: 3.742502212524414, Accuracy: 0.09999999403953552, Accum Accuracy: 50.8999969959259\n",
      "Validation Epoch: 1, Validation Minibatch: 655, Validation Loss: 3.9563794136047363, Accuracy: 0.0, Accum Accuracy: 50.8999969959259\n",
      "Validation Epoch: 1, Validation Minibatch: 656, Validation Loss: 3.309415340423584, Accuracy: 0.29999998211860657, Accum Accuracy: 51.19999697804451\n",
      "Validation Epoch: 1, Validation Minibatch: 657, Validation Loss: 3.5253238677978516, Accuracy: 0.19999998807907104, Accum Accuracy: 51.39999696612358\n",
      "Validation Epoch: 1, Validation Minibatch: 658, Validation Loss: 4.2229905128479, Accuracy: 0.09999999403953552, Accum Accuracy: 51.49999696016312\n",
      "Validation Epoch: 1, Validation Minibatch: 659, Validation Loss: 3.893334150314331, Accuracy: 0.29999998211860657, Accum Accuracy: 51.79999694228172\n",
      "Validation Epoch: 1, Validation Minibatch: 660, Validation Loss: 3.5670692920684814, Accuracy: 0.0, Accum Accuracy: 51.79999694228172\n",
      "Validation Epoch: 1, Validation Minibatch: 661, Validation Loss: 3.3242180347442627, Accuracy: 0.19999998807907104, Accum Accuracy: 51.999996930360794\n",
      "Validation Epoch: 1, Validation Minibatch: 662, Validation Loss: 4.530322074890137, Accuracy: 0.0, Accum Accuracy: 51.999996930360794\n",
      "Validation Epoch: 1, Validation Minibatch: 663, Validation Loss: 4.240226745605469, Accuracy: 0.0, Accum Accuracy: 51.999996930360794\n",
      "Validation Epoch: 1, Validation Minibatch: 664, Validation Loss: 4.127468109130859, Accuracy: 0.0, Accum Accuracy: 51.999996930360794\n",
      "Validation Epoch: 1, Validation Minibatch: 665, Validation Loss: 3.9658915996551514, Accuracy: 0.09999999403953552, Accum Accuracy: 52.09999692440033\n",
      "Validation Epoch: 1, Validation Minibatch: 666, Validation Loss: 2.9337093830108643, Accuracy: 0.09999999403953552, Accum Accuracy: 52.199996918439865\n",
      "Validation Epoch: 1, Validation Minibatch: 667, Validation Loss: 3.360659122467041, Accuracy: 0.09999999403953552, Accum Accuracy: 52.2999969124794\n",
      "Validation Epoch: 1, Validation Minibatch: 668, Validation Loss: 3.8237662315368652, Accuracy: 0.09999999403953552, Accum Accuracy: 52.399996906518936\n",
      "Validation Epoch: 1, Validation Minibatch: 669, Validation Loss: 3.7752113342285156, Accuracy: 0.09999999403953552, Accum Accuracy: 52.49999690055847\n",
      "Validation Epoch: 1, Validation Minibatch: 670, Validation Loss: 3.6906466484069824, Accuracy: 0.09999999403953552, Accum Accuracy: 52.59999689459801\n",
      "Validation Epoch: 1, Validation Minibatch: 671, Validation Loss: 3.638774871826172, Accuracy: 0.09999999403953552, Accum Accuracy: 52.69999688863754\n",
      "Validation Epoch: 1, Validation Minibatch: 672, Validation Loss: 3.5052456855773926, Accuracy: 0.09999999403953552, Accum Accuracy: 52.79999688267708\n",
      "Validation Epoch: 1, Validation Minibatch: 673, Validation Loss: 4.01865291595459, Accuracy: 0.0, Accum Accuracy: 52.79999688267708\n",
      "Validation Epoch: 1, Validation Minibatch: 674, Validation Loss: 3.3809216022491455, Accuracy: 0.0, Accum Accuracy: 52.79999688267708\n",
      "Validation Epoch: 1, Validation Minibatch: 675, Validation Loss: 3.8890583515167236, Accuracy: 0.09999999403953552, Accum Accuracy: 52.899996876716614\n",
      "Validation Epoch: 1, Validation Minibatch: 676, Validation Loss: 3.975424289703369, Accuracy: 0.0, Accum Accuracy: 52.899996876716614\n",
      "Validation Epoch: 1, Validation Minibatch: 677, Validation Loss: 3.1348986625671387, Accuracy: 0.09999999403953552, Accum Accuracy: 52.99999687075615\n",
      "Validation Epoch: 1, Validation Minibatch: 678, Validation Loss: 3.169358491897583, Accuracy: 0.0, Accum Accuracy: 52.99999687075615\n",
      "Validation Epoch: 1, Validation Minibatch: 679, Validation Loss: 4.120306015014648, Accuracy: 0.09999999403953552, Accum Accuracy: 53.099996864795685\n",
      "Validation Epoch: 1, Validation Minibatch: 680, Validation Loss: 3.8336777687072754, Accuracy: 0.0, Accum Accuracy: 53.099996864795685\n",
      "Validation Epoch: 1, Validation Minibatch: 681, Validation Loss: 3.337533950805664, Accuracy: 0.09999999403953552, Accum Accuracy: 53.19999685883522\n",
      "Validation Epoch: 1, Validation Minibatch: 682, Validation Loss: 4.209006309509277, Accuracy: 0.0, Accum Accuracy: 53.19999685883522\n",
      "Validation Epoch: 1, Validation Minibatch: 683, Validation Loss: 4.365756988525391, Accuracy: 0.19999998807907104, Accum Accuracy: 53.39999684691429\n",
      "Validation Epoch: 1, Validation Minibatch: 684, Validation Loss: 3.4273018836975098, Accuracy: 0.19999998807907104, Accum Accuracy: 53.59999683499336\n",
      "Validation Epoch: 1, Validation Minibatch: 685, Validation Loss: 3.415709972381592, Accuracy: 0.0, Accum Accuracy: 53.59999683499336\n",
      "Validation Epoch: 1, Validation Minibatch: 686, Validation Loss: 3.0193862915039062, Accuracy: 0.09999999403953552, Accum Accuracy: 53.6999968290329\n",
      "Validation Epoch: 1, Validation Minibatch: 687, Validation Loss: 3.4360873699188232, Accuracy: 0.0, Accum Accuracy: 53.6999968290329\n",
      "Validation Epoch: 1, Validation Minibatch: 688, Validation Loss: 4.406576633453369, Accuracy: 0.09999999403953552, Accum Accuracy: 53.79999682307243\n",
      "Validation Epoch: 1, Validation Minibatch: 689, Validation Loss: 3.4056496620178223, Accuracy: 0.09999999403953552, Accum Accuracy: 53.89999681711197\n",
      "Validation Epoch: 1, Validation Minibatch: 690, Validation Loss: 3.4021363258361816, Accuracy: 0.0, Accum Accuracy: 53.89999681711197\n",
      "Validation Epoch: 1, Validation Minibatch: 691, Validation Loss: 3.5862724781036377, Accuracy: 0.29999998211860657, Accum Accuracy: 54.199996799230576\n",
      "Validation Epoch: 1, Validation Minibatch: 692, Validation Loss: 4.074603080749512, Accuracy: 0.0, Accum Accuracy: 54.199996799230576\n",
      "Validation Epoch: 1, Validation Minibatch: 693, Validation Loss: 3.565865993499756, Accuracy: 0.19999998807907104, Accum Accuracy: 54.39999678730965\n",
      "Validation Epoch: 1, Validation Minibatch: 694, Validation Loss: 3.792236804962158, Accuracy: 0.09999999403953552, Accum Accuracy: 54.49999678134918\n",
      "Validation Epoch: 1, Validation Minibatch: 695, Validation Loss: 3.859487533569336, Accuracy: 0.29999998211860657, Accum Accuracy: 54.79999676346779\n",
      "Validation Epoch: 1, Validation Minibatch: 696, Validation Loss: 3.9883644580841064, Accuracy: 0.09999999403953552, Accum Accuracy: 54.899996757507324\n",
      "Validation Epoch: 1, Validation Minibatch: 697, Validation Loss: 4.241174221038818, Accuracy: 0.09999999403953552, Accum Accuracy: 54.99999675154686\n",
      "Validation Epoch: 1, Validation Minibatch: 698, Validation Loss: 3.3378703594207764, Accuracy: 0.19999998807907104, Accum Accuracy: 55.19999673962593\n",
      "Validation Epoch: 1, Validation Minibatch: 699, Validation Loss: 4.798515319824219, Accuracy: 0.0, Accum Accuracy: 55.19999673962593\n",
      "Validation Epoch: 1, Validation Minibatch: 700, Validation Loss: 4.1839399337768555, Accuracy: 0.0, Accum Accuracy: 55.19999673962593\n",
      "Validation Epoch: 1, Validation Minibatch: 701, Validation Loss: 3.6092941761016846, Accuracy: 0.0, Accum Accuracy: 55.19999673962593\n",
      "Validation Epoch: 1, Validation Minibatch: 702, Validation Loss: 3.1494154930114746, Accuracy: 0.09999999403953552, Accum Accuracy: 55.299996733665466\n",
      "Validation Epoch: 1, Validation Minibatch: 703, Validation Loss: 3.5911757946014404, Accuracy: 0.19999998807907104, Accum Accuracy: 55.49999672174454\n",
      "Validation Epoch: 1, Validation Minibatch: 704, Validation Loss: 4.197545528411865, Accuracy: 0.09999999403953552, Accum Accuracy: 55.59999671578407\n",
      "Validation Epoch: 1, Validation Minibatch: 705, Validation Loss: 4.1792707443237305, Accuracy: 0.09999999403953552, Accum Accuracy: 55.69999670982361\n",
      "Validation Epoch: 1, Validation Minibatch: 706, Validation Loss: 4.295284748077393, Accuracy: 0.09999999403953552, Accum Accuracy: 55.799996703863144\n",
      "Validation Epoch: 1, Validation Minibatch: 707, Validation Loss: 3.479445695877075, Accuracy: 0.09999999403953552, Accum Accuracy: 55.89999669790268\n",
      "Validation Epoch: 1, Validation Minibatch: 708, Validation Loss: 3.8048911094665527, Accuracy: 0.0, Accum Accuracy: 55.89999669790268\n",
      "Validation Epoch: 1, Validation Minibatch: 709, Validation Loss: 3.2743782997131348, Accuracy: 0.09999999403953552, Accum Accuracy: 55.999996691942215\n",
      "Validation Epoch: 1, Validation Minibatch: 710, Validation Loss: 3.67069935798645, Accuracy: 0.0, Accum Accuracy: 55.999996691942215\n",
      "Validation Epoch: 1, Validation Minibatch: 711, Validation Loss: 3.1032016277313232, Accuracy: 0.0, Accum Accuracy: 55.999996691942215\n",
      "Validation Epoch: 1, Validation Minibatch: 712, Validation Loss: 3.6564781665802, Accuracy: 0.0, Accum Accuracy: 55.999996691942215\n",
      "Validation Epoch: 1, Validation Minibatch: 713, Validation Loss: 4.296938419342041, Accuracy: 0.09999999403953552, Accum Accuracy: 56.09999668598175\n",
      "Validation Epoch: 1, Validation Minibatch: 714, Validation Loss: 3.663503646850586, Accuracy: 0.19999998807907104, Accum Accuracy: 56.29999667406082\n",
      "Validation Epoch: 1, Validation Minibatch: 715, Validation Loss: 3.0957865715026855, Accuracy: 0.29999998211860657, Accum Accuracy: 56.59999665617943\n",
      "Validation Epoch: 1, Validation Minibatch: 716, Validation Loss: 3.7280526161193848, Accuracy: 0.0, Accum Accuracy: 56.59999665617943\n",
      "Validation Epoch: 1, Validation Minibatch: 717, Validation Loss: 3.4136948585510254, Accuracy: 0.19999998807907104, Accum Accuracy: 56.7999966442585\n",
      "Validation Epoch: 1, Validation Minibatch: 718, Validation Loss: 4.2779340744018555, Accuracy: 0.0, Accum Accuracy: 56.7999966442585\n",
      "Validation Epoch: 1, Validation Minibatch: 719, Validation Loss: 3.5044047832489014, Accuracy: 0.09999999403953552, Accum Accuracy: 56.899996638298035\n",
      "Validation Epoch: 1, Validation Minibatch: 720, Validation Loss: 4.018649578094482, Accuracy: 0.09999999403953552, Accum Accuracy: 56.99999663233757\n",
      "Validation Epoch: 1, Validation Minibatch: 721, Validation Loss: 3.3463821411132812, Accuracy: 0.09999999403953552, Accum Accuracy: 57.099996626377106\n",
      "Validation Epoch: 1, Validation Minibatch: 722, Validation Loss: 3.549391269683838, Accuracy: 0.19999998807907104, Accum Accuracy: 57.29999661445618\n",
      "Validation Epoch: 1, Validation Minibatch: 723, Validation Loss: 3.438828229904175, Accuracy: 0.29999998211860657, Accum Accuracy: 57.59999659657478\n",
      "Validation Epoch: 1, Validation Minibatch: 724, Validation Loss: 3.925020694732666, Accuracy: 0.0, Accum Accuracy: 57.59999659657478\n",
      "Validation Epoch: 1, Validation Minibatch: 725, Validation Loss: 3.9082870483398438, Accuracy: 0.09999999403953552, Accum Accuracy: 57.69999659061432\n",
      "Validation Epoch: 1, Validation Minibatch: 726, Validation Loss: 4.29819393157959, Accuracy: 0.0, Accum Accuracy: 57.69999659061432\n",
      "Validation Epoch: 1, Validation Minibatch: 727, Validation Loss: 3.0836918354034424, Accuracy: 0.0, Accum Accuracy: 57.69999659061432\n",
      "Validation Epoch: 1, Validation Minibatch: 728, Validation Loss: 3.112715244293213, Accuracy: 0.09999999403953552, Accum Accuracy: 57.799996584653854\n",
      "Validation Epoch: 1, Validation Minibatch: 729, Validation Loss: 3.712886333465576, Accuracy: 0.0, Accum Accuracy: 57.799996584653854\n",
      "Validation Epoch: 1, Validation Minibatch: 730, Validation Loss: 3.941293239593506, Accuracy: 0.09999999403953552, Accum Accuracy: 57.89999657869339\n",
      "Validation Epoch: 1, Validation Minibatch: 731, Validation Loss: 3.86360239982605, Accuracy: 0.0, Accum Accuracy: 57.89999657869339\n",
      "Validation Epoch: 1, Validation Minibatch: 732, Validation Loss: 3.98553466796875, Accuracy: 0.0, Accum Accuracy: 57.89999657869339\n",
      "Validation Epoch: 1, Validation Minibatch: 733, Validation Loss: 3.419656753540039, Accuracy: 0.09999999403953552, Accum Accuracy: 57.999996572732925\n",
      "Validation Epoch: 1, Validation Minibatch: 734, Validation Loss: 3.973649501800537, Accuracy: 0.0, Accum Accuracy: 57.999996572732925\n",
      "Validation Epoch: 1, Validation Minibatch: 735, Validation Loss: 4.111607551574707, Accuracy: 0.09999999403953552, Accum Accuracy: 58.09999656677246\n",
      "Validation Epoch: 1, Validation Minibatch: 736, Validation Loss: 3.534940242767334, Accuracy: 0.19999998807907104, Accum Accuracy: 58.29999655485153\n",
      "Validation Epoch: 1, Validation Minibatch: 737, Validation Loss: 3.590174913406372, Accuracy: 0.0, Accum Accuracy: 58.29999655485153\n",
      "Validation Epoch: 1, Validation Minibatch: 738, Validation Loss: 4.114933490753174, Accuracy: 0.09999999403953552, Accum Accuracy: 58.39999654889107\n",
      "Validation Epoch: 1, Validation Minibatch: 739, Validation Loss: 3.594635009765625, Accuracy: 0.0, Accum Accuracy: 58.39999654889107\n",
      "Validation Epoch: 1, Validation Minibatch: 740, Validation Loss: 3.9437172412872314, Accuracy: 0.19999998807907104, Accum Accuracy: 58.59999653697014\n",
      "Validation Epoch: 1, Validation Minibatch: 741, Validation Loss: 3.2368175983428955, Accuracy: 0.19999998807907104, Accum Accuracy: 58.79999652504921\n",
      "Validation Epoch: 1, Validation Minibatch: 742, Validation Loss: 3.319467544555664, Accuracy: 0.29999998211860657, Accum Accuracy: 59.099996507167816\n",
      "Validation Epoch: 1, Validation Minibatch: 743, Validation Loss: 3.776519775390625, Accuracy: 0.0, Accum Accuracy: 59.099996507167816\n",
      "Validation Epoch: 1, Validation Minibatch: 744, Validation Loss: 3.905712604522705, Accuracy: 0.09999999403953552, Accum Accuracy: 59.19999650120735\n",
      "Validation Epoch: 1, Validation Minibatch: 745, Validation Loss: 3.349942684173584, Accuracy: 0.0, Accum Accuracy: 59.19999650120735\n",
      "Validation Epoch: 1, Validation Minibatch: 746, Validation Loss: 3.8813138008117676, Accuracy: 0.19999998807907104, Accum Accuracy: 59.39999648928642\n",
      "Validation Epoch: 1, Validation Minibatch: 747, Validation Loss: 4.442063808441162, Accuracy: 0.09999999403953552, Accum Accuracy: 59.49999648332596\n",
      "Validation Epoch: 1, Validation Minibatch: 748, Validation Loss: 4.14625883102417, Accuracy: 0.0, Accum Accuracy: 59.49999648332596\n",
      "Validation Epoch: 1, Validation Minibatch: 749, Validation Loss: 3.7704710960388184, Accuracy: 0.09999999403953552, Accum Accuracy: 59.599996477365494\n",
      "Validation Epoch: 1, Validation Minibatch: 750, Validation Loss: 3.124056816101074, Accuracy: 0.0, Accum Accuracy: 59.599996477365494\n",
      "Validation Epoch: 1, Validation Minibatch: 751, Validation Loss: 4.288486480712891, Accuracy: 0.09999999403953552, Accum Accuracy: 59.69999647140503\n",
      "Validation Epoch: 1, Validation Minibatch: 752, Validation Loss: 3.5627365112304688, Accuracy: 0.29999998211860657, Accum Accuracy: 59.999996453523636\n",
      "Validation Epoch: 1, Validation Minibatch: 753, Validation Loss: 3.2784202098846436, Accuracy: 0.29999998211860657, Accum Accuracy: 60.29999643564224\n",
      "Validation Epoch: 1, Validation Minibatch: 754, Validation Loss: 3.2757954597473145, Accuracy: 0.09999999403953552, Accum Accuracy: 60.39999642968178\n",
      "Validation Epoch: 1, Validation Minibatch: 755, Validation Loss: 4.190383434295654, Accuracy: 0.09999999403953552, Accum Accuracy: 60.49999642372131\n",
      "Validation Epoch: 1, Validation Minibatch: 756, Validation Loss: 3.771113634109497, Accuracy: 0.0, Accum Accuracy: 60.49999642372131\n",
      "Validation Epoch: 1, Validation Minibatch: 757, Validation Loss: 3.861844301223755, Accuracy: 0.0, Accum Accuracy: 60.49999642372131\n",
      "Validation Epoch: 1, Validation Minibatch: 758, Validation Loss: 3.478174924850464, Accuracy: 0.29999998211860657, Accum Accuracy: 60.79999640583992\n",
      "Validation Epoch: 1, Validation Minibatch: 759, Validation Loss: 3.933577060699463, Accuracy: 0.19999998807907104, Accum Accuracy: 60.99999639391899\n",
      "Validation Epoch: 1, Validation Minibatch: 760, Validation Loss: 3.9443325996398926, Accuracy: 0.19999998807907104, Accum Accuracy: 61.19999638199806\n",
      "Validation Epoch: 1, Validation Minibatch: 761, Validation Loss: 3.4154484272003174, Accuracy: 0.0, Accum Accuracy: 61.19999638199806\n",
      "Validation Epoch: 1, Validation Minibatch: 762, Validation Loss: 3.8135437965393066, Accuracy: 0.0, Accum Accuracy: 61.19999638199806\n",
      "Validation Epoch: 1, Validation Minibatch: 763, Validation Loss: 3.502350330352783, Accuracy: 0.09999999403953552, Accum Accuracy: 61.2999963760376\n",
      "Validation Epoch: 1, Validation Minibatch: 764, Validation Loss: 3.5015830993652344, Accuracy: 0.29999998211860657, Accum Accuracy: 61.599996358156204\n",
      "Validation Epoch: 1, Validation Minibatch: 765, Validation Loss: 2.911450147628784, Accuracy: 0.0, Accum Accuracy: 61.599996358156204\n",
      "Validation Epoch: 1, Validation Minibatch: 766, Validation Loss: 3.958101987838745, Accuracy: 0.0, Accum Accuracy: 61.599996358156204\n",
      "Validation Epoch: 1, Validation Minibatch: 767, Validation Loss: 3.50703763961792, Accuracy: 0.09999999403953552, Accum Accuracy: 61.69999635219574\n",
      "Validation Epoch: 1, Validation Minibatch: 768, Validation Loss: 2.9703240394592285, Accuracy: 0.09999999403953552, Accum Accuracy: 61.799996346235275\n",
      "Validation Epoch: 1, Validation Minibatch: 769, Validation Loss: 3.7137844562530518, Accuracy: 0.09999999403953552, Accum Accuracy: 61.89999634027481\n",
      "Validation Epoch: 1, Validation Minibatch: 770, Validation Loss: 4.142346382141113, Accuracy: 0.09999999403953552, Accum Accuracy: 61.999996334314346\n",
      "Validation Epoch: 1, Validation Minibatch: 771, Validation Loss: 3.5963635444641113, Accuracy: 0.09999999403953552, Accum Accuracy: 62.09999632835388\n",
      "Validation Epoch: 1, Validation Minibatch: 772, Validation Loss: 3.2446389198303223, Accuracy: 0.09999999403953552, Accum Accuracy: 62.19999632239342\n",
      "Validation Epoch: 1, Validation Minibatch: 773, Validation Loss: 4.346769332885742, Accuracy: 0.0, Accum Accuracy: 62.19999632239342\n",
      "Validation Epoch: 1, Validation Minibatch: 774, Validation Loss: 3.2907538414001465, Accuracy: 0.0, Accum Accuracy: 62.19999632239342\n",
      "Validation Epoch: 1, Validation Minibatch: 775, Validation Loss: 3.9185242652893066, Accuracy: 0.29999998211860657, Accum Accuracy: 62.499996304512024\n",
      "Validation Epoch: 1, Validation Minibatch: 776, Validation Loss: 3.9227843284606934, Accuracy: 0.19999998807907104, Accum Accuracy: 62.699996292591095\n",
      "Validation Epoch: 1, Validation Minibatch: 777, Validation Loss: 3.5222601890563965, Accuracy: 0.0, Accum Accuracy: 62.699996292591095\n",
      "Validation Epoch: 1, Validation Minibatch: 778, Validation Loss: 3.0049514770507812, Accuracy: 0.0, Accum Accuracy: 62.699996292591095\n",
      "Validation Epoch: 1, Validation Minibatch: 779, Validation Loss: 2.8955817222595215, Accuracy: 0.29999998211860657, Accum Accuracy: 62.9999962747097\n",
      "Validation Epoch: 1, Validation Minibatch: 780, Validation Loss: 3.8790249824523926, Accuracy: 0.0, Accum Accuracy: 62.9999962747097\n",
      "Validation Epoch: 1, Validation Minibatch: 781, Validation Loss: 3.4404613971710205, Accuracy: 0.09999999403953552, Accum Accuracy: 63.09999626874924\n",
      "Validation Epoch: 1, Validation Minibatch: 782, Validation Loss: 4.310116291046143, Accuracy: 0.0, Accum Accuracy: 63.09999626874924\n",
      "Validation Epoch: 1, Validation Minibatch: 783, Validation Loss: 4.353931427001953, Accuracy: 0.09999999403953552, Accum Accuracy: 63.19999626278877\n",
      "Validation Epoch: 1, Validation Minibatch: 784, Validation Loss: 4.451567649841309, Accuracy: 0.19999998807907104, Accum Accuracy: 63.399996250867844\n",
      "Validation Epoch: 1, Validation Minibatch: 785, Validation Loss: 4.152379512786865, Accuracy: 0.09999999403953552, Accum Accuracy: 63.49999624490738\n",
      "Validation Epoch: 1, Validation Minibatch: 786, Validation Loss: 3.7650980949401855, Accuracy: 0.09999999403953552, Accum Accuracy: 63.599996238946915\n",
      "Validation Epoch: 1, Validation Minibatch: 787, Validation Loss: 3.390071392059326, Accuracy: 0.09999999403953552, Accum Accuracy: 63.69999623298645\n",
      "Validation Epoch: 1, Validation Minibatch: 788, Validation Loss: 3.9814391136169434, Accuracy: 0.0, Accum Accuracy: 63.69999623298645\n",
      "Validation Epoch: 1, Validation Minibatch: 789, Validation Loss: 3.967146396636963, Accuracy: 0.0, Accum Accuracy: 63.69999623298645\n",
      "Validation Epoch: 1, Validation Minibatch: 790, Validation Loss: 3.8944942951202393, Accuracy: 0.0, Accum Accuracy: 63.69999623298645\n",
      "Validation Epoch: 1, Validation Minibatch: 791, Validation Loss: 3.4097137451171875, Accuracy: 0.19999998807907104, Accum Accuracy: 63.89999622106552\n",
      "Validation Epoch: 1, Validation Minibatch: 792, Validation Loss: 3.9303841590881348, Accuracy: 0.0, Accum Accuracy: 63.89999622106552\n",
      "Validation Epoch: 1, Validation Minibatch: 793, Validation Loss: 3.799480438232422, Accuracy: 0.09999999403953552, Accum Accuracy: 63.99999621510506\n",
      "Validation Epoch: 1, Validation Minibatch: 794, Validation Loss: 3.6567063331604004, Accuracy: 0.0, Accum Accuracy: 63.99999621510506\n",
      "Validation Epoch: 1, Validation Minibatch: 795, Validation Loss: 3.259983777999878, Accuracy: 0.0, Accum Accuracy: 63.99999621510506\n",
      "Validation Epoch: 1, Validation Minibatch: 796, Validation Loss: 4.241894721984863, Accuracy: 0.0, Accum Accuracy: 63.99999621510506\n",
      "Validation Epoch: 1, Validation Minibatch: 797, Validation Loss: 3.6401283740997314, Accuracy: 0.09999999403953552, Accum Accuracy: 64.09999620914459\n",
      "Validation Epoch: 1, Validation Minibatch: 798, Validation Loss: 3.3137385845184326, Accuracy: 0.09999999403953552, Accum Accuracy: 64.19999620318413\n",
      "Validation Epoch: 1, Validation Minibatch: 799, Validation Loss: 4.067188262939453, Accuracy: 0.0, Accum Accuracy: 64.19999620318413\n",
      "Validation Epoch: 1, Validation Minibatch: 800, Validation Loss: 3.7817814350128174, Accuracy: 0.0, Accum Accuracy: 64.19999620318413\n",
      "Validation Epoch: 1, Validation Minibatch: 801, Validation Loss: 4.344367027282715, Accuracy: 0.09999999403953552, Accum Accuracy: 64.29999619722366\n",
      "Validation Epoch: 1, Validation Minibatch: 802, Validation Loss: 4.251890659332275, Accuracy: 0.09999999403953552, Accum Accuracy: 64.3999961912632\n",
      "Validation Epoch: 1, Validation Minibatch: 803, Validation Loss: 3.4702281951904297, Accuracy: 0.09999999403953552, Accum Accuracy: 64.49999618530273\n",
      "Validation Epoch: 1, Validation Minibatch: 804, Validation Loss: 4.144130706787109, Accuracy: 0.09999999403953552, Accum Accuracy: 64.59999617934227\n",
      "Validation Epoch: 1, Validation Minibatch: 805, Validation Loss: 3.8679263591766357, Accuracy: 0.09999999403953552, Accum Accuracy: 64.6999961733818\n",
      "Validation Epoch: 1, Validation Minibatch: 806, Validation Loss: 3.633155345916748, Accuracy: 0.19999998807907104, Accum Accuracy: 64.89999616146088\n",
      "Validation Epoch: 1, Validation Minibatch: 807, Validation Loss: 4.030350685119629, Accuracy: 0.0, Accum Accuracy: 64.89999616146088\n",
      "Validation Epoch: 1, Validation Minibatch: 808, Validation Loss: 3.91471791267395, Accuracy: 0.0, Accum Accuracy: 64.89999616146088\n",
      "Validation Epoch: 1, Validation Minibatch: 809, Validation Loss: 3.482037305831909, Accuracy: 0.09999999403953552, Accum Accuracy: 64.99999615550041\n",
      "Validation Epoch: 1, Validation Minibatch: 810, Validation Loss: 4.028499126434326, Accuracy: 0.09999999403953552, Accum Accuracy: 65.09999614953995\n",
      "Validation Epoch: 1, Validation Minibatch: 811, Validation Loss: 3.642880916595459, Accuracy: 0.0, Accum Accuracy: 65.09999614953995\n",
      "Validation Epoch: 1, Validation Minibatch: 812, Validation Loss: 3.4690818786621094, Accuracy: 0.0, Accum Accuracy: 65.09999614953995\n",
      "Validation Epoch: 1, Validation Minibatch: 813, Validation Loss: 3.4830212593078613, Accuracy: 0.0, Accum Accuracy: 65.09999614953995\n",
      "Validation Epoch: 1, Validation Minibatch: 814, Validation Loss: 4.3621368408203125, Accuracy: 0.09999999403953552, Accum Accuracy: 65.19999614357948\n",
      "Validation Epoch: 1, Validation Minibatch: 815, Validation Loss: 4.046529769897461, Accuracy: 0.0, Accum Accuracy: 65.19999614357948\n",
      "Validation Epoch: 1, Validation Minibatch: 816, Validation Loss: 4.263802528381348, Accuracy: 0.0, Accum Accuracy: 65.19999614357948\n",
      "Validation Epoch: 1, Validation Minibatch: 817, Validation Loss: 3.914062023162842, Accuracy: 0.09999999403953552, Accum Accuracy: 65.29999613761902\n",
      "Validation Epoch: 1, Validation Minibatch: 818, Validation Loss: 4.553226470947266, Accuracy: 0.0, Accum Accuracy: 65.29999613761902\n",
      "Validation Epoch: 1, Validation Minibatch: 819, Validation Loss: 3.3888192176818848, Accuracy: 0.3999999761581421, Accum Accuracy: 65.69999611377716\n",
      "Validation Epoch: 1, Validation Minibatch: 820, Validation Loss: 3.5395636558532715, Accuracy: 0.0, Accum Accuracy: 65.69999611377716\n",
      "Validation Epoch: 1, Validation Minibatch: 821, Validation Loss: 3.125828504562378, Accuracy: 0.09999999403953552, Accum Accuracy: 65.7999961078167\n",
      "Validation Epoch: 1, Validation Minibatch: 822, Validation Loss: 4.906737327575684, Accuracy: 0.09999999403953552, Accum Accuracy: 65.89999610185623\n",
      "Validation Epoch: 1, Validation Minibatch: 823, Validation Loss: 4.586674690246582, Accuracy: 0.0, Accum Accuracy: 65.89999610185623\n",
      "Validation Epoch: 1, Validation Minibatch: 824, Validation Loss: 3.4553985595703125, Accuracy: 0.09999999403953552, Accum Accuracy: 65.99999609589577\n",
      "Validation Epoch: 1, Validation Minibatch: 825, Validation Loss: 3.9546616077423096, Accuracy: 0.09999999403953552, Accum Accuracy: 66.0999960899353\n",
      "Validation Epoch: 1, Validation Minibatch: 826, Validation Loss: 4.587304592132568, Accuracy: 0.0, Accum Accuracy: 66.0999960899353\n",
      "Validation Epoch: 1, Validation Minibatch: 827, Validation Loss: 3.901319980621338, Accuracy: 0.09999999403953552, Accum Accuracy: 66.19999608397484\n",
      "Validation Epoch: 1, Validation Minibatch: 828, Validation Loss: 4.362465858459473, Accuracy: 0.0, Accum Accuracy: 66.19999608397484\n",
      "Validation Epoch: 1, Validation Minibatch: 829, Validation Loss: 3.4724793434143066, Accuracy: 0.0, Accum Accuracy: 66.19999608397484\n",
      "Validation Epoch: 1, Validation Minibatch: 830, Validation Loss: 3.544598340988159, Accuracy: 0.09999999403953552, Accum Accuracy: 66.29999607801437\n",
      "Validation Epoch: 1, Validation Minibatch: 831, Validation Loss: 4.029821395874023, Accuracy: 0.0, Accum Accuracy: 66.29999607801437\n",
      "Validation Epoch: 1, Validation Minibatch: 832, Validation Loss: 3.6442809104919434, Accuracy: 0.0, Accum Accuracy: 66.29999607801437\n",
      "Validation Epoch: 1, Validation Minibatch: 833, Validation Loss: 3.6145710945129395, Accuracy: 0.09999999403953552, Accum Accuracy: 66.39999607205391\n",
      "Validation Epoch: 1, Validation Minibatch: 834, Validation Loss: 3.855673313140869, Accuracy: 0.09999999403953552, Accum Accuracy: 66.49999606609344\n",
      "Validation Epoch: 1, Validation Minibatch: 835, Validation Loss: 3.2928595542907715, Accuracy: 0.09999999403953552, Accum Accuracy: 66.59999606013298\n",
      "Validation Epoch: 1, Validation Minibatch: 836, Validation Loss: 3.7184600830078125, Accuracy: 0.0, Accum Accuracy: 66.59999606013298\n",
      "Validation Epoch: 1, Validation Minibatch: 837, Validation Loss: 3.6763644218444824, Accuracy: 0.29999998211860657, Accum Accuracy: 66.89999604225159\n",
      "Validation Epoch: 1, Validation Minibatch: 838, Validation Loss: 4.040330410003662, Accuracy: 0.09999999403953552, Accum Accuracy: 66.99999603629112\n",
      "Validation Epoch: 1, Validation Minibatch: 839, Validation Loss: 4.297188758850098, Accuracy: 0.09999999403953552, Accum Accuracy: 67.09999603033066\n",
      "Validation Epoch: 1, Validation Minibatch: 840, Validation Loss: 3.4039738178253174, Accuracy: 0.0, Accum Accuracy: 67.09999603033066\n",
      "Validation Epoch: 1, Validation Minibatch: 841, Validation Loss: 3.346864700317383, Accuracy: 0.0, Accum Accuracy: 67.09999603033066\n",
      "Validation Epoch: 1, Validation Minibatch: 842, Validation Loss: 3.410823345184326, Accuracy: 0.19999998807907104, Accum Accuracy: 67.29999601840973\n",
      "Validation Epoch: 1, Validation Minibatch: 843, Validation Loss: 4.124807834625244, Accuracy: 0.09999999403953552, Accum Accuracy: 67.39999601244926\n",
      "Validation Epoch: 1, Validation Minibatch: 844, Validation Loss: 4.329357624053955, Accuracy: 0.09999999403953552, Accum Accuracy: 67.4999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 845, Validation Loss: 4.064165115356445, Accuracy: 0.0, Accum Accuracy: 67.4999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 846, Validation Loss: 3.688397169113159, Accuracy: 0.0, Accum Accuracy: 67.4999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 847, Validation Loss: 3.464721202850342, Accuracy: 0.0, Accum Accuracy: 67.4999960064888\n",
      "Validation Epoch: 1, Validation Minibatch: 848, Validation Loss: 3.488110303878784, Accuracy: 0.19999998807907104, Accum Accuracy: 67.69999599456787\n",
      "Validation Epoch: 1, Validation Minibatch: 849, Validation Loss: 3.3138327598571777, Accuracy: 0.0, Accum Accuracy: 67.69999599456787\n",
      "Validation Epoch: 1, Validation Minibatch: 850, Validation Loss: 3.4681715965270996, Accuracy: 0.29999998211860657, Accum Accuracy: 67.99999597668648\n",
      "Validation Epoch: 1, Validation Minibatch: 851, Validation Loss: 3.321596622467041, Accuracy: 0.19999998807907104, Accum Accuracy: 68.19999596476555\n",
      "Validation Epoch: 1, Validation Minibatch: 852, Validation Loss: 3.620751142501831, Accuracy: 0.09999999403953552, Accum Accuracy: 68.29999595880508\n",
      "Validation Epoch: 1, Validation Minibatch: 853, Validation Loss: 3.368762493133545, Accuracy: 0.0, Accum Accuracy: 68.29999595880508\n",
      "Validation Epoch: 1, Validation Minibatch: 854, Validation Loss: 3.280076503753662, Accuracy: 0.19999998807907104, Accum Accuracy: 68.49999594688416\n",
      "Validation Epoch: 1, Validation Minibatch: 855, Validation Loss: 3.4321606159210205, Accuracy: 0.0, Accum Accuracy: 68.49999594688416\n",
      "Validation Epoch: 1, Validation Minibatch: 856, Validation Loss: 3.850189208984375, Accuracy: 0.0, Accum Accuracy: 68.49999594688416\n",
      "Validation Epoch: 1, Validation Minibatch: 857, Validation Loss: 3.607455015182495, Accuracy: 0.0, Accum Accuracy: 68.49999594688416\n",
      "Validation Epoch: 1, Validation Minibatch: 858, Validation Loss: 3.5834743976593018, Accuracy: 0.09999999403953552, Accum Accuracy: 68.59999594092369\n",
      "Validation Epoch: 1, Validation Minibatch: 859, Validation Loss: 3.5160744190216064, Accuracy: 0.09999999403953552, Accum Accuracy: 68.69999593496323\n",
      "Validation Epoch: 1, Validation Minibatch: 860, Validation Loss: 3.6130454540252686, Accuracy: 0.09999999403953552, Accum Accuracy: 68.79999592900276\n",
      "Validation Epoch: 1, Validation Minibatch: 861, Validation Loss: 3.9892868995666504, Accuracy: 0.09999999403953552, Accum Accuracy: 68.8999959230423\n",
      "Validation Epoch: 1, Validation Minibatch: 862, Validation Loss: 3.804560899734497, Accuracy: 0.0, Accum Accuracy: 68.8999959230423\n",
      "Validation Epoch: 1, Validation Minibatch: 863, Validation Loss: 3.208508014678955, Accuracy: 0.0, Accum Accuracy: 68.8999959230423\n",
      "Validation Epoch: 1, Validation Minibatch: 864, Validation Loss: 2.920948028564453, Accuracy: 0.19999998807907104, Accum Accuracy: 69.09999591112137\n",
      "Validation Epoch: 1, Validation Minibatch: 865, Validation Loss: 3.341944456100464, Accuracy: 0.0, Accum Accuracy: 69.09999591112137\n",
      "Validation Epoch: 1, Validation Minibatch: 866, Validation Loss: 3.431922197341919, Accuracy: 0.19999998807907104, Accum Accuracy: 69.29999589920044\n",
      "Validation Epoch: 1, Validation Minibatch: 867, Validation Loss: 3.219900131225586, Accuracy: 0.09999999403953552, Accum Accuracy: 69.39999589323997\n",
      "Validation Epoch: 1, Validation Minibatch: 868, Validation Loss: 3.589857816696167, Accuracy: 0.19999998807907104, Accum Accuracy: 69.59999588131905\n",
      "Validation Epoch: 1, Validation Minibatch: 869, Validation Loss: 4.011711120605469, Accuracy: 0.09999999403953552, Accum Accuracy: 69.69999587535858\n",
      "Validation Epoch: 1, Validation Minibatch: 870, Validation Loss: 3.6522746086120605, Accuracy: 0.0, Accum Accuracy: 69.69999587535858\n",
      "Validation Epoch: 1, Validation Minibatch: 871, Validation Loss: 3.759265422821045, Accuracy: 0.19999998807907104, Accum Accuracy: 69.89999586343765\n",
      "Validation Epoch: 1, Validation Minibatch: 872, Validation Loss: 2.9474751949310303, Accuracy: 0.19999998807907104, Accum Accuracy: 70.09999585151672\n",
      "Validation Epoch: 1, Validation Minibatch: 873, Validation Loss: 5.124574184417725, Accuracy: 0.0, Accum Accuracy: 70.09999585151672\n",
      "Validation Epoch: 1, Validation Minibatch: 874, Validation Loss: 3.748560667037964, Accuracy: 0.0, Accum Accuracy: 70.09999585151672\n",
      "Validation Epoch: 1, Validation Minibatch: 875, Validation Loss: 3.3693530559539795, Accuracy: 0.0, Accum Accuracy: 70.09999585151672\n",
      "Validation Epoch: 1, Validation Minibatch: 876, Validation Loss: 3.330353260040283, Accuracy: 0.0, Accum Accuracy: 70.09999585151672\n",
      "Validation Epoch: 1, Validation Minibatch: 877, Validation Loss: 4.223143100738525, Accuracy: 0.09999999403953552, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 878, Validation Loss: 4.182962417602539, Accuracy: 0.0, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 879, Validation Loss: 3.9259448051452637, Accuracy: 0.0, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 880, Validation Loss: 3.984572649002075, Accuracy: 0.0, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 881, Validation Loss: 4.004575729370117, Accuracy: 0.0, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 882, Validation Loss: 3.6765124797821045, Accuracy: 0.0, Accum Accuracy: 70.19999584555626\n",
      "Validation Epoch: 1, Validation Minibatch: 883, Validation Loss: 3.6900031566619873, Accuracy: 0.19999998807907104, Accum Accuracy: 70.39999583363533\n",
      "Validation Epoch: 1, Validation Minibatch: 884, Validation Loss: 3.9457759857177734, Accuracy: 0.0, Accum Accuracy: 70.39999583363533\n",
      "Validation Epoch: 1, Validation Minibatch: 885, Validation Loss: 3.8620083332061768, Accuracy: 0.0, Accum Accuracy: 70.39999583363533\n",
      "Validation Epoch: 1, Validation Minibatch: 886, Validation Loss: 4.179025173187256, Accuracy: 0.0, Accum Accuracy: 70.39999583363533\n",
      "Validation Epoch: 1, Validation Minibatch: 887, Validation Loss: 3.2584426403045654, Accuracy: 0.19999998807907104, Accum Accuracy: 70.5999958217144\n",
      "Validation Epoch: 1, Validation Minibatch: 888, Validation Loss: 3.9247021675109863, Accuracy: 0.0, Accum Accuracy: 70.5999958217144\n",
      "Validation Epoch: 1, Validation Minibatch: 889, Validation Loss: 3.17824125289917, Accuracy: 0.09999999403953552, Accum Accuracy: 70.69999581575394\n",
      "Validation Epoch: 1, Validation Minibatch: 890, Validation Loss: 3.744760036468506, Accuracy: 0.0, Accum Accuracy: 70.69999581575394\n",
      "Validation Epoch: 1, Validation Minibatch: 891, Validation Loss: 3.2494888305664062, Accuracy: 0.19999998807907104, Accum Accuracy: 70.89999580383301\n",
      "Validation Epoch: 1, Validation Minibatch: 892, Validation Loss: 3.2674572467803955, Accuracy: 0.19999998807907104, Accum Accuracy: 71.09999579191208\n",
      "Validation Epoch: 1, Validation Minibatch: 893, Validation Loss: 4.056682109832764, Accuracy: 0.09999999403953552, Accum Accuracy: 71.19999578595161\n",
      "Validation Epoch: 1, Validation Minibatch: 894, Validation Loss: 3.835461378097534, Accuracy: 0.09999999403953552, Accum Accuracy: 71.29999577999115\n",
      "Validation Epoch: 1, Validation Minibatch: 895, Validation Loss: 3.538097381591797, Accuracy: 0.09999999403953552, Accum Accuracy: 71.39999577403069\n",
      "Validation Epoch: 1, Validation Minibatch: 896, Validation Loss: 3.1574349403381348, Accuracy: 0.19999998807907104, Accum Accuracy: 71.59999576210976\n",
      "Validation Epoch: 1, Validation Minibatch: 897, Validation Loss: 4.37354850769043, Accuracy: 0.09999999403953552, Accum Accuracy: 71.69999575614929\n",
      "Validation Epoch: 1, Validation Minibatch: 898, Validation Loss: 3.5483767986297607, Accuracy: 0.09999999403953552, Accum Accuracy: 71.79999575018883\n",
      "Validation Epoch: 1, Validation Minibatch: 899, Validation Loss: 3.5497219562530518, Accuracy: 0.19999998807907104, Accum Accuracy: 71.9999957382679\n",
      "Validation Epoch: 1, Validation Minibatch: 900, Validation Loss: 3.388732433319092, Accuracy: 0.09999999403953552, Accum Accuracy: 72.09999573230743\n",
      "Validation Epoch: 1, Validation Minibatch: 901, Validation Loss: 3.139380931854248, Accuracy: 0.19999998807907104, Accum Accuracy: 72.2999957203865\n",
      "Validation Epoch: 1, Validation Minibatch: 902, Validation Loss: 3.625734806060791, Accuracy: 0.0, Accum Accuracy: 72.2999957203865\n",
      "Validation Epoch: 1, Validation Minibatch: 903, Validation Loss: 3.671365261077881, Accuracy: 0.09999999403953552, Accum Accuracy: 72.39999571442604\n",
      "Validation Epoch: 1, Validation Minibatch: 904, Validation Loss: 2.9581408500671387, Accuracy: 0.09999999403953552, Accum Accuracy: 72.49999570846558\n",
      "Validation Epoch: 1, Validation Minibatch: 905, Validation Loss: 3.8857078552246094, Accuracy: 0.0, Accum Accuracy: 72.49999570846558\n",
      "Validation Epoch: 1, Validation Minibatch: 906, Validation Loss: 3.753260374069214, Accuracy: 0.0, Accum Accuracy: 72.49999570846558\n",
      "Validation Epoch: 1, Validation Minibatch: 907, Validation Loss: 3.2030158042907715, Accuracy: 0.09999999403953552, Accum Accuracy: 72.59999570250511\n",
      "Validation Epoch: 1, Validation Minibatch: 908, Validation Loss: 4.0891594886779785, Accuracy: 0.0, Accum Accuracy: 72.59999570250511\n",
      "Validation Epoch: 1, Validation Minibatch: 909, Validation Loss: 4.106987953186035, Accuracy: 0.0, Accum Accuracy: 72.59999570250511\n",
      "Validation Epoch: 1, Validation Minibatch: 910, Validation Loss: 3.672072649002075, Accuracy: 0.09999999403953552, Accum Accuracy: 72.69999569654465\n",
      "Validation Epoch: 1, Validation Minibatch: 911, Validation Loss: 3.579223155975342, Accuracy: 0.19999998807907104, Accum Accuracy: 72.89999568462372\n",
      "Validation Epoch: 1, Validation Minibatch: 912, Validation Loss: 3.949604034423828, Accuracy: 0.0, Accum Accuracy: 72.89999568462372\n",
      "Validation Epoch: 1, Validation Minibatch: 913, Validation Loss: 3.8064942359924316, Accuracy: 0.09999999403953552, Accum Accuracy: 72.99999567866325\n",
      "Validation Epoch: 1, Validation Minibatch: 914, Validation Loss: 3.7119171619415283, Accuracy: 0.09999999403953552, Accum Accuracy: 73.09999567270279\n",
      "Validation Epoch: 1, Validation Minibatch: 915, Validation Loss: 3.4465670585632324, Accuracy: 0.0, Accum Accuracy: 73.09999567270279\n",
      "Validation Epoch: 1, Validation Minibatch: 916, Validation Loss: 3.756127119064331, Accuracy: 0.09999999403953552, Accum Accuracy: 73.19999566674232\n",
      "Validation Epoch: 1, Validation Minibatch: 917, Validation Loss: 4.686809062957764, Accuracy: 0.0, Accum Accuracy: 73.19999566674232\n",
      "Validation Epoch: 1, Validation Minibatch: 918, Validation Loss: 4.364279747009277, Accuracy: 0.0, Accum Accuracy: 73.19999566674232\n",
      "Validation Epoch: 1, Validation Minibatch: 919, Validation Loss: 3.900803804397583, Accuracy: 0.0, Accum Accuracy: 73.19999566674232\n",
      "Validation Epoch: 1, Validation Minibatch: 920, Validation Loss: 3.806931972503662, Accuracy: 0.29999998211860657, Accum Accuracy: 73.49999564886093\n",
      "Validation Epoch: 1, Validation Minibatch: 921, Validation Loss: 3.376330614089966, Accuracy: 0.0, Accum Accuracy: 73.49999564886093\n",
      "Validation Epoch: 1, Validation Minibatch: 922, Validation Loss: 2.9804139137268066, Accuracy: 0.0, Accum Accuracy: 73.49999564886093\n",
      "Validation Epoch: 1, Validation Minibatch: 923, Validation Loss: 3.6138076782226562, Accuracy: 0.29999998211860657, Accum Accuracy: 73.79999563097954\n",
      "Validation Epoch: 1, Validation Minibatch: 924, Validation Loss: 3.877112627029419, Accuracy: 0.0, Accum Accuracy: 73.79999563097954\n",
      "Validation Epoch: 1, Validation Minibatch: 925, Validation Loss: 3.865675449371338, Accuracy: 0.09999999403953552, Accum Accuracy: 73.89999562501907\n",
      "Validation Epoch: 1, Validation Minibatch: 926, Validation Loss: 3.591911792755127, Accuracy: 0.09999999403953552, Accum Accuracy: 73.99999561905861\n",
      "Validation Epoch: 1, Validation Minibatch: 927, Validation Loss: 3.6037986278533936, Accuracy: 0.0, Accum Accuracy: 73.99999561905861\n",
      "Validation Epoch: 1, Validation Minibatch: 928, Validation Loss: 3.7326245307922363, Accuracy: 0.0, Accum Accuracy: 73.99999561905861\n",
      "Validation Epoch: 1, Validation Minibatch: 929, Validation Loss: 4.046537399291992, Accuracy: 0.0, Accum Accuracy: 73.99999561905861\n",
      "Validation Epoch: 1, Validation Minibatch: 930, Validation Loss: 4.295000076293945, Accuracy: 0.09999999403953552, Accum Accuracy: 74.09999561309814\n",
      "Validation Epoch: 1, Validation Minibatch: 931, Validation Loss: 3.805973768234253, Accuracy: 0.09999999403953552, Accum Accuracy: 74.19999560713768\n",
      "Validation Epoch: 1, Validation Minibatch: 932, Validation Loss: 3.874338150024414, Accuracy: 0.09999999403953552, Accum Accuracy: 74.29999560117722\n",
      "Validation Epoch: 1, Validation Minibatch: 933, Validation Loss: 3.1355185508728027, Accuracy: 0.09999999403953552, Accum Accuracy: 74.39999559521675\n",
      "Validation Epoch: 1, Validation Minibatch: 934, Validation Loss: 3.1703996658325195, Accuracy: 0.29999998211860657, Accum Accuracy: 74.69999557733536\n",
      "Validation Epoch: 1, Validation Minibatch: 935, Validation Loss: 3.573413372039795, Accuracy: 0.0, Accum Accuracy: 74.69999557733536\n",
      "Validation Epoch: 1, Validation Minibatch: 936, Validation Loss: 4.046978950500488, Accuracy: 0.09999999403953552, Accum Accuracy: 74.7999955713749\n",
      "Validation Epoch: 1, Validation Minibatch: 937, Validation Loss: 4.154905796051025, Accuracy: 0.09999999403953552, Accum Accuracy: 74.89999556541443\n",
      "Validation Epoch: 1, Validation Minibatch: 938, Validation Loss: 4.07120418548584, Accuracy: 0.09999999403953552, Accum Accuracy: 74.99999555945396\n",
      "Validation Epoch: 1, Validation Minibatch: 939, Validation Loss: 3.772101879119873, Accuracy: 0.0, Accum Accuracy: 74.99999555945396\n",
      "Validation Epoch: 1, Validation Minibatch: 940, Validation Loss: 3.2437713146209717, Accuracy: 0.0, Accum Accuracy: 74.99999555945396\n",
      "Validation Epoch: 1, Validation Minibatch: 941, Validation Loss: 3.0168824195861816, Accuracy: 0.09999999403953552, Accum Accuracy: 75.0999955534935\n",
      "Validation Epoch: 1, Validation Minibatch: 942, Validation Loss: 3.0311551094055176, Accuracy: 0.0, Accum Accuracy: 75.0999955534935\n",
      "Validation Epoch: 1, Validation Minibatch: 943, Validation Loss: 3.611077070236206, Accuracy: 0.09999999403953552, Accum Accuracy: 75.19999554753304\n",
      "Validation Epoch: 1, Validation Minibatch: 944, Validation Loss: 3.3243789672851562, Accuracy: 0.09999999403953552, Accum Accuracy: 75.29999554157257\n",
      "Validation Epoch: 1, Validation Minibatch: 945, Validation Loss: 3.53796648979187, Accuracy: 0.0, Accum Accuracy: 75.29999554157257\n",
      "Validation Epoch: 1, Validation Minibatch: 946, Validation Loss: 3.669520854949951, Accuracy: 0.0, Accum Accuracy: 75.29999554157257\n",
      "Validation Epoch: 1, Validation Minibatch: 947, Validation Loss: 3.545822858810425, Accuracy: 0.09999999403953552, Accum Accuracy: 75.3999955356121\n",
      "Validation Epoch: 1, Validation Minibatch: 948, Validation Loss: 3.266294479370117, Accuracy: 0.09999999403953552, Accum Accuracy: 75.49999552965164\n",
      "Validation Epoch: 1, Validation Minibatch: 949, Validation Loss: 4.08609676361084, Accuracy: 0.0, Accum Accuracy: 75.49999552965164\n",
      "Validation Epoch: 1, Validation Minibatch: 950, Validation Loss: 3.594130039215088, Accuracy: 0.09999999403953552, Accum Accuracy: 75.59999552369118\n",
      "Validation Epoch: 1, Validation Minibatch: 951, Validation Loss: 3.815927505493164, Accuracy: 0.0, Accum Accuracy: 75.59999552369118\n",
      "Validation Epoch: 1, Validation Minibatch: 952, Validation Loss: 4.420182704925537, Accuracy: 0.0, Accum Accuracy: 75.59999552369118\n",
      "Validation Epoch: 1, Validation Minibatch: 953, Validation Loss: 4.0554962158203125, Accuracy: 0.29999998211860657, Accum Accuracy: 75.89999550580978\n",
      "Validation Epoch: 1, Validation Minibatch: 954, Validation Loss: 3.500046968460083, Accuracy: 0.0, Accum Accuracy: 75.89999550580978\n",
      "Validation Epoch: 1, Validation Minibatch: 955, Validation Loss: 4.74661111831665, Accuracy: 0.0, Accum Accuracy: 75.89999550580978\n",
      "Validation Epoch: 1, Validation Minibatch: 956, Validation Loss: 3.118015766143799, Accuracy: 0.19999998807907104, Accum Accuracy: 76.09999549388885\n",
      "Validation Epoch: 1, Validation Minibatch: 957, Validation Loss: 4.5601301193237305, Accuracy: 0.0, Accum Accuracy: 76.09999549388885\n",
      "Validation Epoch: 1, Validation Minibatch: 958, Validation Loss: 3.9586520195007324, Accuracy: 0.29999998211860657, Accum Accuracy: 76.39999547600746\n",
      "Validation Epoch: 1, Validation Minibatch: 959, Validation Loss: 4.050784111022949, Accuracy: 0.0, Accum Accuracy: 76.39999547600746\n",
      "Validation Epoch: 1, Validation Minibatch: 960, Validation Loss: 3.8535544872283936, Accuracy: 0.09999999403953552, Accum Accuracy: 76.499995470047\n",
      "Validation Epoch: 1, Validation Minibatch: 961, Validation Loss: 3.7366981506347656, Accuracy: 0.0, Accum Accuracy: 76.499995470047\n",
      "Validation Epoch: 1, Validation Minibatch: 962, Validation Loss: 3.9743614196777344, Accuracy: 0.09999999403953552, Accum Accuracy: 76.59999546408653\n",
      "Validation Epoch: 1, Validation Minibatch: 963, Validation Loss: 3.6636383533477783, Accuracy: 0.29999998211860657, Accum Accuracy: 76.89999544620514\n",
      "Validation Epoch: 1, Validation Minibatch: 964, Validation Loss: 3.5658326148986816, Accuracy: 0.0, Accum Accuracy: 76.89999544620514\n",
      "Validation Epoch: 1, Validation Minibatch: 965, Validation Loss: 4.586606025695801, Accuracy: 0.09999999403953552, Accum Accuracy: 76.99999544024467\n",
      "Validation Epoch: 1, Validation Minibatch: 966, Validation Loss: 3.6934916973114014, Accuracy: 0.09999999403953552, Accum Accuracy: 77.09999543428421\n",
      "Validation Epoch: 1, Validation Minibatch: 967, Validation Loss: 3.993065595626831, Accuracy: 0.0, Accum Accuracy: 77.09999543428421\n",
      "Validation Epoch: 1, Validation Minibatch: 968, Validation Loss: 4.440491676330566, Accuracy: 0.09999999403953552, Accum Accuracy: 77.19999542832375\n",
      "Validation Epoch: 1, Validation Minibatch: 969, Validation Loss: 3.626486301422119, Accuracy: 0.09999999403953552, Accum Accuracy: 77.29999542236328\n",
      "Validation Epoch: 1, Validation Minibatch: 970, Validation Loss: 3.4826793670654297, Accuracy: 0.0, Accum Accuracy: 77.29999542236328\n",
      "Validation Epoch: 1, Validation Minibatch: 971, Validation Loss: 3.544156551361084, Accuracy: 0.29999998211860657, Accum Accuracy: 77.59999540448189\n",
      "Validation Epoch: 1, Validation Minibatch: 972, Validation Loss: 3.787343978881836, Accuracy: 0.09999999403953552, Accum Accuracy: 77.69999539852142\n",
      "Validation Epoch: 1, Validation Minibatch: 973, Validation Loss: 4.040501594543457, Accuracy: 0.09999999403953552, Accum Accuracy: 77.79999539256096\n",
      "Validation Epoch: 1, Validation Minibatch: 974, Validation Loss: 3.686192750930786, Accuracy: 0.19999998807907104, Accum Accuracy: 77.99999538064003\n",
      "Validation Epoch: 1, Validation Minibatch: 975, Validation Loss: 4.018753528594971, Accuracy: 0.0, Accum Accuracy: 77.99999538064003\n",
      "Validation Epoch: 1, Validation Minibatch: 976, Validation Loss: 4.143094062805176, Accuracy: 0.09999999403953552, Accum Accuracy: 78.09999537467957\n",
      "Validation Epoch: 1, Validation Minibatch: 977, Validation Loss: 3.577880859375, Accuracy: 0.09999999403953552, Accum Accuracy: 78.1999953687191\n",
      "Validation Epoch: 1, Validation Minibatch: 978, Validation Loss: 3.345919132232666, Accuracy: 0.0, Accum Accuracy: 78.1999953687191\n",
      "Validation Epoch: 1, Validation Minibatch: 979, Validation Loss: 3.3019649982452393, Accuracy: 0.09999999403953552, Accum Accuracy: 78.29999536275864\n",
      "Validation Epoch: 1, Validation Minibatch: 980, Validation Loss: 3.2363791465759277, Accuracy: 0.09999999403953552, Accum Accuracy: 78.39999535679817\n",
      "Validation Epoch: 1, Validation Minibatch: 981, Validation Loss: 4.215417861938477, Accuracy: 0.0, Accum Accuracy: 78.39999535679817\n",
      "Validation Epoch: 1, Validation Minibatch: 982, Validation Loss: 3.9778316020965576, Accuracy: 0.09999999403953552, Accum Accuracy: 78.49999535083771\n",
      "Validation Epoch: 1, Validation Minibatch: 983, Validation Loss: 3.144160509109497, Accuracy: 0.09999999403953552, Accum Accuracy: 78.59999534487724\n",
      "Validation Epoch: 1, Validation Minibatch: 984, Validation Loss: 3.0576348304748535, Accuracy: 0.19999998807907104, Accum Accuracy: 78.79999533295631\n",
      "Validation Epoch: 1, Validation Minibatch: 985, Validation Loss: 4.330887794494629, Accuracy: 0.0, Accum Accuracy: 78.79999533295631\n",
      "Validation Epoch: 1, Validation Minibatch: 986, Validation Loss: 2.8459994792938232, Accuracy: 0.09999999403953552, Accum Accuracy: 78.89999532699585\n",
      "Validation Epoch: 1, Validation Minibatch: 987, Validation Loss: 3.3164820671081543, Accuracy: 0.09999999403953552, Accum Accuracy: 78.99999532103539\n",
      "Validation Epoch: 1, Validation Minibatch: 988, Validation Loss: 4.362514972686768, Accuracy: 0.09999999403953552, Accum Accuracy: 79.09999531507492\n",
      "Validation Epoch: 1, Validation Minibatch: 989, Validation Loss: 3.529663562774658, Accuracy: 0.09999999403953552, Accum Accuracy: 79.19999530911446\n",
      "Validation Epoch: 1, Validation Minibatch: 990, Validation Loss: 3.8324127197265625, Accuracy: 0.0, Accum Accuracy: 79.19999530911446\n",
      "Validation Epoch: 1, Validation Minibatch: 991, Validation Loss: 3.3369040489196777, Accuracy: 0.09999999403953552, Accum Accuracy: 79.29999530315399\n",
      "Validation Epoch: 1, Validation Minibatch: 992, Validation Loss: 3.1886441707611084, Accuracy: 0.0, Accum Accuracy: 79.29999530315399\n",
      "Validation Epoch: 1, Validation Minibatch: 993, Validation Loss: 3.299084424972534, Accuracy: 0.09999999403953552, Accum Accuracy: 79.39999529719353\n",
      "Validation Epoch: 1, Validation Minibatch: 994, Validation Loss: 4.395134925842285, Accuracy: 0.0, Accum Accuracy: 79.39999529719353\n",
      "Validation Epoch: 1, Validation Minibatch: 995, Validation Loss: 3.2075259685516357, Accuracy: 0.19999998807907104, Accum Accuracy: 79.5999952852726\n",
      "Validation Epoch: 1, Validation Minibatch: 996, Validation Loss: 4.2207465171813965, Accuracy: 0.09999999403953552, Accum Accuracy: 79.69999527931213\n",
      "Validation Epoch: 1, Validation Minibatch: 997, Validation Loss: 3.8379969596862793, Accuracy: 0.09999999403953552, Accum Accuracy: 79.79999527335167\n",
      "Validation Epoch: 1, Validation Minibatch: 998, Validation Loss: 3.341140031814575, Accuracy: 0.09999999403953552, Accum Accuracy: 79.8999952673912\n",
      "Validation Epoch: 1, Validation Minibatch: 999, Validation Loss: 4.33615779876709, Accuracy: 0.0, Accum Accuracy: 79.8999952673912\n",
      "Saving: /home/ec2-user/SageMaker/dman-nebula-micromachines-build/source_scripts/../.tmp/data/training/train-validation.json\n",
      "Saving: /home/ec2-user/SageMaker/dman-nebula-micromachines-build/source_scripts/../.tmp/data/training/train-summary.json\n",
      "Saving model for Epoch [1], Validatoin Loss: 3.7574, Mean Accuracy: 0.07989999526739121 \n"
     ]
    }
   ],
   "source": [
    "max_length = 1024\n",
    "d_model = 1000\n",
    "num_heads = 10\n",
    "gradient_accumulation_steps = 2\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        \"vocab.txt\",\n",
    "    )\n",
    ")\n",
    "tokenizer.eos_token = \"[SEP]\"\n",
    "tokenizer.bos_token = \"[CLS]\"\n",
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.unknown_token = \"[UNK]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW\n",
    "# optimizer=torch.optim.Adam\n",
    "# optimizer=torch.optim.SGD\n",
    "# optimizer=torch.optim.Adagrad\n",
    "# optimizer=torch.optim.Adadelta\n",
    "# optimizer=torch.optim.RMSprop\n",
    "print(\"Loading Datasets\")\n",
    "data_file_training = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"training\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "data_file_validate = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"validation\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "(\n",
    "    dataloader,\n",
    "    vocab_size,\n",
    ") = create_dataloader(\n",
    "    data_file_training,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=10000,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "(\n",
    "    dataloader_val,\n",
    "    _,\n",
    ") = create_dataloader(\n",
    "    data_file_validate,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=10000,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Setting up BERT\")\n",
    "bert_trainer = BERTTrainer(\n",
    "    dataloader,\n",
    "    dataloader_val,\n",
    "    vocab_size,\n",
    "    max_length=max_length,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    n_layers=6,\n",
    "    tokenizer=tokenizer,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "print(\"Start Training\")\n",
    "bert_trainer.train(\n",
    "    lr=0.001,\n",
    "    epochs=2,\n",
    "    output_path=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "    ),\n",
    "    graph=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112de77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "max_length = 1024\n",
    "d_model = 1000\n",
    "num_heads = 10\n",
    "\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        \"vocab.txt\",\n",
    "    )\n",
    ")\n",
    "tokenizer.eos_token = \"[SEP]\"\n",
    "tokenizer.bos_token = \"[CLS]\"\n",
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.unknown_token = \"[UNK]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "\n",
    "data_file_validate = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"validation\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "(\n",
    "    dataloader_val,\n",
    "    vocab_size,\n",
    ") = create_dataloader(\n",
    "    data_file_validate,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=100,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "evaluator = BERTEvaluator(\n",
    "    model_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        f\"bert.pth\",\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    ")\n",
    "evaluator.evaluate(\n",
    "    output_path=\"./\",\n",
    "    dataloader_val=dataloader_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
