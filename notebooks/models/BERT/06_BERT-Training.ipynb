{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bb3ff-f742-454d-8080-5e60d8175299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp project.models.bert.training\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eb276b",
   "metadata": {},
   "source": [
    "# Bert Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a849c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Fix seed for experimenting\n",
    "import torch\n",
    "\n",
    "\n",
    "def manual_seed_all(\n",
    "    seed,\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546b148-f35b-431f-a8a3-ef7810c1d5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "\n",
    "# | export\n",
    "import os\n",
    "from random import (\n",
    "    shuffle,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from project.models.bert.model import (\n",
    "    BERT,\n",
    ")\n",
    "from project.utils.plot import (\n",
    "    LivePlot,\n",
    ")\n",
    "from torch import (\n",
    "    nn,\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    TensorDataset,\n",
    ")\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForMaskedLM,\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "def mask_theorem(\n",
    "    token_theorem,\n",
    "    tokenizer,\n",
    "    max_masked=40,\n",
    "):\n",
    "    theo_indices = []\n",
    "    for i in range(\n",
    "        1,\n",
    "        len(token_theorem),\n",
    "    ):  # don't mask [CLS] and [END] or spaces and new lines\n",
    "        if token_theorem[i] == tokenizer.sep_token_id:\n",
    "            break\n",
    "        theo_indices.append(i)\n",
    "\n",
    "    shuffle(theo_indices)\n",
    "    masked_poss = theo_indices[:max_masked]\n",
    "    masked_tokens = []\n",
    "    for i in masked_poss:\n",
    "        masked_tokens.append(token_theorem[i])\n",
    "        token_theorem[i] = tokenizer.mask_token_id\n",
    "    return (\n",
    "        token_theorem,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    )\n",
    "\n",
    "\n",
    "if \"tmp_data_dir\" in os.environ:\n",
    "    tmp_data_dir = os.environ[\"tmp_data_dir\"]\n",
    "else:\n",
    "    TMP_RELATIVE_DATA_PATH = \"../.tmp/data\"\n",
    "    notebook_path = os.getcwd()\n",
    "    tmp_data_dir = os.path.join(\n",
    "        notebook_path,\n",
    "        TMP_RELATIVE_DATA_PATH,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_from_json(\n",
    "    filename,\n",
    "):\n",
    "    print(f\"Loading: {filename}\")\n",
    "    with open(\n",
    "        filename,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_to_json(\n",
    "    data,\n",
    "    filename,\n",
    "):\n",
    "    print(f\"Saving: {filename}\")\n",
    "    with open(\n",
    "        filename,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            data,\n",
    "            f,\n",
    "        )\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    data_file,\n",
    "    max_masked=1,\n",
    "    batch_size=4,\n",
    "    max_length=1024,\n",
    "    cap_train_data=None,\n",
    "    tokenizer=None,\n",
    "):\n",
    "    batch = load_from_json(data_file)  # [(tokens, masked_tokens, masked_pos)]\n",
    "    if cap_train_data and cap_train_data > 0:\n",
    "        batch = batch[0:cap_train_data]\n",
    "\n",
    "    assert tokenizer is not None, \"Tokenizer is None, and must be provider\"\n",
    "\n",
    "    masked_batch = []\n",
    "    for theo in batch:\n",
    "        token_theorem = tokenizer.encode_plus(\n",
    "            theo,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        (\n",
    "            input_ids_list,\n",
    "            masked_tokens,\n",
    "            masked_poss,\n",
    "        ) = mask_theorem(\n",
    "            token_theorem[\"input_ids\"],\n",
    "            tokenizer,\n",
    "            max_masked=max_masked,\n",
    "        )\n",
    "        masked = torch.LongTensor(masked_tokens).cuda()\n",
    "        masked_poss = torch.LongTensor(masked_poss).cuda()\n",
    "        input_ids = torch.LongTensor(input_ids_list).cuda()\n",
    "        attention_mask = torch.LongTensor(token_theorem[\"attention_mask\"]).cuda()\n",
    "        masked_batch.append(\n",
    "            (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked,\n",
    "                masked_poss,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    (\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    ) = list(zip(*masked_batch))\n",
    "    input_ids = torch.stack(input_ids).squeeze(1)\n",
    "    attention_mask = torch.stack(attention_mask).squeeze(1)\n",
    "\n",
    "    masked_tokens = torch.stack(masked_tokens)\n",
    "    masked_poss = torch.stack(masked_poss)\n",
    "\n",
    "    dataset = TensorDataset(\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        masked_tokens,\n",
    "        masked_poss,\n",
    "    )\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    return (\n",
    "        dataloader,\n",
    "        tokenizer.vocab_size,\n",
    "    )\n",
    "\n",
    "\n",
    "class BERTEvaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_file,\n",
    "        tokenizer,\n",
    "        vocab_size,\n",
    "        num_heads=6,\n",
    "        n_layers=6,\n",
    "        d_model=1000,\n",
    "        max_length=1024,\n",
    "    ):\n",
    "        config = BertConfig(\n",
    "            vocab_size=vocab_size,\n",
    "            hidden_size=d_model,\n",
    "            num_hidden_layers=n_layers,\n",
    "            max_length=max_length,\n",
    "            num_attention_heads=num_heads,\n",
    "            intermediate_size=2048,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=max_length,\n",
    "            initializer_range=0.0001,\n",
    "        )\n",
    "\n",
    "        # Initialize the model\n",
    "        model = BertForMaskedLM(config).cuda()\n",
    "\n",
    "        # Load the state dictionary\n",
    "        state_dict = torch.load(model_file)\n",
    "\n",
    "        # Load this state dictionary into your BERT model\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        output_path,\n",
    "        dataloader_val,\n",
    "    ):\n",
    "        # Evaluate the model\n",
    "        minibatch_val_n = 0\n",
    "        running_accuracy = 0.0\n",
    "        n_batches_val = len(dataloader_val)\n",
    "        print(f\"==> Validating Epoch <==\")\n",
    "        progress: list[dict] = [{\"validation\": []}]\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked_tokens,\n",
    "                masked_poss,\n",
    "            ) in dataloader_val:\n",
    "                output = self.model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits = output.logits\n",
    "                mask_positions = torch.where(input_ids == self.tokenizer.mask_token_id)\n",
    "\n",
    "                # Extract logits for the [MASK] positions\n",
    "                mask_logits = logits[\n",
    "                    mask_positions[0],\n",
    "                    mask_positions[1],\n",
    "                    :,\n",
    "                ]\n",
    "                # Get the predicted token IDs for all [MASK] positions\n",
    "                predicted_token_ids = torch.argmax(\n",
    "                    mask_logits,\n",
    "                    dim=1,\n",
    "                )\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                predicted_tokens = [self.tokenizer.decode(token_id) for token_id in predicted_token_ids]\n",
    "\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                masked_logits = torch.gather(\n",
    "                    logits,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                accuracy = (predicted_token_ids == masked_tokens).float().mean().item()\n",
    "                running_accuracy += accuracy\n",
    "                predictions_list = []\n",
    "                for (\n",
    "                    p,\n",
    "                    l,\n",
    "                ) in zip(\n",
    "                    predicted_tokens,\n",
    "                    masked_tokens,\n",
    "                ):\n",
    "                    zipped_lp = zip(\n",
    "                        l,\n",
    "                        p,\n",
    "                    )\n",
    "                    predict = [\n",
    "                        (\n",
    "                            \"\".join(self.tokenizer.decode(ll)),\n",
    "                            \"\".join(pp),\n",
    "                        )\n",
    "                        for ll, pp in zipped_lp\n",
    "                    ]\n",
    "                    predictions_list.append(\" @ \".join([f\"{pr[0]}<>{pr[1]})\" for pr in predict]))\n",
    "                print(f\"Validation Minibatch: {minibatch_val_n}, Accuracy: {accuracy}, Accum Accuracy: {running_accuracy}\")\n",
    "                prediction_str = \" # \".join(predictions_list)\n",
    "                print(\n",
    "                    \"Predictions: \",\n",
    "                    prediction_str,\n",
    "                )\n",
    "                progress[-1][\"validation\"].append(\n",
    "                    {\n",
    "                        \"predictions\": prediction_str,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"acum_accuracy\": running_accuracy,\n",
    "                    }\n",
    "                )\n",
    "                minibatch_val_n += 1\n",
    "            total_accuracy = running_accuracy / n_batches_val\n",
    "            save_to_json(\n",
    "                {\"accuracy\": total_accuracy},\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    \"evaluation.json\",\n",
    "                ),\n",
    "            )\n",
    "            return total_accuracy\n",
    "\n",
    "\n",
    "class BERTTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataloader,\n",
    "        dataloader_val,\n",
    "        vocab_size,\n",
    "        num_heads=6,\n",
    "        n_layers=6,\n",
    "        d_model=1000,\n",
    "        max_length=1024,\n",
    "        tokenizer=None,\n",
    "        criterion=None,\n",
    "        optimizer=torch.optim.SGD,\n",
    "        gradient_accumulation_steps=1,\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.num_heads = num_heads\n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        self.max_length = max_length\n",
    "\n",
    "        assert tokenizer is not None, \"Tokenizer is None, and must be provider\"\n",
    "        assert criterion is not None, \"Criterion is None, and must be provider\"\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        print(\"Create BERTodel\")\n",
    "        config = BertConfig(\n",
    "            vocab_size=vocab_size,\n",
    "            hidden_size=d_model,\n",
    "            num_hidden_layers=n_layers,\n",
    "            max_length=max_length,\n",
    "            num_attention_heads=num_heads,\n",
    "            intermediate_size=2048,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            attention_probs_dropout_prob=0.1,\n",
    "            max_position_embeddings=max_length,\n",
    "            initializer_range=0.0001,\n",
    "        )\n",
    "\n",
    "        model = BertForMaskedLM(config).cuda()\n",
    "\n",
    "        self.model = model\n",
    "        self.dataloader = dataloader\n",
    "        self.dataloader_val = dataloader_val\n",
    "\n",
    "        print(\n",
    "            \"Current GPU memory usage:\",\n",
    "            torch.cuda.memory_allocated(),\n",
    "        )\n",
    "        print(\n",
    "            \"Maximum GPU memory usage:\",\n",
    "            torch.cuda.max_memory_allocated(),\n",
    "        )\n",
    "\n",
    "        self.criterion = criterion.cuda()\n",
    "        self.optimizer = optimizer(\n",
    "            model.parameters(),\n",
    "            lr=0.001,\n",
    "        )  # torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"Number of parameters: {num_params/(1000000)} Millions\")\n",
    "\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        output_path,\n",
    "        dataloader_val,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        criterion,\n",
    "        progress,\n",
    "        epoch=0,\n",
    "        train_loss=0,\n",
    "    ):\n",
    "        # Evaluate the model\n",
    "        minibatch_val_n = 0\n",
    "        accum_val_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        n_batches_val = len(dataloader_val)\n",
    "        print(f\"==> Validating Epoch {epoch} <==\")\n",
    "        model.eval()\n",
    "        progress.append({\"validation\": []})\n",
    "        with torch.no_grad():\n",
    "            for (\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                masked_tokens,\n",
    "                masked_poss,\n",
    "            ) in dataloader_val:\n",
    "                output = model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits = output.logits\n",
    "                mask_positions = torch.where(input_ids == tokenizer.mask_token_id)\n",
    "\n",
    "                # Extract logits for the [MASK] positions\n",
    "                mask_logits = logits[\n",
    "                    mask_positions[0],\n",
    "                    mask_positions[1],\n",
    "                    :,\n",
    "                ]\n",
    "                # Get the predicted token IDs for all [MASK] positions\n",
    "                predicted_token_ids = torch.argmax(\n",
    "                    mask_logits,\n",
    "                    dim=1,\n",
    "                )\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                predicted_tokens = [tokenizer.decode(token_id) for token_id in predicted_token_ids]\n",
    "\n",
    "                # Convert the predicted token IDs to tokens\n",
    "                masked_logits = torch.gather(\n",
    "                    logits,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                loss_lm = criterion(\n",
    "                    masked_logits.transpose(\n",
    "                        1,\n",
    "                        2,\n",
    "                    ),\n",
    "                    masked_tokens,\n",
    "                )\n",
    "                loss_lm = (loss_lm.float()).mean()\n",
    "                accum_val_loss += loss_lm.item()\n",
    "                accuracy = (predicted_token_ids == masked_tokens).float().mean().item()\n",
    "                running_accuracy += accuracy\n",
    "                predictions_list = []\n",
    "                for (\n",
    "                    p,\n",
    "                    l,\n",
    "                ) in zip(\n",
    "                    predicted_tokens,\n",
    "                    masked_tokens,\n",
    "                ):\n",
    "                    zipped_lp = zip(\n",
    "                        l,\n",
    "                        p,\n",
    "                    )\n",
    "                    predict = [\n",
    "                        (\n",
    "                            \"\".join(tokenizer.decode(ll)),\n",
    "                            \"\".join(pp),\n",
    "                        )\n",
    "                        for ll, pp in zipped_lp\n",
    "                    ]\n",
    "                    predictions_list.append(\" @ \".join([f\"{pr[0]}<>{pr[1]})\" for pr in predict]))\n",
    "                print(f\"Validation Epoch: {epoch}, Validation Minibatch: {minibatch_val_n}, Validation Loss: {loss_lm.item()}, Accuracy: {accuracy}, Accum Accuracy: {running_accuracy}\")\n",
    "                prediction_str = \" # \".join(predictions_list)\n",
    "                progress[-1][\"validation\"].append(\n",
    "                    {\n",
    "                        \"predictions\": prediction_str,\n",
    "                        \"eval_loss\": loss_lm.item(),\n",
    "                        \"mean_train_loss\": train_loss,\n",
    "                        \"accuracy\": accuracy,\n",
    "                        \"acum_accuracy\": running_accuracy,\n",
    "                    }\n",
    "                )\n",
    "                minibatch_val_n += 1\n",
    "            return (\n",
    "                accum_val_loss,\n",
    "                running_accuracy,\n",
    "                n_batches_val,\n",
    "            )\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        lr=0.001,\n",
    "        epochs=20,\n",
    "        output_path=None,\n",
    "        graph=False,\n",
    "    ):\n",
    "        if not output_path:\n",
    "            output_path = \"./\"\n",
    "\n",
    "        print(f\"Output path: {output_path}\")\n",
    "        torch.cuda.set_device(0)\n",
    "        data_plot_loss = collections.defaultdict(list)\n",
    "        data_plot_accuracy = collections.defaultdict(list)\n",
    "        live_plot_loss = LivePlot()\n",
    "        train_summary: dict = {\n",
    "            \"epoch_summary\": [],\n",
    "            \"metadata\": {\n",
    "                \"lr\": lr,\n",
    "                \"ds_model\": self.d_model,\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"n_layers\": self.n_layers,\n",
    "            },\n",
    "        }\n",
    "        progress: list = []\n",
    "        n_batches = len(self.dataloader)\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"==> Training Epoch {epoch} <==\")\n",
    "            train_loss_acum = 0\n",
    "            self.model.train()\n",
    "            for (\n",
    "                step,\n",
    "                (\n",
    "                    input_ids,\n",
    "                    attention_mask,\n",
    "                    masked_tokens,\n",
    "                    masked_poss,\n",
    "                ),\n",
    "            ) in enumerate(self.dataloader):\n",
    "                output = self.model(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                )\n",
    "                logits_lm = output.logits\n",
    "                masked_logits = torch.gather(\n",
    "                    logits_lm,\n",
    "                    1,\n",
    "                    masked_poss.unsqueeze(-1).expand(\n",
    "                        -1,\n",
    "                        -1,\n",
    "                        logits_lm.size(-1),\n",
    "                    ),\n",
    "                )\n",
    "                loss_lm = self.criterion(\n",
    "                    masked_logits.transpose(\n",
    "                        1,\n",
    "                        2,\n",
    "                    ),\n",
    "                    masked_tokens,\n",
    "                )\n",
    "                loss_lm = (loss_lm.float()).mean()\n",
    "                loss_lm.backward()\n",
    "                loss_value = loss_lm.item()\n",
    "                train_loss_acum += loss_value\n",
    "\n",
    "                data_plot_loss[f\"Epoch-{epoch}\"].append(loss_value)\n",
    "                if graph:\n",
    "                    live_plot_loss.plot(data_plot_loss)\n",
    "                if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.model.zero_grad()\n",
    "                if (step + 1) % 5 == 0:\n",
    "                    print(f\"Epoch: {epoch}, Step: {step+1}, Loss: {loss_value}\")\n",
    "\n",
    "            train_loss = train_loss_acum / n_batches\n",
    "\n",
    "            (\n",
    "                accum_val_loss,\n",
    "                running_accuracy,\n",
    "                n_batches_val,\n",
    "            ) = self.evaluate(\n",
    "                output_path,\n",
    "                self.dataloader_val,\n",
    "                self.model,\n",
    "                self.tokenizer,\n",
    "                self.criterion,\n",
    "                progress,\n",
    "                epoch,\n",
    "            )\n",
    "            save_to_json(\n",
    "                progress,\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"train-validation.json\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            mean_val_loss = accum_val_loss / n_batches_val\n",
    "            mean_val_accuracy = running_accuracy / n_batches_val\n",
    "            train_summary[\"epoch_summary\"].append(  # type: ignore\n",
    "                {\n",
    "                    \"mean_validation_loss\": mean_val_loss,\n",
    "                    \"mean_train_loss\": train_loss,\n",
    "                    \"mean_accuracy\": mean_val_accuracy,\n",
    "                }\n",
    "            )\n",
    "            save_to_json(\n",
    "                train_summary,\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"train-summary.json\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                \"Saving model for Epoch [{}], Validatoin Loss: {:.4f}, Mean Accuracy: {} \".format(\n",
    "                    epoch,\n",
    "                    mean_val_loss,\n",
    "                    mean_val_accuracy,\n",
    "                )\n",
    "            )\n",
    "            torch.save(\n",
    "                self.model.state_dict(),\n",
    "                os.path.join(\n",
    "                    output_path,\n",
    "                    f\"bert.pth\",\n",
    "                ),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44a56",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b2584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb Cell 7\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m bert_trainer \u001b[39m=\u001b[39m BERTTrainer(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m     dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m     dataloader_val,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m     gradient_accumulation_steps\u001b[39m=\u001b[39mgradient_accumulation_steps,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart Training\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m bert_trainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m     lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=78'>79</a>\u001b[0m     output_path\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=79'>80</a>\u001b[0m         tmp_data_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=80'>81</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=81'>82</a>\u001b[0m     ),\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=82'>83</a>\u001b[0m     graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m )\n",
      "\u001b[1;32m/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb Cell 7\u001b[0m line \u001b[0;36m5\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=524'>525</a>\u001b[0m loss_lm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=525'>526</a>\u001b[0m     masked_logits\u001b[39m.\u001b[39mtranspose(\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=526'>527</a>\u001b[0m         \u001b[39m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=529'>530</a>\u001b[0m     masked_tokens,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=530'>531</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=531'>532</a>\u001b[0m loss_lm \u001b[39m=\u001b[39m (loss_lm\u001b[39m.\u001b[39mfloat())\u001b[39m.\u001b[39mmean()\n\u001b[0;32m--> <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=532'>533</a>\u001b[0m loss_lm\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=533'>534</a>\u001b[0m loss_value \u001b[39m=\u001b[39m loss_lm\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=534'>535</a>\u001b[0m train_loss_acum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_value\n",
      "File \u001b[0;32m/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_length = 1024\n",
    "d_model = 1000\n",
    "num_heads = 10\n",
    "gradient_accumulation_steps = 2\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        \"vocab.txt\",\n",
    "    )\n",
    ")\n",
    "tokenizer.eos_token = \"[SEP]\"\n",
    "tokenizer.bos_token = \"[CLS]\"\n",
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.unknown_token = \"[UNK]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW\n",
    "# optimizer=torch.optim.Adam\n",
    "# optimizer=torch.optim.SGD\n",
    "# optimizer=torch.optim.Adagrad\n",
    "# optimizer=torch.optim.Adadelta\n",
    "# optimizer=torch.optim.RMSprop\n",
    "print(\"Loading Datasets\")\n",
    "data_file_training = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"training\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "data_file_validate = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"validation\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "(\n",
    "    dataloader,\n",
    "    vocab_size,\n",
    ") = create_dataloader(\n",
    "    data_file_training,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=10000,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "(\n",
    "    dataloader_val,\n",
    "    _,\n",
    ") = create_dataloader(\n",
    "    data_file_validate,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=10000,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Setting up BERT\")\n",
    "bert_trainer = BERTTrainer(\n",
    "    dataloader,\n",
    "    dataloader_val,\n",
    "    vocab_size,\n",
    "    max_length=max_length,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    n_layers=6,\n",
    "    tokenizer=tokenizer,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "print(\"Start Training\")\n",
    "bert_trainer.train(\n",
    "    lr=0.001,\n",
    "    epochs=2,\n",
    "    output_path=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "    ),\n",
    "    graph=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112de77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: /notebooks/source_scripts/../.tmp/data/validation/theorems.json\n"
     ]
    },
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\\n    app.start()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\\n    self.io_loop.start()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\\n    self._run_once()\\n', '  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\\n    handle._run()\\n', '  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\\n    await dispatch(*args)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\\n    await result\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\\n    result = self._run_cell(\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\\n    result = runner(coro)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_7644/3942822529.py\", line 7, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/__init__.py\", line 798, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 179, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 177, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py:242\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     queued_call()\n\u001b[1;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py:122\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m old_gpu_warn \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[39mFound GPU\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m which is of cuda capability \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[39mPyTorch no longer supports this GPU because it is too old.\u001b[39m\n\u001b[1;32m    119\u001b[0m \u001b[39mThe minimum cuda capability supported by this library is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39;49mversion\u001b[39m.\u001b[39mcuda \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# on ROCm we don't want this check\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     CUDA_VERSION \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_getCompiledVersion()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m tokenizer\u001b[39m.\u001b[39mpad_token \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[PAD]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m data_file_validate \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     tmp_data_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalidation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtheorems.json\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m (\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     dataloader_val,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     vocab_size,\n\u001b[0;32m---> <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m ) \u001b[39m=\u001b[39m create_dataloader(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     data_file_validate,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     max_masked\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     cap_train_data\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m evaluator \u001b[39m=\u001b[39m BERTEvaluator(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     model_file\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m         tmp_data_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     num_heads\u001b[39m=\u001b[39mnum_heads,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m evaluator\u001b[39m.\u001b[39mevaluate(\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m     output_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     dataloader_val\u001b[39m=\u001b[39mdataloader_val,\n\u001b[1;32m     <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m )\n",
      "\u001b[1;32m/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=113'>114</a>\u001b[0m token_theorem \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=114'>115</a>\u001b[0m     theo,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=115'>116</a>\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=116'>117</a>\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=117'>118</a>\u001b[0m )\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=118'>119</a>\u001b[0m (\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=119'>120</a>\u001b[0m     input_ids_list,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=120'>121</a>\u001b[0m     masked_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=125'>126</a>\u001b[0m     max_masked\u001b[39m=\u001b[39mmax_masked,\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=126'>127</a>\u001b[0m )\n\u001b[0;32m--> <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=127'>128</a>\u001b[0m masked \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mLongTensor(masked_tokens)\u001b[39m.\u001b[39;49mcuda()\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=128'>129</a>\u001b[0m masked_poss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(masked_poss)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m    <a href='vscode-notebook-cell://n2y6h6m8qc.clg07azjl.paperspacegradient.com/notebooks/notebooks/models/BERT/06_BERT-Training.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=129'>130</a>\u001b[0m input_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(input_ids_list)\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py:246\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    244\u001b[0m             msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(e)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCUDA call was originally invoked at:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00morig_traceback\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 246\u001b[0m             \u001b[39mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[39mdelattr\u001b[39m(_tls, \u001b[39m'\u001b[39m\u001b[39mis_initializing\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/traitlets/config/application.py\", line 1053, in launch_instance\\n    app.start()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 737, in start\\n    self.io_loop.start()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\\n    self._run_once()\\n', '  File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\\n    handle._run()\\n', '  File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 524, in dispatch_queue\\n    await self.process_one()\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in process_one\\n    await dispatch(*args)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 418, in dispatch_shell\\n    await result\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 758, in execute_request\\n    reply_content = await reply_content\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 426, in do_execute\\n    res = shell.run_cell(\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\\n    result = self._run_cell(\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\\n    result = runner(coro)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"/tmp/ipykernel_7644/3942822529.py\", line 7, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/__init__.py\", line 798, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 179, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/storage/venv/my-project-XvMgmHVc-py3.9/lib/python3.9/site-packages/torch/cuda/__init__.py\", line 177, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    ")\n",
    "\n",
    "max_length = 1024\n",
    "d_model = 1000\n",
    "num_heads = 10\n",
    "\n",
    "tokenizer = BertTokenizer(\n",
    "    vocab_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        \"vocab.txt\",\n",
    "    )\n",
    ")\n",
    "tokenizer.eos_token = \"[SEP]\"\n",
    "tokenizer.bos_token = \"[CLS]\"\n",
    "tokenizer.mask_token = \"[MASK]\"\n",
    "tokenizer.unknown_token = \"[UNK]\"\n",
    "tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "\n",
    "data_file_validate = os.path.join(\n",
    "    tmp_data_dir,\n",
    "    \"validation\",\n",
    "    f\"theorems.json\",\n",
    ")\n",
    "(\n",
    "    dataloader_val,\n",
    "    vocab_size,\n",
    ") = create_dataloader(\n",
    "    data_file_validate,\n",
    "    max_length=max_length,\n",
    "    max_masked=1,\n",
    "    batch_size=10,\n",
    "    cap_train_data=100,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "evaluator = BERTEvaluator(\n",
    "    model_file=os.path.join(\n",
    "        tmp_data_dir,\n",
    "        \"training\",\n",
    "        f\"bert.pth\",\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    vocab_size=vocab_size,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    ")\n",
    "evaluator.evaluate(\n",
    "    output_path=\"./\",\n",
    "    dataloader_val=dataloader_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bfaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
