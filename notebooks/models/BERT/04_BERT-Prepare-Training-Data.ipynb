{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bb3ff-f742-454d-8080-5e60d8175299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp  project.models.bert.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132de7d9",
   "metadata": {},
   "source": [
    "# Create data and Encoders\n",
    "\n",
    "> Just run this Notebook to generate the data in `.tmp`\n",
    "\n",
    "This notebooks creates data to train the BERT in first order logic. It uses `notebooks.utils.prop_logi` module to generates random theorems. Then mask some persentage of tokens.\n",
    "\n",
    "Generated Data:\n",
    "\n",
    "```\n",
    ".tmp\n",
    "└── data\n",
    "    ├── training\n",
    "    │   ├── theorems.json\n",
    "    │   └── vocab.txt\n",
    "    └── validation\n",
    "        ├── theorems.json\n",
    "        └── vocab.txt\n",
    "```\n",
    "\n",
    "The idea is generate a dataset for train and validation, save the datasets on disk `.tmp` and then it is upload it to an s3 buckets to be used by the production pipeline.\n",
    "\n",
    "During research phase we are going to use the `.tmp` directory to shorcut the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "0. p77  [ axiom ]  nl\n",
      "1. p73  [ axiom ]  nl\n",
      "2. p0  [ axiom ]  nl\n",
      "3. p53  [ axiom ]  nl\n",
      "4. p80  [ axiom ]  nl\n",
      "5. p29  [ axiom ]  nl\n",
      "6. p72  [ axiom ]  nl\n",
      "7. p6  [ axiom ]  nl\n",
      "8. (p77 -> p77)  [ implication-introduction 0,0 ]  nl\n",
      "9. (p53 -> p77)  [ implication-introduction 3,0 ] \n",
      "----------------\n",
      "0. p4  [ axiom ]  nl\n",
      "1. p75  [ axiom ]  nl\n",
      "2. p47  [ axiom ]  nl\n",
      "3. p0  [ axiom ]  nl\n",
      "4. p88  [ axiom ]  nl\n",
      "5. p34  [ axiom ]  nl\n",
      "6. p80  [ axiom ]  nl\n",
      "7. p71  [ axiom ]  nl\n",
      "8. p97  [ axiom ]  nl\n",
      "9. p16  [ axiom ]  nl\n",
      "10. (p75 -> p4)  [ implication-introduction 1,0 ]  nl\n",
      "11. (p91 | p80)  [ disjunction-introduction 6 ]  nl\n",
      "12. (p88 & p4)  [ conjution-introduction 4,0 ]  nl\n",
      "13. (p21 | (p88 & p4))  [ disjunction-introduction 12 ]  nl\n",
      "14. (p47 -> p4)  [ implication-introduction 2,0 ]  nl\n",
      "15. (p97 -> p4)  [ implication-introduction 8,0 ]  nl\n",
      "16. ((p75 -> p4) -> p4)  [ implication-introduction 10,0 ]  nl\n",
      "17. (p0 -> p4)  [ implication-introduction 3,0 ] \n",
      "----------------\n",
      "0. p25  [ axiom ]  nl\n",
      "1. p61  [ axiom ]  nl\n",
      "2. p6  [ axiom ]  nl\n",
      "3. p19  [ axiom ]  nl\n",
      "4. p89  [ axiom ]  nl\n",
      "5. p37  [ axiom ]  nl\n",
      "6. (p37 -> p25)  [ implication-introduction 5,0 ]  nl\n",
      "7. (p9 | p19)  [ disjunction-introduction 3 ]  nl\n",
      "8. (p89 -> p25)  [ implication-introduction 4,0 ]  nl\n",
      "9. (p25 | p25)  [ disjunction-introduction 0 ]  nl\n",
      "10. (p6 | (p89 -> p25))  [ disjunction-introduction 8 ]  nl\n",
      "11. ((p37 | p37) -> p25)  [ disjunction-elimination 6,6 ]  nl\n",
      "12. (p25 & p25)  [ conjution-introduction 0,0 ] \n",
      "----------------\n",
      "0. p8  [ axiom ]  nl\n",
      "1. p62  [ axiom ]  nl\n",
      "2. p64  [ axiom ]  nl\n",
      "3. p94  [ axiom ]  nl\n",
      "4. (p96 | p64)  [ disjunction-introduction 2 ]  nl\n",
      "5. (p66 | p8)  [ disjunction-introduction 0 ]  nl\n",
      "6. (p17 | p64)  [ disjunction-introduction 2 ]  nl\n",
      "7. (p74 | (p66 | p8))  [ disjunction-introduction 5 ]  nl\n",
      "8. (p28 | (p74 | (p66 | p8)))  [ disjunction-introduction 7 ]  nl\n",
      "9. (p33 | p94)  [ disjunction-introduction 3 ]  nl\n",
      "10. (p21 | p94)  [ disjunction-introduction 3 ]  nl\n",
      "11. ((p17 | p64) -> p8)  [ implication-introduction 6,0 ] \n",
      "----------------\n",
      "0. p35  [ axiom ]  nl\n",
      "1. p34  [ axiom ]  nl\n",
      "2. p51  [ axiom ]  nl\n",
      "3. p56  [ axiom ]  nl\n",
      "4. p22  [ axiom ]  nl\n",
      "5. p32  [ axiom ]  nl\n",
      "6. p23  [ axiom ]  nl\n",
      "7. (p51 -> p35)  [ implication-introduction 2,0 ]  nl\n",
      "8. ((p51 | p51) -> p35)  [ disjunction-elimination 7,7 ] \n",
      "----------------\n",
      "0. p40  [ axiom ]  nl\n",
      "1. p66  [ axiom ]  nl\n",
      "2. p49  [ axiom ]  nl\n",
      "3. p45  [ axiom ]  nl\n",
      "4. p80  [ axiom ]  nl\n",
      "5. p40  [ axiom ]  nl\n",
      "6. p64  [ axiom ]  nl\n",
      "7. p14  [ axiom ]  nl\n",
      "8. p77  [ axiom ]  nl\n",
      "9. p93  [ axiom ]  nl\n",
      "10. (p49 -> p40)  [ implication-introduction 2,0 ]  nl\n",
      "11. ((p49 | p49) -> p40)  [ disjunction-elimination 10,10 ]  nl\n",
      "12. (p64 & p40)  [ conjution-introduction 6,0 ]  nl\n",
      "13. (((p49 | p49) | p49) -> p40)  [ disjunction-elimination 11,10 ]  nl\n",
      "14. (p44 | p93)  [ disjunction-introduction 9 ]  nl\n",
      "15. ((((p49 | p49) | p49) | p49) -> p40)  [ disjunction-elimination 13,10 ]  nl\n",
      "16. (((((p49 | p49) | p49) | p49) -> p40) -> p40)  [ implication-introduction 15,0 ] \n",
      "----------------\n",
      "0. p58  [ axiom ]  nl\n",
      "1. p53  [ axiom ]  nl\n",
      "2. p43  [ axiom ]  nl\n",
      "3. (p31 | p53)  [ disjunction-introduction 1 ]  nl\n",
      "4. (p58 -> p58)  [ implication-introduction 0,0 ]  nl\n",
      "5. (p30 | (p58 -> p58))  [ disjunction-introduction 4 ]  nl\n",
      "6. (p53 -> p58)  [ implication-introduction 1,0 ]  nl\n",
      "7. (p46 | p43)  [ disjunction-introduction 2 ]  nl\n",
      "8. (p49 | p43)  [ disjunction-introduction 2 ] \n",
      "----------------\n",
      "0. p1  [ axiom ]  nl\n",
      "1. p26  [ axiom ]  nl\n",
      "2. p35  [ axiom ]  nl\n",
      "3. p51  [ axiom ]  nl\n",
      "4. p93  [ axiom ]  nl\n",
      "5. p49  [ axiom ]  nl\n",
      "6. p28  [ axiom ]  nl\n",
      "7. p57  [ axiom ]  nl\n",
      "8. p96  [ axiom ]  nl\n",
      "9. p72  [ axiom ]  nl\n",
      "10. (p49 -> p1)  [ implication-introduction 5,0 ]  nl\n",
      "11. (p96 & p1)  [ conjution-introduction 8,0 ]  nl\n",
      "12. ((p49 | p49) -> p1)  [ disjunction-elimination 10,10 ]  nl\n",
      "13. (p86 | ((p49 | p49) -> p1))  [ disjunction-introduction 12 ] \n",
      "----------------\n",
      "0. p99  [ axiom ]  nl\n",
      "1. (p95 | p99)  [ disjunction-introduction 0 ]  nl\n",
      "2. (p65 | (p95 | p99))  [ disjunction-introduction 1 ] \n",
      "----------------\n",
      "0. p48  [ axiom ]  nl\n",
      "1. p70  [ axiom ]  nl\n",
      "2. p76  [ axiom ]  nl\n",
      "3. p100  [ axiom ]  nl\n",
      "4. p54  [ axiom ]  nl\n",
      "5. p83  [ axiom ]  nl\n",
      "6. (p72 | p54)  [ disjunction-introduction 4 ]  nl\n",
      "7. (p87 | p54)  [ disjunction-introduction 4 ]  nl\n",
      "8. (p70 | p48)  [ disjunction-introduction 0 ]  nl\n",
      "9. (p88 | (p87 | p54))  [ disjunction-introduction 7 ]  nl\n",
      "10. ((p87 | p54) & p48)  [ conjution-introduction 7,0 ]  nl\n",
      "11. (p1 | p76)  [ disjunction-introduction 2 ]  nl\n",
      "12. (p28 | ((p87 | p54) & p48))  [ disjunction-introduction 10 ]  nl\n",
      "13. ((p88 | (p87 | p54)) & p48)  [ conjution-introduction 9,0 ]  nl\n",
      "14. (p76 -> p48)  [ implication-introduction 2,0 ]  nl\n",
      "15. ((p76 -> p48) & p48)  [ conjution-introduction 14,0 ]  nl\n",
      "16. (((p88 | (p87 | p54)) & p48) -> p48)  [ implication-introduction 13,0 ] \n"
     ]
    }
   ],
   "source": [
    "from random import (\n",
    "    randint,\n",
    ")\n",
    "\n",
    "from project.utils.prop_logic import (\n",
    "    Proof,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_random_theorems(\n",
    "    training_size=10,\n",
    "    axioms=10,\n",
    "    teo_steps=100,\n",
    "    max_teorem_size=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    training_set: list = []\n",
    "    assert numbers >= axioms, \"The number of axioms must be less than the number of numbers\"\n",
    "    while len(training_set) < training_size:\n",
    "        proof = Proof(\n",
    "            numbers=numbers,\n",
    "            prepositions=prepositions,\n",
    "        )\n",
    "\n",
    "        # Generates Axioms\n",
    "        for _ in range(\n",
    "            randint(\n",
    "                1,\n",
    "                axioms,\n",
    "            )\n",
    "        ):\n",
    "            proof.append_axiom(proof.get_random_statement())\n",
    "        proof.generate_steps(\n",
    "            randint(\n",
    "                1,\n",
    "                teo_steps,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        str_proof = str(proof)\n",
    "        if len(str_proof) < max_teorem_size:\n",
    "            training_set.append(str_proof)\n",
    "    return training_set\n",
    "\n",
    "\n",
    "def generates_vocabulary(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    numbers_list = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        numbers,\n",
    "    ):\n",
    "        numbers_list.append(str(i))\n",
    "\n",
    "    prepos = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        prepositions,\n",
    "    ):\n",
    "        prepos.append(f\"p{i}\")\n",
    "\n",
    "    tokens = [\n",
    "        \"[PAD]\",\n",
    "        \"[UNK]\",\n",
    "        \"[CLS]\",\n",
    "        \"[SEP]\",\n",
    "        \"[MASK]\",\n",
    "    ]\n",
    "    special_word = [\n",
    "        \"nl\",\n",
    "        \"hypothesis\",\n",
    "        \"conclusion\",\n",
    "        \"proof\",\n",
    "    ]\n",
    "    punctuation = [\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"[\",\n",
    "        \"]\",\n",
    "        \"-\",\n",
    "    ]\n",
    "    logic_operators = [\n",
    "        \"|\",\n",
    "        \"&\",\n",
    "        \"!\",\n",
    "        \"(\",\n",
    "        \")\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "    ]\n",
    "    rules = [\n",
    "        \"introduction\",\n",
    "        \"elimination\",\n",
    "        \"axiom\",\n",
    "        \"implication\",\n",
    "        \"conjution\",\n",
    "        \"disjunction\",\n",
    "        \"negation\",\n",
    "        \"biconditional\",\n",
    "    ]\n",
    "    generates_vocabulary = tokens + special_word + punctuation + logic_operators + rules + prepos + numbers_list\n",
    "    return generates_vocabulary\n",
    "\n",
    "\n",
    "ts = generate_random_theorems(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    ")\n",
    "\n",
    "for teo in ts:\n",
    "    print(\"----------------\")\n",
    "    print(teo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59516d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "RELATIVE_DATA_PATH = \"../.tmp/data\"\n",
    "\n",
    "notebook_path = os.getcwd()\n",
    "data_dir = os.path.join(\n",
    "    notebook_path,\n",
    "    RELATIVE_DATA_PATH,\n",
    ")\n",
    "train_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"training\",\n",
    ")\n",
    "val_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating_random_theorems()\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(val_dir):\n",
    "    os.makedirs(val_dir)\n",
    "\n",
    "\n",
    "def save_to_json(\n",
    "    data,\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            data,\n",
    "            f,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_from_json(\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_vocab(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    vocab = generates_vocabulary(\n",
    "        numbers=numbers,\n",
    "        prepositions=prepositions,\n",
    "    )\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def crate_training_data(\n",
    "    batch_dir,\n",
    "    batch_size=100,\n",
    "    max_len=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    print(\"generating_random_theorems()\")\n",
    "    theorems = generate_random_theorems(\n",
    "        batch_size,\n",
    "        max_teorem_size=max_len - 2,\n",
    "        numbers=1000,\n",
    "        prepositions=100,\n",
    "    )  # -2, saving space for CLS and END tokens\n",
    "    print(\"Making theorems\")\n",
    "\n",
    "    file_name = f\"theorems.json\"\n",
    "    file_path = os.path.join(\n",
    "        batch_dir,\n",
    "        file_name,\n",
    "    )\n",
    "    print(f\"Saving to path: {file_path}\")\n",
    "    save_to_json(\n",
    "        theorems,\n",
    "        file_path,\n",
    "    )\n",
    "\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 10000\n",
    "numbers = 10000\n",
    "prepositions = 1000\n",
    "\n",
    "# Create Vocabulary\n",
    "vocab = create_vocab(\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "with open(\n",
    "    os.path.join(\n",
    "        train_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "with open(\n",
    "    os.path.join(\n",
    "        val_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "\n",
    "\n",
    "# # create different batches with different max_pred, to ramp up the difficulty\n",
    "crate_training_data(\n",
    "    train_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "\n",
    "# # create validation data\n",
    "crate_training_data(\n",
    "    val_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size * 0.20,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d59143",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
