{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394bb3ff-f742-454d-8080-5e60d8175299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp  project.models.bert.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132de7d9",
   "metadata": {},
   "source": [
    "# Create data and Encoders\n",
    "\n",
    "> Just run this Notebook to generate the data in `.tmp`\n",
    "\n",
    "This notebooks creates data to train the BERT in first order logic. It uses `notebooks.utils.prop_logi` module to generates random theorems. Then mask some persentage of tokens.\n",
    "\n",
    "Generated Data:\n",
    "\n",
    "```\n",
    ".tmp\n",
    "└── data\n",
    "    ├── training\n",
    "    │   ├── theorems.json\n",
    "    │   └── vocab.txt\n",
    "    └── validation\n",
    "        ├── theorems.json\n",
    "        └── vocab.txt\n",
    "```\n",
    "\n",
    "The idea is generate a dataset for train and validation, save the datasets on disk `.tmp` and then it is upload it to an s3 buckets to be used by the production pipeline.\n",
    "\n",
    "During research phase we are going to use the `.tmp` directory to shorcut the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bebace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "0. p47  [ axiom ]  nl\n",
      "1. p20  [ axiom ]  nl\n",
      "2. p77  [ axiom ]  nl\n",
      "3. p82  [ axiom ]  nl\n",
      "4. p44  [ axiom ]  nl\n",
      "5. p95  [ axiom ]  nl\n",
      "6. p69  [ axiom ]  nl\n",
      "7. (p4 | p77)  [ disjunction-introduction 2 ]  nl\n",
      "8. (p77 & p47)  [ conjution-introduction 2,0 ]  nl\n",
      "9. (p44 & p47)  [ conjution-introduction 4,0 ]  nl\n",
      "10. (p31 | p82)  [ disjunction-introduction 3 ]  nl\n",
      "11. ((p77 & p47) & p47)  [ conjution-introduction 8,0 ]  nl\n",
      "12. (p95 & p47)  [ conjution-introduction 5,0 ]  nl\n",
      "13. (p51 | p20)  [ disjunction-introduction 1 ]  nl\n",
      "14. (p55 | (p95 & p47))  [ disjunction-introduction 12 ]  nl\n",
      "15. (p30 | (p31 | p82))  [ disjunction-introduction 10 ]  nl\n",
      "16. ((p95 & p47) & p47)  [ conjution-introduction 12,0 ]  nl\n",
      "17. (p20 -> p47)  [ implication-introduction 1,0 ]  nl\n",
      "18. ((p20 | p20) -> p47)  [ disjunction-elimination 17,17 ] \n",
      "----------------\n",
      "0. p19  [ axiom ]  nl\n",
      "1. (p79 | p19)  [ disjunction-introduction 0 ]  nl\n",
      "2. (p90 | p19)  [ disjunction-introduction 0 ]  nl\n",
      "3. ((p79 | p19) & p19)  [ conjution-introduction 1,0 ]  nl\n",
      "4. (p65 | (p90 | p19))  [ disjunction-introduction 2 ]  nl\n",
      "5. ((p79 | p19) -> p19)  [ implication-introduction 1,0 ]  nl\n",
      "6. ((p90 | p19) & p19)  [ conjution-introduction 2,0 ]  nl\n",
      "7. (((p90 | p19) & p19) -> p19)  [ implication-introduction 6,0 ]  nl\n",
      "8. ((((p90 | p19) & p19) | (p79 | p19)) -> p19)  [ disjunction-elimination 7,5 ]  nl\n",
      "9. ((p90 | p19) -> p19)  [ implication-introduction 2,0 ]  nl\n",
      "10. (p97 | ((p79 | p19) & p19))  [ disjunction-introduction 3 ]  nl\n",
      "11. (p13 | ((p79 | p19) -> p19))  [ disjunction-introduction 5 ]  nl\n",
      "12. (((p90 | p19) | (p79 | p19)) -> p19)  [ disjunction-elimination 9,5 ]  nl\n",
      "13. ((((p90 | p19) & p19) -> p19) & p19)  [ conjution-introduction 7,0 ] \n",
      "----------------\n",
      "0. p77  [ axiom ]  nl\n",
      "1. p40  [ axiom ]  nl\n",
      "2. p13  [ axiom ]  nl\n",
      "3. p94  [ axiom ]  nl\n",
      "4. p50  [ axiom ]  nl\n",
      "5. p93  [ axiom ]  nl\n",
      "6. p66  [ axiom ]  nl\n",
      "7. (p94 & p77)  [ conjution-introduction 3,0 ]  nl\n",
      "8. (p93 -> p77)  [ implication-introduction 5,0 ] \n",
      "----------------\n",
      "0. p32  [ axiom ]  nl\n",
      "1. p65  [ axiom ]  nl\n",
      "2. p28  [ axiom ]  nl\n",
      "3. p46  [ axiom ]  nl\n",
      "4. p69  [ axiom ]  nl\n",
      "5. (p47 | p46)  [ disjunction-introduction 3 ]  nl\n",
      "6. (p37 | p46)  [ disjunction-introduction 3 ]  nl\n",
      "7. (p65 & p32)  [ conjution-introduction 1,0 ]  nl\n",
      "8. (p41 | p65)  [ disjunction-introduction 1 ]  nl\n",
      "9. (p88 | p46)  [ disjunction-introduction 3 ] \n",
      "----------------\n",
      "0. p39  [ axiom ]  nl\n",
      "1. p7  [ axiom ]  nl\n",
      "2. p13  [ axiom ]  nl\n",
      "3. p0  [ axiom ]  nl\n",
      "4. p14  [ axiom ]  nl\n",
      "5. p4  [ axiom ]  nl\n",
      "6. p52  [ axiom ]  nl\n",
      "7. (p16 | p4)  [ disjunction-introduction 5 ]  nl\n",
      "8. (p12 | (p16 | p4))  [ disjunction-introduction 7 ]  nl\n",
      "9. (p14 | p13)  [ disjunction-introduction 2 ]  nl\n",
      "10. (p39 & p39)  [ conjution-introduction 0,0 ]  nl\n",
      "11. ((p39 & p39) -> p39)  [ implication-introduction 10,0 ]  nl\n",
      "12. (p4 -> p39)  [ implication-introduction 5,0 ]  nl\n",
      "13. ((p14 | p13) & p39)  [ conjution-introduction 9,0 ]  nl\n",
      "14. ((p16 | p4) & p39)  [ conjution-introduction 7,0 ]  nl\n",
      "15. (((p39 & p39) -> p39) & p39)  [ conjution-introduction 11,0 ] \n",
      "----------------\n",
      "0. p31  [ axiom ]  nl\n",
      "1. p83  [ axiom ]  nl\n",
      "2. (p83 -> p31)  [ implication-introduction 1,0 ]  nl\n",
      "3. (p70 | p83)  [ disjunction-introduction 1 ]  nl\n",
      "4. (p36 | p31)  [ disjunction-introduction 0 ]  nl\n",
      "5. (p83 & p31)  [ conjution-introduction 1,0 ]  nl\n",
      "6. ((p36 | p31) & p31)  [ conjution-introduction 4,0 ]  nl\n",
      "7. ((p83 | p83) -> p31)  [ disjunction-elimination 2,2 ]  nl\n",
      "8. ((p70 | p83) & p31)  [ conjution-introduction 3,0 ]  nl\n",
      "9. (p30 | ((p83 | p83) -> p31))  [ disjunction-introduction 7 ]  nl\n",
      "10. (p97 | (p83 -> p31))  [ disjunction-introduction 2 ]  nl\n",
      "11. (p31 -> p31)  [ implication-introduction 0,0 ]  nl\n",
      "12. (p31 <-> p31)  [ biconditional-introduction 11,11 ]  nl\n",
      "13. (p92 | ((p70 | p83) & p31))  [ disjunction-introduction 8 ]  nl\n",
      "14. (p15 | (p31 -> p31))  [ disjunction-introduction 11 ] \n",
      "----------------\n",
      "0. p63  [ axiom ]  nl\n",
      "1. p42  [ axiom ]  nl\n",
      "2. p39  [ axiom ]  nl\n",
      "3. p66  [ axiom ]  nl\n",
      "4. p80  [ axiom ]  nl\n",
      "5. p53  [ axiom ]  nl\n",
      "6. p57  [ axiom ]  nl\n",
      "7. p89  [ axiom ]  nl\n",
      "8. (p42 & p63)  [ conjution-introduction 1,0 ]  nl\n",
      "9. (p89 & p63)  [ conjution-introduction 7,0 ]  nl\n",
      "10. (p42 -> p63)  [ implication-introduction 1,0 ]  nl\n",
      "11. (p96 | p42)  [ disjunction-introduction 1 ]  nl\n",
      "12. ((p42 | p42) -> p63)  [ disjunction-elimination 10,10 ]  nl\n",
      "13. (p80 | (p42 & p63))  [ disjunction-introduction 8 ]  nl\n",
      "14. (((p42 | p42) | p42) -> p63)  [ disjunction-elimination 12,10 ] \n",
      "----------------\n",
      "0. p33  [ axiom ]  nl\n",
      "1. p40  [ axiom ]  nl\n",
      "2. p22  [ axiom ]  nl\n",
      "3. p20  [ axiom ]  nl\n",
      "4. p46  [ axiom ]  nl\n",
      "5. p55  [ axiom ]  nl\n",
      "6. p98  [ axiom ]  nl\n",
      "7. p50  [ axiom ]  nl\n",
      "8. (p22 | p50)  [ disjunction-introduction 7 ]  nl\n",
      "9. (p40 & p33)  [ conjution-introduction 1,0 ]  nl\n",
      "10. (p33 & p33)  [ conjution-introduction 0,0 ]  nl\n",
      "11. ((p22 | p50) -> p33)  [ implication-introduction 8,0 ]  nl\n",
      "12. (p50 | p33)  [ disjunction-introduction 0 ]  nl\n",
      "13. (((p22 | p50) | (p22 | p50)) -> p33)  [ disjunction-elimination 11,11 ]  nl\n",
      "14. (p13 | (p22 | p50))  [ disjunction-introduction 8 ]  nl\n",
      "15. (p78 | p46)  [ disjunction-introduction 4 ]  nl\n",
      "16. (p66 | (p22 | p50))  [ disjunction-introduction 8 ]  nl\n",
      "17. (p55 | ((p22 | p50) -> p33))  [ disjunction-introduction 11 ]  nl\n",
      "18. ((p66 | (p22 | p50)) & p33)  [ conjution-introduction 16,0 ] \n",
      "----------------\n",
      "0. p29  [ axiom ]  nl\n",
      "1. p99  [ axiom ]  nl\n",
      "2. p31  [ axiom ]  nl\n",
      "3. p63  [ axiom ]  nl\n",
      "4. p63  [ axiom ]  nl\n",
      "5. p71  [ axiom ]  nl\n",
      "6. (p8 | p71)  [ disjunction-introduction 5 ]  nl\n",
      "7. (p34 | p29)  [ disjunction-introduction 0 ]  nl\n",
      "8. (p63 -> p29)  [ implication-introduction 3,0 ]  nl\n",
      "9. ((p63 | p63) -> p29)  [ disjunction-elimination 8,8 ]  nl\n",
      "10. ((p63 -> p29) -> p29)  [ implication-introduction 8,0 ]  nl\n",
      "11. ((p8 | p71) & p29)  [ conjution-introduction 6,0 ]  nl\n",
      "12. (p73 | p71)  [ disjunction-introduction 5 ]  nl\n",
      "13. (p31 -> p29)  [ implication-introduction 2,0 ]  nl\n",
      "14. (p70 | (p34 | p29))  [ disjunction-introduction 7 ]  nl\n",
      "15. (((p8 | p71) & p29) -> p29)  [ implication-introduction 11,0 ]  nl\n",
      "16. (p31 & p29)  [ conjution-introduction 2,0 ]  nl\n",
      "17. ((p70 | (p34 | p29)) -> p29)  [ implication-introduction 14,0 ]  nl\n",
      "18. ((p73 | p71) & p29)  [ conjution-introduction 12,0 ] \n",
      "----------------\n",
      "0. p48  [ axiom ]  nl\n",
      "1. p36  [ axiom ]  nl\n",
      "2. p95  [ axiom ]  nl\n",
      "3. p25  [ axiom ]  nl\n",
      "4. p82  [ axiom ]  nl\n",
      "5. p85  [ axiom ]  nl\n",
      "6. p24  [ axiom ]  nl\n",
      "7. p43  [ axiom ]  nl\n",
      "8. p33  [ axiom ]  nl\n",
      "9. (p82 -> p48)  [ implication-introduction 4,0 ]  nl\n",
      "10. (p24 & p48)  [ conjution-introduction 6,0 ]  nl\n",
      "11. (p85 -> p48)  [ implication-introduction 5,0 ]  nl\n",
      "12. ((p85 -> p48) -> p48)  [ implication-introduction 11,0 ]  nl\n",
      "13. ((p82 -> p48) -> p48)  [ implication-introduction 9,0 ]  nl\n",
      "14. ((p82 -> p48) & p48)  [ conjution-introduction 9,0 ]  nl\n",
      "15. (p60 | p48)  [ disjunction-introduction 0 ]  nl\n",
      "16. (((p85 -> p48) -> p48) & p48)  [ conjution-introduction 12,0 ] \n"
     ]
    }
   ],
   "source": [
    "from random import (\n",
    "    randint,\n",
    ")\n",
    "\n",
    "from project.utils.prop_logic import (\n",
    "    Proof,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_random_theorems(\n",
    "    training_size=10,\n",
    "    axioms=10,\n",
    "    teo_steps=100,\n",
    "    max_teorem_size=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    training_set: list = []\n",
    "    assert numbers >= axioms, \"The number of axioms must be less than the number of numbers\"\n",
    "    while len(training_set) < training_size:\n",
    "        proof = Proof(\n",
    "            numbers=numbers,\n",
    "            prepositions=prepositions,\n",
    "        )\n",
    "\n",
    "        # Generates Axioms\n",
    "        for _ in range(\n",
    "            randint(\n",
    "                1,\n",
    "                axioms,\n",
    "            )\n",
    "        ):\n",
    "            proof.append_axiom(proof.get_random_statement())\n",
    "        proof.generate_steps(\n",
    "            randint(\n",
    "                1,\n",
    "                teo_steps,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        str_proof = str(proof)\n",
    "        if len(str_proof) < max_teorem_size:\n",
    "            training_set.append(str_proof)\n",
    "    return training_set\n",
    "\n",
    "\n",
    "def generates_vocabulary(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    numbers_list = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        numbers,\n",
    "    ):\n",
    "        numbers_list.append(str(i))\n",
    "\n",
    "    prepos = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        prepositions,\n",
    "    ):\n",
    "        prepos.append(f\"p{i}\")\n",
    "\n",
    "    tokens = [\n",
    "        \"[PAD]\",\n",
    "        \"[UNK]\",\n",
    "        \"[CLS]\",\n",
    "        \"[SEP]\",\n",
    "        \"[MASK]\",\n",
    "    ]\n",
    "    special_word = [\n",
    "        \"nl\",\n",
    "        \"hypothesis\",\n",
    "        \"conclusion\",\n",
    "        \"proof\",\n",
    "    ]\n",
    "    punctuation = [\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"[\",\n",
    "        \"]\",\n",
    "        \"-\",\n",
    "    ]\n",
    "    logic_operators = [\n",
    "        \"|\",\n",
    "        \"&\",\n",
    "        \"!\",\n",
    "        \"(\",\n",
    "        \")\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "    ]\n",
    "    rules = [\n",
    "        \"introduction\",\n",
    "        \"elimination\",\n",
    "        \"axiom\",\n",
    "        \"implication\",\n",
    "        \"conjution\",\n",
    "        \"disjunction\",\n",
    "        \"negation\",\n",
    "        \"biconditional\",\n",
    "    ]\n",
    "    generates_vocabulary = tokens + special_word + punctuation + logic_operators + rules + prepos + numbers_list\n",
    "    return generates_vocabulary\n",
    "\n",
    "\n",
    "ts = generate_random_theorems(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    ")\n",
    "\n",
    "for teo in ts:\n",
    "    print(\"----------------\")\n",
    "    print(teo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59516d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "RELATIVE_DATA_PATH = \"../.tmp/data\"\n",
    "\n",
    "notebook_path = os.getcwd()\n",
    "data_dir = os.path.join(\n",
    "    notebook_path,\n",
    "    RELATIVE_DATA_PATH,\n",
    ")\n",
    "train_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"training\",\n",
    ")\n",
    "val_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22deb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating_random_theorems()\n",
      "Making theorems\n",
      "Saving to path: /notebooks/source_scripts/../.tmp/data/training/theorems.json\n",
      "generating_random_theorems()\n",
      "Making theorems\n",
      "Saving to path: /notebooks/source_scripts/../.tmp/data/validation/theorems.json\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(val_dir):\n",
    "    os.makedirs(val_dir)\n",
    "\n",
    "\n",
    "def save_to_json(\n",
    "    data,\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            data,\n",
    "            f,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_from_json(\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_vocab(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    vocab = generates_vocabulary(\n",
    "        numbers=numbers,\n",
    "        prepositions=prepositions,\n",
    "    )\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def crate_training_data(\n",
    "    batch_dir,\n",
    "    batch_size=100,\n",
    "    max_len=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    print(\"generating_random_theorems()\")\n",
    "    theorems = generate_random_theorems(\n",
    "        batch_size,\n",
    "        max_teorem_size=max_len - 2,\n",
    "        numbers=1000,\n",
    "        prepositions=100,\n",
    "    )  # -2, saving space for CLS and END tokens\n",
    "    print(\"Making theorems\")\n",
    "\n",
    "    file_name = f\"theorems.json\"\n",
    "    file_path = os.path.join(\n",
    "        batch_dir,\n",
    "        file_name,\n",
    "    )\n",
    "    print(f\"Saving to path: {file_path}\")\n",
    "    save_to_json(\n",
    "        theorems,\n",
    "        file_path,\n",
    "    )\n",
    "\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 1000\n",
    "numbers = 10000\n",
    "prepositions = 1000\n",
    "\n",
    "# Create Vocabulary\n",
    "vocab = create_vocab(\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "with open(\n",
    "    os.path.join(\n",
    "        train_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "with open(\n",
    "    os.path.join(\n",
    "        val_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "\n",
    "\n",
    "# # create different batches with different max_pred, to ramp up the difficulty\n",
    "crate_training_data(\n",
    "    train_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "\n",
    "# # create validation data\n",
    "crate_training_data(\n",
    "    val_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size * 0.20,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
