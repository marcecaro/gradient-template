{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394bb3ff-f742-454d-8080-5e60d8175299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp  project.models.bert.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132de7d9",
   "metadata": {},
   "source": [
    "# Create data and Encoders\n",
    "\n",
    "> Just run this Notebook to generate the data in `.tmp`\n",
    "\n",
    "This notebooks creates data to train the BERT in first order logic. It uses `notebooks.utils.prop_logi` module to generates random theorems. Then mask some persentage of tokens.\n",
    "\n",
    "Generated Data:\n",
    "\n",
    "```\n",
    ".tmp\n",
    "└── data\n",
    "    ├── training\n",
    "    │   ├── theorems.json\n",
    "    │   └── vocab.txt\n",
    "    └── validation\n",
    "        ├── theorems.json\n",
    "        └── vocab.txt\n",
    "```\n",
    "\n",
    "The idea is generate a dataset for train and validation, save the datasets on disk `.tmp` and then it is upload it to an s3 buckets to be used by the production pipeline.\n",
    "\n",
    "During research phase we are going to use the `.tmp` directory to shorcut the process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bebace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "0. p97  [ axiom ]  nl\n",
      "1. p43  [ axiom ]  nl\n",
      "2. p55  [ axiom ]  nl\n",
      "3. p15  [ axiom ]  nl\n",
      "4. p7  [ axiom ]  nl\n",
      "5. p24  [ axiom ]  nl\n",
      "6. (p43 & p97)  [ conjution-introduction 1,0 ]  nl\n",
      "7. (p97 -> p97)  [ implication-introduction 0,0 ]  nl\n",
      "8. (p97 <-> p97)  [ biconditional-introduction 7,7 ]  nl\n",
      "9. ((p97 <-> p97) -> p97)  [ implication-introduction 8,0 ]  nl\n",
      "10. (p78 | p15)  [ disjunction-introduction 3 ]  nl\n",
      "11. (p62 | ((p97 <-> p97) -> p97))  [ disjunction-introduction 9 ]  nl\n",
      "12. ((p97 | p97) -> p97)  [ disjunction-elimination 7,7 ]  nl\n",
      "13. ((p62 | ((p97 <-> p97) -> p97)) & p97)  [ conjution-introduction 11,0 ]  nl\n",
      "14. (p87 | p43)  [ disjunction-introduction 1 ]  nl\n",
      "15. (p70 | ((p62 | ((p97 <-> p97) -> p97)) & p97))  [ disjunction-introduction 13 ]  nl\n",
      "16. ((p70 | ((p62 | ((p97 <-> p97) -> p97)) & p97)) & p97)  [ conjution-introduction 15,0 ]  nl\n",
      "17. (p66 | p43)  [ disjunction-introduction 1 ] \n",
      "----------------\n",
      "0. p87  [ axiom ]  nl\n",
      "1. p45  [ axiom ]  nl\n",
      "2. (p57 | p45)  [ disjunction-introduction 1 ]  nl\n",
      "3. (p45 -> p87)  [ implication-introduction 1,0 ]  nl\n",
      "4. (p87 -> p87)  [ implication-introduction 0,0 ]  nl\n",
      "5. (p8 | (p87 -> p87))  [ disjunction-introduction 4 ]  nl\n",
      "6. (p87 & p87)  [ conjution-introduction 0,0 ]  nl\n",
      "7. ((p87 -> p87) -> p87)  [ implication-introduction 4,0 ]  nl\n",
      "8. ((p57 | p45) & p87)  [ conjution-introduction 2,0 ]  nl\n",
      "9. ((p87 -> p87) & p87)  [ conjution-introduction 4,0 ]  nl\n",
      "10. (((p57 | p45) & p87) -> p87)  [ implication-introduction 8,0 ]  nl\n",
      "11. ((p57 | p45) -> p87)  [ implication-introduction 2,0 ]  nl\n",
      "12. ((p45 | p45) -> p87)  [ disjunction-elimination 3,3 ] \n",
      "----------------\n",
      "0. p2  [ axiom ]  nl\n",
      "1. p47  [ axiom ]  nl\n",
      "2. p42  [ axiom ]  nl\n",
      "3. p97  [ axiom ]  nl\n",
      "4. p54  [ axiom ]  nl\n",
      "5. p34  [ axiom ]  nl\n",
      "6. p17  [ axiom ]  nl\n",
      "7. p49  [ axiom ]  nl\n",
      "8. p24  [ axiom ]  nl\n",
      "9. p88  [ axiom ]  nl\n",
      "10. (p100 | p54)  [ disjunction-introduction 4 ]  nl\n",
      "11. (p24 -> p2)  [ implication-introduction 8,0 ]  nl\n",
      "12. (p54 -> p2)  [ implication-introduction 4,0 ]  nl\n",
      "13. (p17 | (p24 -> p2))  [ disjunction-introduction 11 ]  nl\n",
      "14. (p24 & p2)  [ conjution-introduction 8,0 ]  nl\n",
      "15. ((p54 | p24) -> p2)  [ disjunction-elimination 12,11 ]  nl\n",
      "16. (p72 | p2)  [ disjunction-introduction 0 ]  nl\n",
      "17. (p47 & p2)  [ conjution-introduction 1,0 ]  nl\n",
      "18. (p49 -> p2)  [ implication-introduction 7,0 ]  nl\n",
      "19. (p71 | (p24 & p2))  [ disjunction-introduction 14 ]  nl\n",
      "20. (p13 | p24)  [ disjunction-introduction 8 ] \n",
      "----------------\n",
      "0. p78  [ axiom ]  nl\n",
      "1. (p78 -> p78)  [ implication-introduction 0,0 ]  nl\n",
      "2. (p78 <-> p78)  [ biconditional-introduction 1,1 ]  nl\n",
      "3. ((p78 | p78) -> p78)  [ disjunction-elimination 1,1 ] \n",
      "----------------\n",
      "0. p75  [ axiom ]  nl\n",
      "1. p98  [ axiom ]  nl\n",
      "2. p32  [ axiom ]  nl\n",
      "3. p37  [ axiom ]  nl\n",
      "4. p67  [ axiom ]  nl\n",
      "5. (p98 & p75)  [ conjution-introduction 1,0 ]  nl\n",
      "6. (p27 | p37)  [ disjunction-introduction 3 ]  nl\n",
      "7. (p48 | p37)  [ disjunction-introduction 3 ]  nl\n",
      "8. (p75 & p75)  [ conjution-introduction 0,0 ]  nl\n",
      "9. (p32 & p75)  [ conjution-introduction 2,0 ]  nl\n",
      "10. ((p75 & p75) & p75)  [ conjution-introduction 8,0 ]  nl\n",
      "11. ((p32 & p75) & p75)  [ conjution-introduction 9,0 ]  nl\n",
      "12. ((p98 & p75) -> p75)  [ implication-introduction 5,0 ]  nl\n",
      "13. (((p75 & p75) & p75) -> p75)  [ implication-introduction 10,0 ]  nl\n",
      "14. (((p75 & p75) & p75) & p75)  [ conjution-introduction 10,0 ]  nl\n",
      "15. ((p98 & p75) & p75)  [ conjution-introduction 5,0 ] \n",
      "----------------\n",
      "0. p12  [ axiom ]  nl\n",
      "1. p47  [ axiom ]  nl\n",
      "2. p13  [ axiom ]  nl\n",
      "3. p78  [ axiom ]  nl\n",
      "4. p69  [ axiom ]  nl\n",
      "5. p15  [ axiom ]  nl\n",
      "6. p31  [ axiom ]  nl\n",
      "7. p44  [ axiom ]  nl\n",
      "8. p78  [ axiom ]  nl\n",
      "9. (p78 -> p12)  [ implication-introduction 3,0 ]  nl\n",
      "10. ((p78 | p78) -> p12)  [ disjunction-elimination 9,9 ]  nl\n",
      "11. (p29 | ((p78 | p78) -> p12))  [ disjunction-introduction 10 ] \n",
      "----------------\n",
      "0. p4  [ axiom ]  nl\n",
      "1. p79  [ axiom ]  nl\n",
      "2. p82  [ axiom ]  nl\n",
      "3. p80  [ axiom ]  nl\n",
      "4. p19  [ axiom ]  nl\n",
      "5. p32  [ axiom ]  nl\n",
      "6. (p29 | p4)  [ disjunction-introduction 0 ]  nl\n",
      "7. (p32 -> p4)  [ implication-introduction 5,0 ]  nl\n",
      "8. (p45 | p32)  [ disjunction-introduction 5 ]  nl\n",
      "9. (p50 | p19)  [ disjunction-introduction 4 ]  nl\n",
      "10. (p36 | p79)  [ disjunction-introduction 1 ]  nl\n",
      "11. (p29 | (p29 | p4))  [ disjunction-introduction 6 ]  nl\n",
      "12. (p80 & p4)  [ conjution-introduction 3,0 ]  nl\n",
      "13. (p40 | (p32 -> p4))  [ disjunction-introduction 7 ]  nl\n",
      "14. ((p32 | p32) -> p4)  [ disjunction-elimination 7,7 ]  nl\n",
      "15. ((p36 | p79) & p4)  [ conjution-introduction 10,0 ]  nl\n",
      "16. ((p36 | p79) -> p4)  [ implication-introduction 10,0 ]  nl\n",
      "17. (p19 -> p4)  [ implication-introduction 4,0 ]  nl\n",
      "18. (p64 | (p29 | (p29 | p4)))  [ disjunction-introduction 11 ]  nl\n",
      "19. ((p19 | p32) -> p4)  [ disjunction-elimination 17,7 ] \n",
      "----------------\n",
      "0. p6  [ axiom ]  nl\n",
      "1. p96  [ axiom ]  nl\n",
      "2. p12  [ axiom ]  nl\n",
      "3. p63  [ axiom ]  nl\n",
      "4. p51  [ axiom ]  nl\n",
      "5. p0  [ axiom ]  nl\n",
      "6. p89  [ axiom ]  nl\n",
      "7. (p88 | p89)  [ disjunction-introduction 6 ]  nl\n",
      "8. (p96 -> p6)  [ implication-introduction 1,0 ]  nl\n",
      "9. (p6 & p6)  [ conjution-introduction 0,0 ]  nl\n",
      "10. ((p96 | p96) -> p6)  [ disjunction-elimination 8,8 ]  nl\n",
      "11. ((p96 -> p6) -> p6)  [ implication-introduction 8,0 ]  nl\n",
      "12. (((p96 -> p6) | p96) -> p6)  [ disjunction-elimination 11,8 ] \n",
      "----------------\n",
      "0. p18  [ axiom ]  nl\n",
      "1. p21  [ axiom ]  nl\n",
      "2. p68  [ axiom ]  nl\n",
      "3. p72  [ axiom ]  nl\n",
      "4. (p68 -> p18)  [ implication-introduction 2,0 ]  nl\n",
      "5. ((p68 | p68) -> p18)  [ disjunction-elimination 4,4 ]  nl\n",
      "6. (p68 & p18)  [ conjution-introduction 2,0 ]  nl\n",
      "7. (((p68 | p68) -> p18) -> p18)  [ implication-introduction 5,0 ]  nl\n",
      "8. (p67 | (p68 & p18))  [ disjunction-introduction 6 ] \n",
      "----------------\n",
      "0. p74  [ axiom ]  nl\n",
      "1. p50  [ axiom ]  nl\n",
      "2. p37  [ axiom ]  nl\n",
      "3. p83  [ axiom ]  nl\n",
      "4. p58  [ axiom ]  nl\n",
      "5. p85  [ axiom ]  nl\n",
      "6. p28  [ axiom ]  nl\n",
      "7. (p28 & p74)  [ conjution-introduction 6,0 ]  nl\n",
      "8. (p54 | (p28 & p74))  [ disjunction-introduction 7 ]  nl\n",
      "9. (p24 | (p28 & p74))  [ disjunction-introduction 7 ]  nl\n",
      "10. ((p28 & p74) & p74)  [ conjution-introduction 7,0 ]  nl\n",
      "11. (p87 | p83)  [ disjunction-introduction 3 ]  nl\n",
      "12. ((p87 | p83) -> p74)  [ implication-introduction 11,0 ]  nl\n",
      "13. (((p28 & p74) & p74) & p74)  [ conjution-introduction 10,0 ]  nl\n",
      "14. (p79 | p74)  [ disjunction-introduction 0 ]  nl\n",
      "15. (p62 | (p54 | (p28 & p74)))  [ disjunction-introduction 8 ] \n"
     ]
    }
   ],
   "source": [
    "from random import (\n",
    "    randint,\n",
    ")\n",
    "\n",
    "from project.utils.prop_logic import (\n",
    "    Proof,\n",
    ")\n",
    "\n",
    "\n",
    "def generate_random_theorems(\n",
    "    training_size=10,\n",
    "    axioms=10,\n",
    "    teo_steps=100,\n",
    "    max_teorem_size=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    training_set: list = []\n",
    "    assert numbers >= axioms, \"The number of axioms must be less than the number of numbers\"\n",
    "    while len(training_set) < training_size:\n",
    "        proof = Proof(\n",
    "            numbers=numbers,\n",
    "            prepositions=prepositions,\n",
    "        )\n",
    "\n",
    "        # Generates Axioms\n",
    "        for _ in range(\n",
    "            randint(\n",
    "                1,\n",
    "                axioms,\n",
    "            )\n",
    "        ):\n",
    "            proof.append_axiom(proof.get_random_statement())\n",
    "        proof.generate_steps(\n",
    "            randint(\n",
    "                1,\n",
    "                teo_steps,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        str_proof = str(proof)\n",
    "        if len(str_proof) < max_teorem_size:\n",
    "            training_set.append(str_proof)\n",
    "    return training_set\n",
    "\n",
    "\n",
    "def generates_vocabulary(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    numbers_list = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        numbers,\n",
    "    ):\n",
    "        numbers_list.append(str(i))\n",
    "\n",
    "    prepos = []\n",
    "    for i in range(\n",
    "        0,\n",
    "        prepositions,\n",
    "    ):\n",
    "        prepos.append(f\"p{i}\")\n",
    "\n",
    "    tokens = [\n",
    "        \"[PAD]\",\n",
    "        \"[UNK]\",\n",
    "        \"[CLS]\",\n",
    "        \"[SEP]\",\n",
    "        \"[MASK]\",\n",
    "    ]\n",
    "    special_word = [\n",
    "        \"nl\",\n",
    "        \"hypothesis\",\n",
    "        \"conclusion\",\n",
    "        \"proof\",\n",
    "    ]\n",
    "    punctuation = [\n",
    "        \".\",\n",
    "        \",\",\n",
    "        \"[\",\n",
    "        \"]\",\n",
    "        \"-\",\n",
    "    ]\n",
    "    logic_operators = [\n",
    "        \"|\",\n",
    "        \"&\",\n",
    "        \"!\",\n",
    "        \"(\",\n",
    "        \")\",\n",
    "        \"<\",\n",
    "        \">\",\n",
    "    ]\n",
    "    rules = [\n",
    "        \"introduction\",\n",
    "        \"elimination\",\n",
    "        \"axiom\",\n",
    "        \"implication\",\n",
    "        \"conjution\",\n",
    "        \"disjunction\",\n",
    "        \"negation\",\n",
    "        \"biconditional\",\n",
    "    ]\n",
    "    generates_vocabulary = tokens + special_word + punctuation + logic_operators + rules + prepos + numbers_list\n",
    "    return generates_vocabulary\n",
    "\n",
    "\n",
    "ts = generate_random_theorems(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    ")\n",
    "\n",
    "for teo in ts:\n",
    "    print(\"----------------\")\n",
    "    print(teo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59516d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "RELATIVE_DATA_PATH = \"/storage/.tmp/data/\n",
    "\n",
    "notebook_path = os.getcwd()\n",
    "data_dir = os.path.join(\n",
    "    notebook_path,\n",
    "    RELATIVE_DATA_PATH,\n",
    ")\n",
    "train_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"training\",\n",
    ")\n",
    "val_dir = os.path.join(\n",
    "    data_dir,\n",
    "    \"validation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22deb471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating_random_theorems()\n",
      "Making theorems\n",
      "Saving to path: /notebooks/source_scripts/../.tmp/data/training/theorems.json\n",
      "generating_random_theorems()\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(val_dir):\n",
    "    os.makedirs(val_dir)\n",
    "\n",
    "\n",
    "def save_to_json(\n",
    "    data,\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"w\",\n",
    "    ) as f:\n",
    "        json.dump(\n",
    "            data,\n",
    "            f,\n",
    "        )\n",
    "\n",
    "\n",
    "def load_from_json(\n",
    "    filename,\n",
    "):\n",
    "    with open(\n",
    "        filename,\n",
    "        \"r\",\n",
    "    ) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_vocab(\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    vocab = generates_vocabulary(\n",
    "        numbers=numbers,\n",
    "        prepositions=prepositions,\n",
    "    )\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def crate_training_data(\n",
    "    batch_dir,\n",
    "    batch_size=100,\n",
    "    max_len=1000,\n",
    "    numbers=1000,\n",
    "    prepositions=100,\n",
    "):\n",
    "    print(\"generating_random_theorems()\")\n",
    "    theorems = generate_random_theorems(\n",
    "        batch_size,\n",
    "        max_teorem_size=max_len - 2,\n",
    "        numbers=1000,\n",
    "        prepositions=100,\n",
    "    )  # -2, saving space for CLS and END tokens\n",
    "    print(\"Making theorems\")\n",
    "\n",
    "    file_name = f\"theorems.json\"\n",
    "    file_path = os.path.join(\n",
    "        batch_dir,\n",
    "        file_name,\n",
    "    )\n",
    "    print(f\"Saving to path: {file_path}\")\n",
    "    save_to_json(\n",
    "        theorems,\n",
    "        file_path,\n",
    "    )\n",
    "\n",
    "\n",
    "max_len = 256\n",
    "batch_size = 1000000\n",
    "numbers = 10000\n",
    "prepositions = 1000\n",
    "\n",
    "# Create Vocabulary\n",
    "vocab = create_vocab(\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "with open(\n",
    "    os.path.join(\n",
    "        train_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "with open(\n",
    "    os.path.join(\n",
    "        val_dir,\n",
    "        \"vocab.txt\",\n",
    "    ),\n",
    "    \"w\",\n",
    ") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "\n",
    "\n",
    "# # create different batches with different max_pred, to ramp up the difficulty\n",
    "crate_training_data(\n",
    "    train_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")\n",
    "\n",
    "# # create validation data\n",
    "crate_training_data(\n",
    "    val_dir,\n",
    "    max_len=max_len,\n",
    "    batch_size=batch_size * 0.20,\n",
    "    numbers=numbers,\n",
    "    prepositions=prepositions,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
